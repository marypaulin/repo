{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "Below are various preprocessing procedures for each dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third-party imports\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Dataframe Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# votes = pd.DataFrame(pd.read_csv('voting-records/house-votes-84.data',header=None))\n",
    "# votes[votes==\"?\"] = np.nan\n",
    "# votes=votes.dropna(axis = 0)\n",
    "# votes[votes==\"y\"] = 1\n",
    "# votes[votes==\"n\"] = 0\n",
    "# votes[votes==\"democrat\"] = 1\n",
    "# votes[votes==\"republican\"] = 0\n",
    "# votes.columns=[\"democrat\", \"handicapped-infants\", \"water-project-cost-sharing\", \"adoption-of-the-budget-resolution\", \n",
    "#                \"physician-fee-freeze\", \"el-salvador-aid\", \"religious-groups-in-schools\", \"anti-satellite-test-ban\",\n",
    "#                \"aid-to-nicaraguan-contras\", \"mx-missile\", \"immigration\", \"synfuels-corporation-cutback\", \n",
    "#                \"education-spending\", \"superfund-right-to-sue\", \"crime\", \"duty-free-exports\", \n",
    "#                \"export-administration-act-south-africa\"\n",
    "#               ]\n",
    "# votes.to_csv('voting-records-binary.csv',index=False,sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monk 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monk1\n",
    "monk1 = pd.DataFrame(pd.read_csv('data/monks-problems/monks-1.train',header=None,delimiter=\" \"))\n",
    "monk1 = monk1.drop(columns=[0,8])\n",
    "monk1 = monk1.applymap(str)\n",
    "monk1 = pd.get_dummies(monk1, prefix=[\"class\", \"a1\", \"a2\", \"a3\", \"a4\", \"a5\", \"a6\"])\n",
    "monk1 = monk1.drop(columns=['class_0', 'a1_3', 'a2_3', 'a3_2', 'a4_3', 'a5_4', 'a6_2'])\n",
    "columns = [\"a1_1\",\"a1_2\",\"a2_1\",\"a2_2\",\"a3_1\",\"a4_1\",\"a4_2\",\"a5_1\",\"a5_2\",\"a5_3\",\"a6_1\",\"class_1\"]\n",
    "monk1 = monk1[columns]\n",
    "\n",
    "monk1.to_csv('data/preprocessed/monk1-train.csv',index=False,sep=';')\n",
    "monk1; # remove semicolon to reveal the table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monk 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monk2\n",
    "monk2 = pd.DataFrame(pd.read_csv('data/monks-problems/monks-2.train',header=None,delimiter=\" \"))\n",
    "monk2 = monk2.drop(columns=[0,8])\n",
    "monk2 = monk2.applymap(str)\n",
    "monk2 = pd.get_dummies(monk2, prefix=[\"class\", \"a1\", \"a2\", \"a3\", \"a4\", \"a5\", \"a6\"])\n",
    "monk2 = monk2.drop(columns=['class_0', 'a1_3', 'a2_3', 'a3_2', 'a4_3', 'a5_4', 'a6_2'])\n",
    "columns = [\"a1_1\",\"a1_2\",\"a2_1\",\"a2_2\",\"a3_1\",\"a4_1\",\"a4_2\",\"a5_1\",\"a5_2\",\"a5_3\",\"a6_1\",\"class_1\"]\n",
    "monk2 = monk2[columns]\n",
    "\n",
    "monk2.to_csv('data/preprocessed/monk2-train.csv',index=False,sep=';')\n",
    "monk2; # remove semicolon to reveal the table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monk 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monk3\n",
    "monk3 = pd.DataFrame(pd.read_csv('data/monks-problems/monks-3.train',header=None,delimiter=\" \"))\n",
    "monk3 = monk3.drop(columns=[0,8])\n",
    "monk3 = monk3.applymap(str)\n",
    "monk3 = pd.get_dummies(monk3, prefix=[\"class\", \"a1\", \"a2\", \"a3\", \"a4\", \"a5\", \"a6\"])\n",
    "monk3 = monk3.drop(columns=['class_0', 'a1_3', 'a2_3', 'a3_2', 'a4_3', 'a5_4', 'a6_2'])\n",
    "columns = [\"a1_1\",\"a1_2\",\"a2_1\",\"a2_2\",\"a3_1\",\"a4_1\",\"a4_2\",\"a5_1\",\"a5_2\",\"a5_3\",\"a6_1\",\"class_1\"]\n",
    "monk3 = monk3[columns]\n",
    "\n",
    "monk3.to_csv('data/preprocessed/monk3-train.csv',index=False,sep=';')\n",
    "monk3; # remove semicolon to reveal the table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_scale = pd.DataFrame(pd.read_csv('data/balance-scale/balance-scale.data',header=None,delimiter=\",\"))\n",
    "balance_scale.columns = [\"class\", \"a1\", \"a2\", \"a3\", \"a4\"]\n",
    "balance_scale['class'] = (balance_scale['class']==\"B\")\n",
    "balance_scale\n",
    "\n",
    "balance_scale = balance_scale.applymap(str)\n",
    "balance_scale = pd.get_dummies(balance_scale, prefix=[\"class\", \"a1\", \"a2\", \"a3\", \"a4\"])\n",
    "balance_scale['class']=balance_scale['class_True']\n",
    "balance_scale = balance_scale.drop(columns=['class_True','class_False', 'a1_5', 'a2_5','a3_5','a4_5'])\n",
    "\n",
    "balance_scale.to_csv('data/preprocessed/balance-scale.csv',index=False,sep=';')\n",
    "balance_scale; # remove semicolon to reveal the table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "car = pd.DataFrame(pd.read_csv('data/car/car.data',header=None,delimiter=\",\"))\n",
    "car.columns = [\"a1\", \"a2\", \"a3\", \"a4\", \"a5\", \"a6\", \"class\"]\n",
    "car['class'] = 1-(car['class']==\"unacc\")\n",
    "car = car.applymap(str)\n",
    "car = pd.get_dummies(car)\n",
    "car = car.drop(columns=['a1_vhigh', 'a2_vhigh', 'a3_5more', 'a4_more', 'a5_small', 'a6_med', 'class_0'])\n",
    "car.to_csv('data/preprocessed/car-evaluation.csv',index=False,sep=';')\n",
    "car; # remove semicolon to reveal the table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPAS is already in a compatible format\n",
    "compas = pd.DataFrame(pd.read_csv('data/compas/compas-binary.csv'))\n",
    "compas['age:<21']=compas['age:18-20']\n",
    "compas['age:<23']=compas['age:18-20']+compas['age:21-22']\n",
    "compas['age:<26']=compas['age:18-20']+compas['age:21-22']+compas['age:23-25']\n",
    "compas['age:<46']=compas['age:18-20']+compas['age:21-22']+compas['age:23-25']+compas['age:26-45']\n",
    "\n",
    "compas = compas.drop(columns=['age:18-20', 'age:21-22', 'age:23-25', 'age:26-45', 'age:>45'])\n",
    "\n",
    "columns = ['sex:Female','age:<21','age:<23','age:<26', 'age:<46', \n",
    "           'juvenile-felonies:=0', 'juvenile-misdemeanors:=0', 'juvenile-crimes:=0',\n",
    "           'priors:=0', 'priors:=1', 'priors:2-3', 'priors:>3', 'recidivate-within-two-years:1']\n",
    "\n",
    "compas = compas[columns]\n",
    "compas\n",
    "compas.to_csv('data/preprocessed/compas-binary.csv',index=False,sep=';')\n",
    "\n",
    "compas; # remove semicolon to reveal the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I see, I don't think it's necessary to store the partitioned data copies on disk\n",
    "# We now have a library function to do crss validation in memory so the stuff below can go away"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold # import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10,random_state=2018,shuffle=True) # Define the split - into 10 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "compas = pd.DataFrame(pd.read_csv('data/preprocessed/compas-binary.csv',sep=\";\"))\n",
    "monk1 = pd.DataFrame(pd.read_csv('data/preprocessed/monk1-train.csv',sep=\";\"))\n",
    "monk2 = pd.DataFrame(pd.read_csv('data/preprocessed/monk2-train.csv',sep=\";\"))\n",
    "monk3 = pd.DataFrame(pd.read_csv('data/preprocessed/monk3-train.csv',sep=\";\"))\n",
    "balance = pd.DataFrame(pd.read_csv('data/preprocessed/balance-scale.csv',sep=\";\"))\n",
    "tictactoe = pd.DataFrame(pd.read_csv('data/preprocessed/tic-tac-toe.csv',sep=\";\"))\n",
    "car = pd.DataFrame(pd.read_csv('data/preprocessed/car-evaluation.csv',sep=\";\"))\n",
    "fico = pd.DataFrame(pd.read_csv('data/preprocessed/fico_binary.csv',sep=\";\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for train_index, test_index in kf.split(compas):\n",
    "    i=i+1\n",
    "    compas_train = compas.iloc[train_index]\n",
    "    compas_test = compas.iloc[test_index]\n",
    "    \n",
    "    compas_train.to_csv('preprocessed/compas-binary.csv.train'+str(i)+'.csv',index=False,sep=';')\n",
    "    compas_test.to_csv('preprocessed/compas-binary.csv.test'+str(i)+'.csv',index=False,sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for train_index, test_index in kf.split(monk1):\n",
    "    i=i+1\n",
    "    monk1_train = monk1.iloc[train_index]\n",
    "    monk1_test = monk1.iloc[test_index]\n",
    "    \n",
    "    monk1_train.to_csv('preprocessed/monk1-train.csv.train'+str(i)+'.csv',index=False,sep=';')\n",
    "    monk1_test.to_csv('preprocessed/monk1-train.csv.test'+str(i)+'.csv',index=False,sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for train_index, test_index in kf.split(monk2):\n",
    "    i=i+1\n",
    "    monk2_train = monk2.iloc[train_index]\n",
    "    monk2_test = monk2.iloc[test_index]\n",
    "    \n",
    "    monk2_train.to_csv('preprocessed/monk2-train.csv.train'+str(i)+'.csv',index=False,sep=';')\n",
    "    monk2_test.to_csv('preprocessed/monk2-train.csv.test'+str(i)+'.csv',index=False,sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for train_index, test_index in kf.split(monk3):\n",
    "    i=i+1\n",
    "    monk3_train = monk3.iloc[train_index]\n",
    "    monk3_test = monk3.iloc[test_index]\n",
    "    \n",
    "    monk3_train.to_csv('preprocessed/monk3-train.csv.train'+str(i)+'.csv',index=False,sep=';')\n",
    "    monk3_test.to_csv('preprocessed/monk3-train.csv.test'+str(i)+'.csv',index=False,sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for train_index, test_index in kf.split(balance):\n",
    "    i=i+1\n",
    "    balance_train = balance.iloc[train_index]\n",
    "    balance_test = balance.iloc[test_index]\n",
    "    \n",
    "    balance_train.to_csv('preprocessed/balance-scale.csv.train'+str(i)+'.csv',index=False,sep=';')\n",
    "    balance_test.to_csv('preprocessed/balance-scale.csv.test'+str(i)+'.csv',index=False,sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for train_index, test_index in kf.split(tictactoe):\n",
    "    i=i+1\n",
    "    tictactoe_train = tictactoe.iloc[train_index]\n",
    "    tictactoe_test = tictactoe.iloc[test_index]\n",
    "    \n",
    "    tictactoe_train.to_csv('preprocessed/tic-tac-toe.csv.train'+str(i)+'.csv',index=False,sep=';')\n",
    "    tictactoe_test.to_csv('preprocessed/tic-tac-toe.csv.test'+str(i)+'.csv',index=False,sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for train_index, test_index in kf.split(car):\n",
    "    i=i+1\n",
    "    car_train = car.iloc[train_index]\n",
    "    car_test = car.iloc[test_index]\n",
    "    \n",
    "    car_train.to_csv('preprocessed/car-evaluation.csv.train'+str(i)+'.csv',index=False,sep=';')\n",
    "    car_test.to_csv('preprocessed/car-evaluation.csv.test'+str(i)+'.csv',index=False,sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for train_index, test_index in kf.split(fico):\n",
    "    i=i+1\n",
    "    fico_train = fico.iloc[train_index]\n",
    "    fico_test = fico.iloc[test_index]\n",
    "    \n",
    "    fico_train.to_csv('preprocessed/fico_binary.csv.train'+str(i)+'.csv',index=False,sep=';')\n",
    "    fico_test.to_csv('preprocessed/fico_binary.csv.test'+str(i)+'.csv',index=False,sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
