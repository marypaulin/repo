{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Parallel OSDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Compression Factor: 56.154\n",
      "Runtime: 2.243695020675659 Seconds\n",
      "Prediction: \n",
      "[[0 0 1 ... 0 0 1]]\n",
      "Training Accuracy: 0.669031417402635\n",
      "Visualization: \n",
      "(_,_,_,0,_,_,_,_,_,_,_,0) => 0 (Risk Contribution = 0.12878746199507746)\n",
      "(_,_,_,1,_,_,_,0,_,_,_,0) => 1 (Risk Contribution = 0.022518459533806285)\n",
      "(_,_,_,1,_,_,_,1,_,_,0,0) => 0 (Risk Contribution = 0.0708751990734038)\n",
      "(_,_,_,1,_,_,_,1,_,_,1,0) => 1 (Risk Contribution = 0.022228898219197917)\n",
      "(_,_,_,_,_,_,_,_,_,_,_,1) => 1 (Risk Contribution = 0.11155856377587954)\n"
     ]
    }
   ],
   "source": [
    "# third-party imports\n",
    "from time import time\n",
    "\n",
    "# local imports\n",
    "from lib.models.parallel_osdt_classifier import ParallelOSDTClassifier\n",
    "from lib.data_structures.dataset import read_dataframe\n",
    "\n",
    "# Using COMPAS as an example\n",
    "dataset = read_dataframe('data/preprocessed/compas-binary.csv') \n",
    "(n, m) = dataset.shape\n",
    "X = dataset.values[:n,:m-1]\n",
    "y = dataset.values[:n,-1]\n",
    "\n",
    "hyperparameters = {\n",
    "    'regularization': 0.005, # Regularization coefficient which effects the penalty on model complexity\n",
    "\n",
    "    'max_depth': float('Inf'), # User-specified limit on the model\n",
    "    'max_time': float('Inf'), # User-specified limit on the runtime \n",
    "\n",
    "    'workers': 1, # Parameter that varies based on how much computational resource is available\n",
    "\n",
    "    'visualize_model': True, # Toggle whether a rule-list visualization is rendered\n",
    "    'visualize_training': False,  # Toggle whether a dependency graph is streamed at runtime\n",
    "    'verbose': False, # Toggle whether event messages are printed\n",
    "    'log': False, # Toggle whether client processes log to logs/work_<id>.log files\n",
    "    'profile': False, # Toggle Snapshots for Profiling Memory Usage\n",
    "    \n",
    "    'configuration': { # More configurations around toggling optimizations and prioritization options\n",
    "        'priority_metric': 'uniform', # Decides how tasks are prioritized\n",
    "        'deprioritization': 0.01, # Decides how much to push back a task if it has pending dependencies\n",
    "\n",
    "        # Note that Leaf Permutation Bound (Theorem 6) is \n",
    "        # Toggles the assumption about objective independence when composing subtrees (Theorem 1)\n",
    "        # Disabling this actually breaks convergence due to information loss\n",
    "        'hierarchical_lowerbound': True, \n",
    "        # Toggles whether problems are pruned based on insufficient accuracy (compared to other results) (Lemma 2)\n",
    "        'look_ahead': True,\n",
    "        # Toggles whether a split is avoided based on insufficient support (proxy for accuracy gain) (Theorem 3)\n",
    "        'support_lowerbound': True,\n",
    "        # Toggles whether a split is avoided based on insufficient potential accuracy gain (Theorem 4)\n",
    "        'incremental_accuracy_lowerbound': True,\n",
    "        # Toggles whether a problem is pruned based on insufficient accuracy (in general) (Theorem 5)\n",
    "        'accuracy_lowerbound': True,\n",
    "        # Toggles whether problem equivalence is based solely on the capture set (Similar to Corollary 6)\n",
    "        'capture_equivalence': True,\n",
    "        # Hamming distance used to propagate bounding information of similar problems (Theorem 7 + some more...)\n",
    "        \"similarity_threshold\": 0,\n",
    "        # Toggles whether equivalent points contribute to the lowerbound (Proposition 8 and Theorem 9)\n",
    "        'equivalent_point_lowerbound': True,\n",
    "\n",
    "        # Toggles compression of dataset based on equivalent point aggregation\n",
    "        'equivalent_point_compression': False,\n",
    "        # Toggles whether asynchronous tasks can be cancelled after being issued\n",
    "        'task_cancellation': True,\n",
    "        # Toggles whether look_ahead prunes using objective upperbounds (This builds on top of look_ahead)\n",
    "        'interval_look_ahead': True,\n",
    "        # Cooldown timer (seconds) on synchornization operations\n",
    "        'synchronization_cooldown': 0.01,\n",
    "        # Cache Limit\n",
    "        'cache_limit': float('Inf')\n",
    "    }\n",
    "}\n",
    "\n",
    "start = time()\n",
    "model = ParallelOSDTClassifier(**hyperparameters)\n",
    "model.fit(X, y)\n",
    "prediction = model.predict(X)\n",
    "prediction = prediction.reshape(1, n)\n",
    "print('Runtime: {} Seconds'.format(time() - start))\n",
    "print('Prediction: \\n{}'.format(prediction))\n",
    "print('Training Accuracy: {}'.format(model.score(X, y)))\n",
    "print('Visualization: \\n{}'.format(model.model.visualization))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Sequential OSDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nrule: 11\n",
      "ndata: 122\n",
      "gr: [4.89173624e-03 4.37315843e-03 1.10185434e-03 2.13904218e-03\n",
      " 5.77481732e-05 6.86278883e-03 2.62190206e-04 7.14565236e-03\n",
      " 4.42608021e-03 2.81267657e-03 2.22388497e-04]\n",
      "order: [7, 5, 0, 8, 1, 9, 3, 2, 6, 10, 4]\n",
      "odr: [7, 5, 0, 8, 1, 9, 3, 2, 6, 10, 4]\n",
      "the order of x's columns:  [7, 5, 0, 8, 1, 9, 3, 2, 6, 10, 4]\n",
      "COUNT: 1000000\n",
      "COUNT: 2000000\n",
      "COUNT: 3000000\n",
      "COUNT: 4000000\n",
      "COUNT: 5000000\n",
      "COUNT: 6000000\n",
      "COUNT: 7000000\n",
      "COUNT: 8000000\n",
      "COUNT: 9000000\n",
      "COUNT: 10000000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-18c22461dfef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOSDTClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/NSS/repo/lib/models/osdt_classifier.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0minit_cart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0msaveTree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             readTree=False)\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/NSS/repo/lib/osdt.py\u001b[0m in \u001b[0;36mbbound\u001b[0;34m(x, y, lamb, prior_metric, MAXDEPTH, MAX_NLEAVES, niter, logon, support, incre_support, accu_support, equiv_points, lookahead, lenbound, R_c0, timelimit, init_cart, saveTree, readTree)\u001b[0m\n\u001b[1;32m    724\u001b[0m                 \u001b[0;31m# construct the new tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m                 tree_new = Tree(cache_tree=child, ndata=ndata, lamb=lamb,\n\u001b[0;32m--> 726\u001b[0;31m                                 splitleaf=new_leaf_split, prior_metric=prior_metric)\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m                 \u001b[0;31m# MAX Number of leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/NSS/repo/lib/osdt.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cache_tree, ndata, lamb, splitleaf, prior_metric)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mprior_metric\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"curiosity\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mremoved_leaves\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleaves\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplitleaf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m             \u001b[0mnum_cap_rm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleaf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_captured\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mleaf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mremoved_leaves\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnum_cap_rm\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mndata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# All dependencies of this notebook\n",
    "\n",
    "# third-party imports\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# local imports\n",
    "from lib.models.osdt_classifier import OSDTClassifier\n",
    "from lib.experiments.analysis import train_cross_validate\n",
    "from lib.data_structures.dataset import read_dataframe\n",
    "\n",
    "# Using COMPAS as an example\n",
    "dataset = read_dataframe('data/compression/1.csv') \n",
    "(n, m) = dataset.shape\n",
    "X = dataset.values[:,:-1]\n",
    "y = dataset.values[:,-1]\n",
    "\n",
    "hyperparameters = {\n",
    "    'regularization': 0.005, # Regularization coefficient which effects the penalty on model complexity\n",
    "    'max_depth': float('Inf'), # User-specified limit on the model\n",
    "    'max_time': float('Inf'), # User-specified limit on the runtime \n",
    "    \n",
    "    'configuration': { # More configurations around toggling optimizations and prioritization options\n",
    "        'priority_metric': 'curiosity',\n",
    "        'look_ahead': True,\n",
    "        'support_lowerbound': True,\n",
    "        'incremental_accuracy_lowerbound': True,\n",
    "        'accuracy_lowerbound': True,\n",
    "        'equivalent_point_lowerbound': True,\n",
    "    }\n",
    "}\n",
    "\n",
    "start = time()\n",
    "model = OSDTClassifier(**hyperparameters)\n",
    "model.fit(X, y)\n",
    "prediction = model.predict(X)\n",
    "prediction = prediction.reshape(1, n)\n",
    "print('Runtime: {} Seconds'.format(time() - start))\n",
    "print('Prediction: \\n{}'.format(prediction))\n",
    "print('Training Accuracy: {}'.format(model.score(X, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
