{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Parallel OSDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Compression Factor: 1.504\n"
     ]
    }
   ],
   "source": [
    "# third-party imports\n",
    "from time import time\n",
    "\n",
    "# local imports\n",
    "from lib.models.parallel_osdt_classifier import ParallelOSDTClassifier\n",
    "from lib.data_structures.dataset import read_dataframe\n",
    "\n",
    "# Using COMPAS as an example\n",
    "dataset = read_dataframe('data/preprocessed/census.csv') \n",
    "(n, m) = dataset.shape\n",
    "X = dataset.values[:n,:m-1]\n",
    "y = dataset.values[:n,-1]\n",
    "\n",
    "hyperparameters = {\n",
    "    'regularization': 0.1, # Regularization coefficient which effects the penalty on model complexity\n",
    "\n",
    "    'max_depth': float('Inf'), # User-specified limit on the model\n",
    "    'max_time': float('Inf'), # User-specified limit on the runtime \n",
    "\n",
    "    'workers': 1, # Parameter that varies based on how much computational resource is available\n",
    "\n",
    "    'visualize': True, # Toggle whether a rule-list visualization is rendered\n",
    "    'verbose': False, # Toggle whether event messages are printed\n",
    "    'log': False, # Toggle whether client processes log to logs/work_<id>.log files\n",
    "    'profile': False, # Toggle Snapshots for Profiling Memory Usage\n",
    "    \n",
    "    'configuration': { # More configurations around toggling optimizations and prioritization options\n",
    "        'priority_metric': 'uniform', # Decides how tasks are prioritized\n",
    "        'deprioritization': 0.01, # Decides how much to push back a task if it has pending dependencies\n",
    "\n",
    "        # Note that Leaf Permutation Bound (Theorem 6) is \n",
    "        # Toggles the assumption about objective independence when composing subtrees (Theorem 1)\n",
    "        # Disabling this actually breaks convergence due to information loss\n",
    "        'hierarchical_lowerbound': True, \n",
    "        # Toggles whether problems are pruned based on insufficient accuracy (compared to other results) (Lemma 2)\n",
    "        'look_ahead': True,\n",
    "        # Toggles whether a split is avoided based on insufficient support (proxy for accuracy gain) (Theorem 3)\n",
    "        'support_lowerbound': True,\n",
    "        # Toggles whether a split is avoided based on insufficient potential accuracy gain (Theorem 4)\n",
    "        'incremental_accuracy_lowerbound': True,\n",
    "        # Toggles whether a problem is pruned based on insufficient accuracy (in general) (Theorem 5)\n",
    "        'accuracy_lowerbound': True,\n",
    "        # Toggles whether problem equivalence is based solely on the capture set (Similar to Corollary 6)\n",
    "        'capture_equivalence': True,\n",
    "        # Hamming distance used to propagate bounding information of similar problems (Theorem 7 + some more...)\n",
    "        \"similarity_threshold\": 0,\n",
    "        # Toggles whether equivalent points contribute to the lowerbound (Proposition 8 and Theorem 9)\n",
    "        'equivalent_point_lowerbound': True,\n",
    "\n",
    "        # Toggles compression of dataset based on equivalent point aggregation\n",
    "        'equivalent_point_compression': False,\n",
    "        # Toggles whether asynchronous tasks can be cancelled after being issued\n",
    "        'task_cancellation': True,\n",
    "        # Toggles whether look_ahead prunes using objective upperbounds (This builds on top of look_ahead)\n",
    "        'interval_look_ahead': True,\n",
    "        # Cooldown timer (seconds) on synchornization operations\n",
    "        'synchronization_cooldown': 0.01,\n",
    "        # Cache Limit\n",
    "        'cache_limit': float('Inf')\n",
    "    }\n",
    "}\n",
    "\n",
    "start = time()\n",
    "model = ParallelOSDTClassifier(**hyperparameters)\n",
    "model.fit(X, y)\n",
    "prediction = model.predict(X)\n",
    "prediction = prediction.reshape(1, n)\n",
    "print('Runtime: {} Seconds'.format(time() - start))\n",
    "print('Prediction: \\n{}'.format(prediction))\n",
    "print('Training Accuracy: {}'.format(model.score(X, y)))\n",
    "print('Visualization: \\n{}'.format(model.model.visualization))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Sequential OSDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nrule: 331\n",
      "ndata: 2500\n",
      "gr: [2.34867144e-02 2.10133877e-03 3.25128590e-05 3.48267745e-03\n",
      " 2.35034402e-03 4.60710225e-03 6.71334445e-02 4.75370524e-02\n",
      " 1.23818180e-02 1.48757206e-02 1.83997212e-02 2.19774440e-02\n",
      " 1.27934857e-03 1.84304866e-03 2.34867144e-02 3.69941921e-03\n",
      " 3.20981155e-03 6.48703954e-04 3.12005194e-03 3.67152148e-03\n",
      " 2.80167030e-03 3.09330444e-03 1.54061248e-03 2.68882733e-03\n",
      " 9.93566346e-03 9.52988220e-03 2.16075381e-03 2.71545243e-04\n",
      " 4.91306064e-06 3.09330444e-03 1.83746938e-04 4.35665932e-05\n",
      " 8.18568411e-04 2.96152799e-04 1.32943974e-04 1.42407573e-04\n",
      " 1.51414184e-04 9.44496191e-05 4.65667488e-04 4.44274023e-04\n",
      " 0.00000000e+00 9.55634029e-07 0.00000000e+00 4.07815385e-05\n",
      " 3.10571366e-04 4.21871282e-04 5.41274704e-05 1.71317353e-03\n",
      " 4.49528142e-04 5.05269005e-04 1.36920602e-03 3.24949052e-04\n",
      " 6.50158271e-04 0.00000000e+00 1.06227816e-04 3.16276748e-04\n",
      " 4.28724906e-04 3.68640025e-03 2.21870127e-04 1.30135846e-03\n",
      " 3.69625405e-03 5.91234027e-04 1.20367762e-03 1.72691404e-03\n",
      " 1.50887771e-05 3.79353103e-08 9.57653333e-04 2.30829993e-02\n",
      " 1.67687288e-02 1.96242240e-03 6.70963468e-05 1.16434186e-03\n",
      " 1.64891021e-04 7.02733870e-08 3.10954086e-07 6.61476653e-04\n",
      " 3.01422578e-05 8.02026946e-02 2.40939919e-02 2.53250997e-02\n",
      " 8.02026946e-02 1.88152217e-02 3.62716283e-02 4.54938600e-04\n",
      " 2.53730840e-04 7.65784297e-05 2.69390612e-03 1.33926601e-03\n",
      " 3.95459365e-03 6.41323401e-02 1.66117157e-02 9.56417642e-04\n",
      " 8.06079664e-03 1.05674918e-02 2.01704395e-03 2.68034511e-03\n",
      " 3.69625405e-03 3.01422578e-05 3.01422578e-05 6.50158271e-04\n",
      " 6.50158271e-04 2.08638633e-06 9.75627970e-04 1.67274819e-04\n",
      " 5.27550461e-04 1.20400808e-04 1.37234178e-03 9.05718043e-05\n",
      " 4.44274023e-04 3.01422578e-05 3.95878776e-04 1.20367762e-03\n",
      " 1.14695415e-03 1.11470766e-03 2.05747525e-03 1.35819762e-03\n",
      " 4.56455350e-04 3.95650639e-04 5.65223226e-04 2.68480400e-04\n",
      " 5.54729639e-04 2.62063590e-04 2.30829993e-02 3.07911615e-03\n",
      " 5.27550461e-04 1.97368880e-04 6.57422222e-05 7.30531259e-04\n",
      " 1.34226742e-04 1.68088011e-02 2.95444109e-03 4.43084465e-03\n",
      " 3.58737722e-05 1.47107490e-05 3.01422578e-05 3.18312016e-05\n",
      " 2.25183643e-02 4.54938600e-04 7.29258993e-03 3.03325830e-02\n",
      " 3.25920267e-03 2.50414497e-02 4.40473023e-03 6.49956189e-03\n",
      " 1.10507517e-03 1.92554449e-03 1.82594909e-02 1.82029262e-03\n",
      " 3.20981155e-03 1.40998488e-03 1.78279002e-03 0.00000000e+00\n",
      " 5.54645291e-06 5.27550461e-04 1.05341208e-04 2.71659866e-04\n",
      " 3.16971837e-03 2.51158024e-05 3.16276748e-04 8.02026946e-02\n",
      " 9.87215328e-06 1.42609976e-03 2.65307920e-03 8.33198335e-02\n",
      " 2.25183643e-02 5.87959820e-03 1.87132505e-05 8.00591536e-02\n",
      " 1.32971342e-02 4.80428210e-02 2.30829993e-02 3.30990283e-03\n",
      " 5.39833441e-03 1.82651960e-02 3.39496025e-03 2.09476315e-04\n",
      " 5.41640697e-03 1.42801288e-04 3.01422578e-05 2.10766757e-04\n",
      " 8.00591536e-02 3.76806737e-03 5.56337667e-02 1.20367762e-03\n",
      " 1.72691404e-03 1.60729219e-04 1.18462600e-04 1.41763179e-03\n",
      " 0.00000000e+00 2.42929528e-05 1.90350493e-02 4.42696072e-03\n",
      " 4.71863091e-03 2.43270548e-03 3.55857794e-03 4.40207913e-04\n",
      " 2.39270268e-02 2.26000109e-02 1.40021164e-03 3.39633294e-03\n",
      " 2.42929528e-05 2.69362081e-03 3.01594504e-04 4.81672724e-05\n",
      " 7.13319802e-04 1.61426160e-03 1.30240858e-04 1.88319915e-04\n",
      " 4.16942088e-03 3.01594504e-04 3.33697966e-05 4.81672724e-05\n",
      " 9.75627970e-04 1.05341208e-04 6.50158271e-04 2.10766757e-04\n",
      " 1.05721960e-03 2.31794249e-03 6.26110845e-02 1.21523513e-02\n",
      " 9.45466340e-03 6.53412078e-04 9.51115664e-04 1.16085912e-02\n",
      " 7.39163161e-04 5.54729639e-04 1.05341208e-04 5.54729639e-04\n",
      " 1.47350628e-03 2.10766757e-04 2.10766757e-04 3.67524913e-03\n",
      " 4.06312422e-03 2.65906747e-03 1.40998488e-03 1.14900354e-03\n",
      " 6.58304355e-04 3.04643232e-04 4.97534626e-06 1.05341208e-04\n",
      " 2.10766757e-04 3.16276748e-04 8.02026946e-02 3.24238188e-03\n",
      " 2.05747525e-03 2.69390612e-03 1.33092132e-06 3.24949052e-04\n",
      " 3.27876642e-02 5.68924909e-02 3.77036305e-03 1.90865248e-06\n",
      " 2.36580741e-03 1.90185646e-05 4.99683048e-04 2.13570692e-03\n",
      " 1.05341208e-04 1.50887771e-05 3.79353103e-08 9.57653333e-04\n",
      " 6.46836992e-02 8.00591536e-02 3.46599925e-03 1.19169862e-03\n",
      " 6.49956189e-03 1.10507517e-03 1.92554449e-03 1.85716276e-02\n",
      " 1.27934857e-03 1.59775611e-03 4.17779203e-06 1.26968334e-03\n",
      " 2.13614835e-03 1.05341208e-04 1.05341208e-04 2.33714647e-03\n",
      " 2.75197833e-05 6.03328205e-05 2.60108286e-07 1.05341208e-04\n",
      " 1.52623496e-02 3.02194338e-02 1.02433617e-02 2.95354651e-03\n",
      " 4.14011316e-05 1.90350493e-02 1.17081482e-04 9.07481290e-04\n",
      " 5.29480743e-04 3.62953006e-03 1.17081482e-04 1.17081482e-04\n",
      " 0.00000000e+00 3.17654583e-02 7.44265963e-04 2.03264323e-03\n",
      " 2.74450165e-02 2.30552479e-03 8.02026946e-02 2.34867144e-02\n",
      " 1.18153797e-02 5.28879807e-02 2.47161769e-03 2.41076672e-02\n",
      " 1.20031413e-06 1.52623496e-02 3.10017532e-03 3.49506231e-03\n",
      " 4.60710225e-03 7.00233463e-03 2.71765313e-04 1.50340153e-03\n",
      " 3.18509870e-03 3.10174570e-03 7.45534957e-04 1.41278132e-02\n",
      " 4.12165479e-03 6.82398009e-06 7.30163250e-05 1.65587422e-03\n",
      " 3.25709157e-03 3.26140530e-04 9.51115664e-04 8.02026946e-02\n",
      " 9.89094318e-03 9.18618169e-03 1.32204233e-05 1.79456697e-04\n",
      " 3.10418722e-03 1.11039927e-02 1.05726813e-03]\n",
      "order: [163, 242, 80, 77, 159, 323, 298, 261, 180, 167, 6, 260, 89, 218, 249, 182, 301, 169, 7, 82, 248, 293, 139, 281, 296, 79, 141, 303, 78, 196, 299, 0, 14, 170, 122, 67, 197, 164, 136, 11, 190, 285, 81, 267, 10, 173, 146, 129, 68, 90, 280, 305, 9, 315, 168, 8, 219, 300, 223, 329, 93, 282, 24, 324, 25, 220, 325, 92, 138, 309, 143, 264, 165, 176, 172, 192, 308, 5, 131, 191, 142, 208, 316, 232, 88, 250, 181, 15, 96, 60, 57, 231, 19, 289, 194, 307, 3, 262, 199, 174, 171, 140, 320, 243, 148, 16, 312, 156, 18, 328, 313, 306, 21, 29, 123, 130, 283, 20, 245, 86, 201, 23, 95, 233, 162, 302, 193, 252, 4, 275, 217, 297, 26, 272, 255, 1, 114, 244, 295, 94, 69, 145, 266, 13, 147, 150, 63, 184, 47, 319, 205, 269, 22, 311, 228, 161, 187, 149, 234, 198, 106, 50, 115, 87, 59, 268, 12, 271, 62, 111, 183, 263, 71, 235, 112, 113, 265, 144, 330, 216, 102, 212, 66, 259, 91, 222, 322, 287, 32, 314, 294, 224, 127, 204, 75, 236, 221, 214, 99, 100, 52, 17, 61, 118, 225, 120, 227, 288, 124, 153, 104, 49, 254, 38, 116, 83, 137, 48, 108, 39, 195, 56, 45, 110, 117, 321, 247, 51, 158, 55, 241, 44, 237, 202, 209, 33, 310, 155, 27, 119, 121, 84, 58, 240, 230, 229, 215, 179, 175, 125, 207, 30, 327, 103, 72, 185, 36, 177, 35, 128, 34, 206, 105, 186, 286, 290, 291, 54, 213, 273, 274, 226, 279, 239, 256, 154, 37, 107, 85, 318, 70, 126, 277, 46, 203, 211, 31, 284, 43, 132, 210, 2, 135, 76, 109, 97, 178, 134, 98, 276, 157, 200, 189, 253, 166, 64, 257, 133, 326, 160, 317, 152, 238, 28, 270, 101, 251, 246, 304, 41, 74, 278, 73, 65, 258, 42, 40, 53, 188, 151, 292]\n",
      "odr: [163, 242, 80, 77, 159, 323, 298, 261, 180, 167, 6, 260, 89, 218, 249, 182, 301, 169, 7, 82, 248, 293, 139, 281, 296, 79, 141, 303, 78, 196, 299, 0, 14, 170, 122, 67, 197, 164, 136, 11, 190, 285, 81, 267, 10, 173, 146, 129, 68, 90, 280, 305, 9, 315, 168, 8, 219, 300, 223, 329, 93, 282, 24, 324, 25, 220, 325, 92, 138, 309, 143, 264, 165, 176, 172, 192, 308, 5, 131, 191, 142, 208, 316, 232, 88, 250, 181, 15, 96, 60, 57, 231, 19, 289, 194, 307, 3, 262, 199, 174, 171, 140, 320, 243, 148, 16, 312, 156, 18, 328, 313, 306, 21, 29, 123, 130, 283, 20, 245, 86, 201, 23, 95, 233, 162, 302, 193, 252, 4, 275, 217, 297, 26, 272, 255, 1, 114, 244, 295, 94, 69, 145, 266, 13, 147, 150, 63, 184, 47, 319, 205, 269, 22, 311, 228, 161, 187, 149, 234, 198, 106, 50, 115, 87, 59, 268, 12, 271, 62, 111, 183, 263, 71, 235, 112, 113, 265, 144, 330, 216, 102, 212, 66, 259, 91, 222, 322, 287, 32, 314, 294, 224, 127, 204, 75, 236, 221, 214, 99, 100, 52, 17, 61, 118, 225, 120, 227, 288, 124, 153, 104, 49, 254, 38, 116, 83, 137, 48, 108, 39, 195, 56, 45, 110, 117, 321, 247, 51, 158, 55, 241, 44, 237, 202, 209, 33, 310, 155, 27, 119, 121, 84, 58, 240, 230, 229, 215, 179, 175, 125, 207, 30, 327, 103, 72, 185, 36, 177, 35, 128, 34, 206, 105, 186, 286, 290, 291, 54, 213, 273, 274, 226, 279, 239, 256, 154, 37, 107, 85, 318, 70, 126, 277, 46, 203, 211, 31, 284, 43, 132, 210, 2, 135, 76, 109, 97, 178, 134, 98, 276, 157, 200, 189, 253, 166, 64, 257, 133, 326, 160, 317, 152, 238, 28, 270, 101, 251, 246, 304, 41, 74, 278, 73, 65, 258, 42, 40, 53, 188, 151, 292]\n",
      "the order of x's columns:  [163, 242, 80, 77, 159, 323, 298, 261, 180, 167, 6, 260, 89, 218, 249, 182, 301, 169, 7, 82, 248, 293, 139, 281, 296, 79, 141, 303, 78, 196, 299, 0, 14, 170, 122, 67, 197, 164, 136, 11, 190, 285, 81, 267, 10, 173, 146, 129, 68, 90, 280, 305, 9, 315, 168, 8, 219, 300, 223, 329, 93, 282, 24, 324, 25, 220, 325, 92, 138, 309, 143, 264, 165, 176, 172, 192, 308, 5, 131, 191, 142, 208, 316, 232, 88, 250, 181, 15, 96, 60, 57, 231, 19, 289, 194, 307, 3, 262, 199, 174, 171, 140, 320, 243, 148, 16, 312, 156, 18, 328, 313, 306, 21, 29, 123, 130, 283, 20, 245, 86, 201, 23, 95, 233, 162, 302, 193, 252, 4, 275, 217, 297, 26, 272, 255, 1, 114, 244, 295, 94, 69, 145, 266, 13, 147, 150, 63, 184, 47, 319, 205, 269, 22, 311, 228, 161, 187, 149, 234, 198, 106, 50, 115, 87, 59, 268, 12, 271, 62, 111, 183, 263, 71, 235, 112, 113, 265, 144, 330, 216, 102, 212, 66, 259, 91, 222, 322, 287, 32, 314, 294, 224, 127, 204, 75, 236, 221, 214, 99, 100, 52, 17, 61, 118, 225, 120, 227, 288, 124, 153, 104, 49, 254, 38, 116, 83, 137, 48, 108, 39, 195, 56, 45, 110, 117, 321, 247, 51, 158, 55, 241, 44, 237, 202, 209, 33, 310, 155, 27, 119, 121, 84, 58, 240, 230, 229, 215, 179, 175, 125, 207, 30, 327, 103, 72, 185, 36, 177, 35, 128, 34, 206, 105, 186, 286, 290, 291, 54, 213, 273, 274, 226, 279, 239, 256, 154, 37, 107, 85, 318, 70, 126, 277, 46, 203, 211, 31, 284, 43, 132, 210, 2, 135, 76, 109, 97, 178, 134, 98, 276, 157, 200, 189, 253, 166, 64, 257, 133, 326, 160, 317, 152, 238, 28, 270, 101, 251, 246, 304, 41, 74, 278, 73, 65, 258, 42, 40, 53, 188, 151, 292]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> log: False\n",
      ">>> support bound: True\n",
      ">>> accu_support: True\n",
      ">>> accurate support bound: True\n",
      ">>> equiv points bound: True\n",
      ">>> lookahead bound: True\n",
      "prior_metric= curiosity\n",
      "COUNT_UNIQLEAVES: 15516\n",
      "COUNT_LEAFLOOKUPS: 146\n",
      "total time:  5.536438703536987\n",
      "lambda:  0.1\n",
      "leaves:  [()]\n",
      "num_captured:  [2500]\n",
      "num_captured_incorrect:  [907]\n",
      "prediction:  [1]\n",
      "Objective:  0.4628\n",
      "Accuracy:  0.6372\n",
      "COUNT of the best tree:  0\n",
      "time when the best tree is achieved:  1563743936.418797\n",
      "TOTAL COUNT:  3299\n",
      "best_is_cart False\n",
      "Runtime: 37.541176080703735 Seconds\n",
      "Prediction: \n",
      "[[1 1 1 ... 1 1 1]]\n",
      "Training Accuracy: 0.6372\n"
     ]
    }
   ],
   "source": [
    "# All dependencies of this notebook\n",
    "\n",
    "# third-party imports\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# local imports\n",
    "from lib.models.osdt_classifier import OSDTClassifier\n",
    "from lib.experiments.analysis import train_cross_validate\n",
    "from lib.data_structures.dataset import read_dataframe\n",
    "\n",
    "# Using COMPAS as an example\n",
    "dataset = read_dataframe('data/preprocessed/census.csv') \n",
    "(n, m) = dataset.shape\n",
    "X = dataset.values[:,:-1]\n",
    "y = dataset.values[:,-1]\n",
    "\n",
    "hyperparameters = {\n",
    "    'regularization': 0.1, # Regularization coefficient which effects the penalty on model complexity\n",
    "    'max_depth': float('Inf'), # User-specified limit on the model\n",
    "    'max_time': float('Inf'), # User-specified limit on the runtime \n",
    "    \n",
    "    'configuration': { # More configurations around toggling optimizations and prioritization options\n",
    "        'priority_metric': 'curiosity',\n",
    "        'look_ahead': True,\n",
    "        'support_lowerbound': True,\n",
    "        'incremental_accuracy_lowerbound': True,\n",
    "        'accuracy_lowerbound': True,\n",
    "        'equivalent_point_lowerbound': True,\n",
    "    }\n",
    "}\n",
    "\n",
    "model = OSDTClassifier(**hyperparameters)\n",
    "model.fit(X, y)\n",
    "prediction = model.predict(X)\n",
    "prediction = prediction.reshape(1, n)\n",
    "print('Runtime: {} Seconds'.format(time() - start))\n",
    "print('Prediction: \\n{}'.format(prediction))\n",
    "print('Training Accuracy: {}'.format(model.score(X, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
