{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Parallel OSDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 8.55211615562439 Seconds\n",
      "Prediction: \n",
      "[[0]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n",
      "Training Accuracy: 0.669031417402635\n",
      "Visualization: \n",
      "(_,_,_,0,_,_,_,_,_,_,_,0) => 0 (Risk Contribution = 0.12878746199507746)\n",
      "(_,_,_,1,_,_,_,0,_,_,_,0) => 1 (Risk Contribution = 0.022518459533806285)\n",
      "(_,_,_,1,_,_,_,1,_,_,0,0) => 0 (Risk Contribution = 0.0708751990734038)\n",
      "(_,_,_,1,_,_,_,1,_,_,1,0) => 1 (Risk Contribution = 0.022228898219197917)\n",
      "(_,_,_,_,_,_,_,_,_,_,_,1) => 1 (Risk Contribution = 0.11155856377587954)\n"
     ]
    }
   ],
   "source": [
    "# third-party imports\n",
    "from time import time\n",
    "\n",
    "# local imports\n",
    "from lib.parallel_osdt_classifier import ParallelOSDTClassifier\n",
    "from lib.data_processing import read_dataset\n",
    "\n",
    "# Using COMPAS as an example\n",
    "dataset = read_dataset('data/preprocessed/compas-binary.csv') \n",
    "(n, m) = dataset.shape\n",
    "# n = 20\n",
    "X = dataset.values[:n,:m-1]\n",
    "y = dataset.values[:n,-1]\n",
    "\n",
    "hyperparameters = {\n",
    "    'regularization': 0.005, # Regularization coefficient which effects the penalty on model complexity\n",
    "\n",
    "    'max_depth': float('Inf'), # User-specified limit on the model\n",
    "    'max_time': 60, # User-specified limit on the runtime \n",
    "\n",
    "    'clients': 1, # Parameter that varies based on how much computational resource is available\n",
    "    'servers': 1, # Parameter that varies based on how much computational resource is available\n",
    "\n",
    "    'visualize': True, # Toggle whether a rule-list visualization is rendered\n",
    "    'verbose': False, # Toggle whether event messages are printed\n",
    "    'log': False, # Toggle whether client processes log to logs/work_<id>.log files\n",
    "    'profile': False, # Toggle Snapshots for Profiling Memory Usage\n",
    "    \n",
    "    'configuration': { # More configurations around toggling optimizations and prioritization options\n",
    "        'priority_metric': 'uniform', # Decides how tasks are prioritized\n",
    "        'deprioritization': 0.01, # Decides how much to push back a task if it has pending dependencies\n",
    "\n",
    "        # Note that Leaf Permutation Bound (Theorem 6) is \n",
    "        # Toggles the assumption about objective independence when composing subtrees (Theorem 1)\n",
    "        # Disabling this actually breaks convergence due to information loss\n",
    "        'hierarchical_lowerbound': True, \n",
    "        # Toggles whether problems are pruned based on insufficient accuracy (compared to other results) (Lemma 2)\n",
    "        'look_ahead': True,\n",
    "        # Toggles whether a split is avoided based on insufficient support (proxy for accuracy gain) (Theorem 3)\n",
    "        'support_lowerbound': True,\n",
    "        # Toggles whether a split is avoided based on insufficient potential accuracy gain (Theorem 4)\n",
    "        'incremental_accuracy_lowerbound': True,\n",
    "        # Toggles whether a problem is pruned based on insufficient accuracy (in general) (Theorem 5)\n",
    "        'accuracy_lowerbound': True,\n",
    "        # Toggles whether problem equivalence is based solely on the capture set (Similar to Corollary 6)\n",
    "        'capture_equivalence': True,\n",
    "        # Hamming distance used to propagate bounding information of similar problems (Theorem 7 + some more...)\n",
    "        \"similarity_threshold\": 0,\n",
    "        # Toggles whether equivalent points contribute to the lowerbound (Proposition 8 and Theorem 9)\n",
    "        'equivalent_point_lowerbound': True,\n",
    "\n",
    "        # Toggles compression of dataset based on equivalent point aggregation\n",
    "        'equivalent_point_compression': True,\n",
    "        # Toggles whether asynchronous tasks can be cancelled after being issued\n",
    "        'task_cancellation': True,\n",
    "        # Toggles whether look_ahead prunes using objective upperbounds (This builds on top of look_ahead)\n",
    "        'interval_look_ahead': True,\n",
    "        # Cooldown timer (seconds) on synchornization operations\n",
    "        'synchronization_cooldown': 0.1,\n",
    "        # Cache Limit\n",
    "        'cache_limit': float('Inf')\n",
    "    }\n",
    "}\n",
    "\n",
    "start = time()\n",
    "model = ParallelOSDTClassifier(**hyperparameters)\n",
    "model.fit(X, y)\n",
    "print('Runtime: {} Seconds'.format(time() - start))\n",
    "print('Prediction: \\n{}'.format(model.predict(X)))\n",
    "print('Training Accuracy: {}'.format(model.score(X, y)))\n",
    "print('Visualization: \\n{}'.format(model.model.visualization))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open file handles: 0: FIFO\n",
      "1: CHR\n",
      "2: CHR\n",
      "3: CHR\n",
      "4: CHR\n",
      "5: SOCK\n",
      "6: SOCK\n",
      "7: SOCK\n",
      "8: SOCK\n",
      "9: FIFO\n",
      "10: SOCK\n",
      "11: SOCK\n",
      "12: FIFO\n",
      "13: SOCK\n",
      "14: SOCK\n",
      "15: SOCK\n",
      "16: SOCK\n",
      "17: SOCK\n",
      "18: SOCK\n",
      "19: SOCK\n",
      "20: SOCK\n",
      "21: SOCK\n",
      "22: SOCK\n",
      "23: SOCK\n",
      "24: SOCK\n",
      "25: FIFO\n",
      "26: FIFO\n",
      "27: SOCK\n",
      "28: SOCK\n",
      "29: SOCK\n",
      "30: SOCK\n",
      "31: SOCK\n",
      "32: SOCK\n",
      "33: SOCK\n",
      "34: SOCK\n",
      "35: SOCK\n",
      "36: FIFO\n",
      "37: SOCK\n",
      "38: SOCK\n",
      "39: FIFO\n",
      "40: SOCK\n",
      "41: SOCK\n",
      "42: SOCK\n",
      "43: FIFO\n",
      "44: FIFO\n",
      "45: SOCK\n",
      "46: REG\n",
      "47: REG\n",
      "48: SOCK\n",
      "49: SOCK\n",
      "50: SOCK\n",
      "51: SOCK\n",
      "52: SOCK\n",
      "53: SOCK\n",
      "54: SOCK\n",
      "55: SOCK\n",
      "56: FIFO\n",
      "72: FIFO\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import stat\n",
    "\n",
    "_fd_types = (\n",
    "    ('REG', stat.S_ISREG),\n",
    "    ('FIFO', stat.S_ISFIFO),\n",
    "    ('DIR', stat.S_ISDIR),\n",
    "    ('CHR', stat.S_ISCHR),\n",
    "    ('BLK', stat.S_ISBLK),\n",
    "    ('LNK', stat.S_ISLNK),\n",
    "    ('SOCK', stat.S_ISSOCK)\n",
    ")\n",
    "\n",
    "def fd_table_status():\n",
    "    result = []\n",
    "    for fd in range(100):\n",
    "        try:\n",
    "            s = os.fstat(fd)\n",
    "        except:\n",
    "            continue\n",
    "        for fd_type, func in _fd_types:\n",
    "            if func(s.st_mode):\n",
    "                break\n",
    "        else:\n",
    "            fd_type = str(s.st_mode)\n",
    "        result.append((fd, fd_type))\n",
    "    return result\n",
    "\n",
    "def fd_table_status_logify(fd_table_result):\n",
    "    return ('Open file handles: ' +\n",
    "            '\\n'.join(['{0}: {1}'.format(*i) for i in fd_table_result]))\n",
    "\n",
    "def fd_table_status_str():\n",
    "    return fd_table_status_logify(fd_table_status())\n",
    "\n",
    "if __name__=='__main__':\n",
    "    print(fd_table_status_str())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Sequential OSDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All dependencies of this notebook\n",
    "\n",
    "# third-party imports\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# local imports\n",
    "from lib.osdt_classifier import OSDTClassifier\n",
    "from lib.model_selection import train_cross_validate\n",
    "from lib.data_processing import read_dataset\n",
    "\n",
    "# Using COMPAS as an example\n",
    "dataset = read_dataset('data/preprocessed/compas-binary.csv') \n",
    "(n, m) = dataset.shape\n",
    "X = dataset.values[:,:-1]\n",
    "y = dataset.values[:,-1]\n",
    "\n",
    "hyperparameters = {\n",
    "    'regularization': 0.005, # Regularization coefficient which effects the penalty on model complexity\n",
    "    'max_depth': float('Inf'), # User-specified limit on the model\n",
    "    'max_time': float('Inf'), # User-specified limit on the runtime \n",
    "    \n",
    "    'configuration': { # More configurations around toggling optimizations and prioritization options\n",
    "        'priority_metric': 'curiosity',\n",
    "        'look_ahead': True,\n",
    "        'support_lowerbound': True,\n",
    "        'incremental_accuracy_lowerbound': True,\n",
    "        'accuracy_lowerbound': True,\n",
    "        'equivalent_point_lowerbound': True,\n",
    "    }\n",
    "}\n",
    "\n",
    "model = OSDTClassifier(**hyperparameters)\n",
    "model.fit(X, y)\n",
    "print('Runtime: {}'.format(time() - start))\n",
    "print('Prediction: \\n{}'.format(model.predict(X)))\n",
    "print('Training Accuracy: {}'.format(model.score(X, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
