{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Parallel OSDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 10.88456130027771 Seconds\n",
      "Prediction: \n",
      "[[0 0 1 ... 0 0 1]]\n",
      "Training Accuracy: 0.669031417402635\n",
      "Visualization: \n",
      "(_,_,_,0,_,_,_,_,_,_,_,0) => 0 (Risk Contribution = 0.12878746199507746)\n",
      "(_,_,_,1,_,_,_,0,_,_,_,0) => 1 (Risk Contribution = 0.022518459533806285)\n",
      "(_,_,_,1,_,_,_,1,_,_,0,0) => 0 (Risk Contribution = 0.0708751990734038)\n",
      "(_,_,_,1,_,_,_,1,_,_,1,0) => 1 (Risk Contribution = 0.022228898219197917)\n",
      "(_,_,_,_,_,_,_,_,_,_,_,1) => 1 (Risk Contribution = 0.11155856377587954)\n"
     ]
    }
   ],
   "source": [
    "# third-party imports\n",
    "from time import time\n",
    "\n",
    "# local imports\n",
    "from lib.models.parallel_osdt_classifier import ParallelOSDTClassifier\n",
    "from lib.data_structures.dataset import read_dataframe\n",
    "\n",
    "# Using COMPAS as an example\n",
    "dataset = read_dataframe('data/preprocessed/compas-binary.csv') \n",
    "(n, m) = dataset.shape\n",
    "X = dataset.values[:n,:m-1]\n",
    "y = dataset.values[:n,-1]\n",
    "\n",
    "hyperparameters = {\n",
    "    'regularization': 0.005, # Regularization coefficient which effects the penalty on model complexity\n",
    "\n",
    "    'max_depth': float('Inf'), # User-specified limit on the model\n",
    "    'max_time': 60, # User-specified limit on the runtime \n",
    "\n",
    "    'workers': 1, # Parameter that varies based on how much computational resource is available\n",
    "\n",
    "    'visualize': True, # Toggle whether a rule-list visualization is rendered\n",
    "    'verbose': False, # Toggle whether event messages are printed\n",
    "    'log': False, # Toggle whether client processes log to logs/work_<id>.log files\n",
    "    'profile': False, # Toggle Snapshots for Profiling Memory Usage\n",
    "    \n",
    "    'configuration': { # More configurations around toggling optimizations and prioritization options\n",
    "        'priority_metric': 'uniform', # Decides how tasks are prioritized\n",
    "        'deprioritization': 0.01, # Decides how much to push back a task if it has pending dependencies\n",
    "\n",
    "        # Note that Leaf Permutation Bound (Theorem 6) is \n",
    "        # Toggles the assumption about objective independence when composing subtrees (Theorem 1)\n",
    "        # Disabling this actually breaks convergence due to information loss\n",
    "        'hierarchical_lowerbound': True, \n",
    "        # Toggles whether problems are pruned based on insufficient accuracy (compared to other results) (Lemma 2)\n",
    "        'look_ahead': True,\n",
    "        # Toggles whether a split is avoided based on insufficient support (proxy for accuracy gain) (Theorem 3)\n",
    "        'support_lowerbound': True,\n",
    "        # Toggles whether a split is avoided based on insufficient potential accuracy gain (Theorem 4)\n",
    "        'incremental_accuracy_lowerbound': True,\n",
    "        # Toggles whether a problem is pruned based on insufficient accuracy (in general) (Theorem 5)\n",
    "        'accuracy_lowerbound': True,\n",
    "        # Toggles whether problem equivalence is based solely on the capture set (Similar to Corollary 6)\n",
    "        'capture_equivalence': True,\n",
    "        # Hamming distance used to propagate bounding information of similar problems (Theorem 7 + some more...)\n",
    "        \"similarity_threshold\": 0,\n",
    "        # Toggles whether equivalent points contribute to the lowerbound (Proposition 8 and Theorem 9)\n",
    "        'equivalent_point_lowerbound': True,\n",
    "\n",
    "        # Toggles compression of dataset based on equivalent point aggregation\n",
    "        'equivalent_point_compression': True,\n",
    "        # Toggles whether asynchronous tasks can be cancelled after being issued\n",
    "        'task_cancellation': True,\n",
    "        # Toggles whether look_ahead prunes using objective upperbounds (This builds on top of look_ahead)\n",
    "        'interval_look_ahead': True,\n",
    "        # Cooldown timer (seconds) on synchornization operations\n",
    "        'synchronization_cooldown': 0.01,\n",
    "        # Cache Limit\n",
    "        'cache_limit': float('Inf')\n",
    "    }\n",
    "}\n",
    "\n",
    "start = time()\n",
    "model = ParallelOSDTClassifier(**hyperparameters)\n",
    "model.fit(X, y)\n",
    "prediction = model.predict(X)\n",
    "prediction = prediction.reshape(1, n)\n",
    "print('Runtime: {} Seconds'.format(time() - start))\n",
    "print('Prediction: \\n{}'.format(prediction))\n",
    "print('Training Accuracy: {}'.format(model.score(X, y)))\n",
    "print('Visualization: \\n{}'.format(model.model.visualization))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Sequential OSDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All dependencies of this notebook\n",
    "\n",
    "# third-party imports\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# local imports\n",
    "from lib.models.osdt_classifier import OSDTClassifier\n",
    "from lib.experiments.analysis import train_cross_validate\n",
    "from lib.data_structures.dataset import read_dataframe\n",
    "\n",
    "# Using COMPAS as an example\n",
    "dataset = read_dataframe('data/preprocessed/compas-binary.csv') \n",
    "(n, m) = dataset.shape\n",
    "X = dataset.values[:,:-1]\n",
    "y = dataset.values[:,-1]\n",
    "\n",
    "hyperparameters = {\n",
    "    'regularization': 0.005, # Regularization coefficient which effects the penalty on model complexity\n",
    "    'max_depth': float('Inf'), # User-specified limit on the model\n",
    "    'max_time': float('Inf'), # User-specified limit on the runtime \n",
    "    \n",
    "    'configuration': { # More configurations around toggling optimizations and prioritization options\n",
    "        'priority_metric': 'curiosity',\n",
    "        'look_ahead': True,\n",
    "        'support_lowerbound': True,\n",
    "        'incremental_accuracy_lowerbound': True,\n",
    "        'accuracy_lowerbound': True,\n",
    "        'equivalent_point_lowerbound': True,\n",
    "    }\n",
    "}\n",
    "\n",
    "model = OSDTClassifier(**hyperparameters)\n",
    "prediction = model.predict(X)\n",
    "prediction = prediction.reshape(1, n)\n",
    "print('Runtime: {} Seconds'.format(time() - start))\n",
    "print('Prediction: \\n{}'.format(prediction))\n",
    "print('Training Accuracy: {}'.format(model.score(X, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
