{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#An implementation of Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import heapq\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the dataset\n",
    "df = pd.DataFrame(pd.read_csv('../data/compas-binary.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = df.as_matrix()[:,:13]\n",
    "\n",
    "y = df.as_matrix()[:,13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Association Rule Mining (Only one feature)\n",
    "\n",
    "#support\n",
    "#supp = [(x[:,i]*y).mean() for i in range(13)]\n",
    "#supp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3667168674698795,\n",
       " 0.592274678111588,\n",
       " 0.5300462249614792,\n",
       " 0.5184782608695652,\n",
       " 0.45773618016964024,\n",
       " 0.32459016393442625,\n",
       " 0.45069360675512665,\n",
       " 0.44644229291532195,\n",
       " 0.4233735747820255,\n",
       " 0.4932330827067669,\n",
       " 0.28986197049024276,\n",
       " 0.37864823348694315,\n",
       " 0.6614535418583257]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confidence\n",
    "conf1 = [sum(x_all[:,i]*y)/sum(x_all[:,i]) for i in range(13)]\n",
    "conf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.48557089084065247,\n",
       " 0.4481314432989691,\n",
       " 0.45573665707893896,\n",
       " 0.45415065976281943,\n",
       " 0.4676032110091743,\n",
       " 0.4923509759099701,\n",
       " 0.7527272727272727,\n",
       " 0.7275,\n",
       " 0.711558854718982,\n",
       " 0.45544199390353235,\n",
       " 0.5382854764877236,\n",
       " 0.4822479928635147,\n",
       " 0.37143460807099093]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confidence\n",
    "conf0 = [sum((x_all[:,i]==0)*y)/sum((x_all[:,i]==0)) for i in range(13)]\n",
    "conf0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBecause Using both conf1 and conf0 would select out too many features, \\nwhich is hard for the algorithm to run out,\\njust use conf1 to select out a small fraction of feature.\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x_idx = [conf1[i]>0.5 or conf0[i]>0.5 for i in range(len(conf1))]\n",
    "\"\"\"\n",
    "Because Using both conf1 and conf0 would select out too many features, \n",
    "which is hard for the algorithm to run out,\n",
    "just use conf1 to select out a small fraction of feature.\n",
    "\"\"\"\n",
    "#x_idx = [conf1[i]>0.5 for i in range(len(conf1))]\n",
    "#x_idx[0] = True # in the CORELS paper, gender is an important feature, so I add it manually\n",
    "#x_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select out these features\n",
    "#x = x_all[:,x_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 1],\n",
       "       ...,\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [1, 0, 0, 1, 0],\n",
       "       [1, 0, 1, 1, 0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#manaually select out 5 features, accoring to CORELS paper when lambda=0.01\n",
    "# sex:Female, age:18-20,age:21-22, juvenile-crimes:=0, priors:>3\n",
    "x_idx = [0,1,2,8,12]\n",
    "x = x_all[:,x_idx]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrule = x.shape[1]\n",
    "ndata = len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "calculate z, which is for the equivalent points bound\n",
    "z is the vector defined in algorithm 5 of the CORELS paper\n",
    "z is a binary vector indicating the data with a minority lable in its equivalent set\n",
    "\"\"\"\n",
    "z = pd.DataFrame([-1]*ndata).as_matrix()\n",
    "# enumerate through theses samples\n",
    "for i in range(ndata):\n",
    "    #if z[i,0]==-1, this sample i has not been put into its equivalent set\n",
    "    if z[i,0] == -1:\n",
    "        tag1 = np.array([True]*ndata)\n",
    "        for j in range(nrule):\n",
    "            rule_label = x[i][j]\n",
    "            #tag1 indicates which samples have exactly the same features with sample i\n",
    "            tag1 = (x[:,j] == rule_label)*tag1\n",
    "            \n",
    "        y_l = y[tag1]\n",
    "        pred = int(y_l.sum()/len(y_l) > 0.5)\n",
    "        #tag2 indicates the samples in a equiv set which have the minority label\n",
    "        tag2 = (y_l != pred)\n",
    "        z[tag1,0] = tag2\n",
    "\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcul(antecedents, x, y, points_cap=tuple()):\n",
    "    \"\"\"\n",
    "    Function for calculating the predictions, number of data captured,\n",
    "    number of data incorrectly captured by the leaves, and b0 (defined in (28) in the CORELS paper).\n",
    "    \"\"\"\n",
    "    prediction = []\n",
    "    num_captured = []\n",
    "    num_captured_incorrect = []\n",
    "    B0 = [] # b0 is defined in (28)\n",
    "    points_captured = []\n",
    "    \n",
    "    num = len(antecedents)\n",
    "    \n",
    "    for i in range(num):\n",
    "        \n",
    "        \n",
    "        if (len(points_cap)>0):\n",
    "            #when split a leaf, points_cap is the vector indicating points captured by that leaf\n",
    "            tag = np.array(points_cap)\n",
    "            rule_index = abs(antecedents[i][-1])-1\n",
    "            rule_label = int(antecedents[i][-1]>0)\n",
    "            tag = (x[:,rule_index] == rule_label)*tag\n",
    "        else:\n",
    "            #when initialize the queue\n",
    "            rule_index = abs(antecedents[i][0])-1\n",
    "            rule_label = int(antecedents[i][0]>0)\n",
    "            tag = (x[:,rule_index] == rule_label)\n",
    "        \n",
    "        points_captured.append(tag)\n",
    "        \n",
    "        # the y's of these data captured by leaf antecedents[i]\n",
    "        y_leaf = y[tag]\n",
    "        \n",
    "        #b0 is defined in (28)\n",
    "        b0 = tag.dot(z)[0]/ndata\n",
    "        B0.append(b0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        num_cap = len(y_leaf)\n",
    "        num_captured.append(num_cap)\n",
    "        \n",
    "        if len(y_leaf)>0:\n",
    "            pred = int(y_leaf.sum()/len(y_leaf) > 0.5)\n",
    "            prediction.append(pred)\n",
    "            num_cap_incor = sum(y_leaf != pred)\n",
    "            num_captured_incorrect.append(num_cap_incor)\n",
    "        else:\n",
    "            prediction.append(0)\n",
    "            num_captured_incorrect.append(0)\n",
    "\n",
    "    if num==1:\n",
    "        return prediction[0], num_captured[0], num_captured_incorrect[0], B0[0], points_captured[0]\n",
    "        \n",
    "    return prediction, num_captured, num_captured_incorrect, B0, points_captured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0]*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CacheTree:\n",
    "    \"\"\"\n",
    "    A tree data structure.\n",
    "    prefix: a 2-d tuple to encode the leaves\n",
    "    prediction: a list to record the predictions of leaves\n",
    "    num_captured: a list to record number of data captured by the leaves\n",
    "    num_captured_incorrect: a list to record number of data incorrectly captured by the leaves\n",
    "    \"\"\"\n",
    "    def __init__(self, x, y, prefix,\n",
    "                 lamb, prior_metric = None,\n",
    "                 prediction=None,\n",
    "                 num_captured=None,\n",
    "                 num_captured_incorrect=None,\n",
    "                 deadleaf = None,\n",
    "                 splitleaf = None,\n",
    "                 lbound=None,\n",
    "                 B0 = None, points_cap = None):\n",
    "        self.prefix = prefix\n",
    "        self.prediction = prediction\n",
    "        self.num_captured = num_captured\n",
    "        self.num_captured_incorrect = num_captured_incorrect\n",
    "        self.deadleaf = deadleaf #a list indicate which leaves will never be split (support bound)\n",
    "        self.splitleaf = splitleaf #a queue of lists indicating which leaves will be split in next rounds (1 for split, 0 for not split)\n",
    "        self.lbound = lbound #a list of lower bound\n",
    "        self.B0 = B0 # a list of b0\n",
    "        self.points_cap = points_cap #a 2-d list (nleaves by ndata) indicating which points are captured by each leaf\n",
    "        \n",
    "        ndata = len(y)\n",
    "        l = len(prefix)\n",
    "        if prediction==None:\n",
    "            self.prediction, self.num_captured, self.num_captured_incorrect, self.B0, self.points_cap = calcul(self.prefix, x, y)\n",
    "            self.deadleaf = [0]*l\n",
    "            self.splitleaf = [[1]*l]\n",
    "            self.lbound = [sum(self.num_captured_incorrect[:i]+self.num_captured_incorrect[i+1:])/ndata + lamb*l \n",
    "                           for i in range(l)]\n",
    "        #print(self.prefix)\n",
    "        #print(self.lbound)\n",
    "        #print(self.splitleaf)\n",
    "        # which metrics to use for the priority queue\n",
    "        if (prior_metric==\"curiosity\"):\n",
    "            self.metric = min([self.lbound[i]/((ndata-self.num_captured[i])/len(y)) \n",
    "                                  for i in range(l) if self.splitleaf[0][i]==1])\n",
    "        elif (prior_metric==\"bound\"):\n",
    "            self.metric = min([self.lbound[i]\n",
    "                                  for i in range(l) if self.splitleaf[0][i]==1])\n",
    "        elif (prior_metric==\"entropy\"): \n",
    "            self.p = [self.num_captured_incorrect[i]/self.num_captured[i] \n",
    "                      if self.num_captured[i]!=0 else 0 for i in range(l)]\n",
    "            self.entropy = [(-self.p[i]*math.log2(self.p[i])-(1-self.p[i])*math.log2(1-self.p[i]))*self.num_captured[i] \n",
    "                            if self.p[i]!=0 and self.p[i]!=1 else 0 for i in range(l)]\n",
    "            self.metric = min([sum(self.entropy[:i]+self.entropy[i+1:])/(ndata-self.num_captured[i]) for i in range(l)])\n",
    "        elif (prior_metric==\"gini\"):\n",
    "            self.p = [self.num_captured_incorrect[i]/self.num_captured[i] \n",
    "                      if self.num_captured[i]!=0 else 0 for i in range(l)]\n",
    "            self.giniindex = [(2*self.p[i]*(1-self.p[i]))*self.num_captured[i] for i in range(l)]\n",
    "            self.metric = min([sum(self.giniindex[:i]+self.giniindex[i+1:])/(ndata-self.num_captured[i]) for i in range(l)])\n",
    "        else:\n",
    "            self.metric = 0\n",
    "\n",
    "            \n",
    "    def get_prefix(self):\n",
    "        # return the encoded tree\n",
    "        return self.prefix\n",
    "    \n",
    "    def get_pred(self):\n",
    "        # return a list of length len(prefix)\n",
    "        # the predictions of all leaves\n",
    "        return self.prediction\n",
    "    \n",
    "    def get_cap(self):\n",
    "        # return a list of length len(prefix)\n",
    "        # the number of captured points of all leaves\n",
    "        return self.num_captured\n",
    "    \n",
    "    def get_ncc(self):\n",
    "        # return a list of length len(prefix)\n",
    "        # the number of incorrectly captured points of all leaves\n",
    "        return self.num_captured_incorrect\n",
    "    \n",
    "    def get_deadleaf(self):\n",
    "        # return a list of length len(prefix)\n",
    "        # indicating whether or not the leaf is dead (because of the support bound)\n",
    "        return self.deadleaf\n",
    "    \n",
    "    def get_splitleaf(self):\n",
    "        # return a queue of lists of length len(prefix)\n",
    "        # indicating whether or not the leaf will be split\n",
    "        return self.splitleaf\n",
    "    \n",
    "    def set_deadleaf(self,i):\n",
    "        # set leaf i to be dead\n",
    "        self.deadleaf[i] = 1\n",
    "        return\n",
    "    \n",
    "        \n",
    "    def get_lbound(self):\n",
    "        # return a list of length len(prefix)\n",
    "        # the lower bound of the tree with leaf i as d0, the rest as dp\n",
    "        return self.lbound\n",
    "    \n",
    "    \n",
    "    def get_metric(self):\n",
    "        # return the metric (to be used as metrics in priority queue)\n",
    "        return self.metric\n",
    "    \n",
    "    def get_B0(self):\n",
    "        # return a list of length len(prefix)\n",
    "        # b0\n",
    "        return self.B0\n",
    "    \n",
    "    def get_pc(self):\n",
    "        # return a list of length len(prefix)\n",
    "        # points captured\n",
    "        return self.points_cap\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        # define <, which will be used in the priority queue\n",
    "        return self.metric<other.metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cache every leaf\n",
    "\n",
    "class CacheLeaf:\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, prediction=None,\n",
    "                 num_captured=None,\n",
    "                 num_captured_incorrect=None,\n",
    "                 B0 = None, \n",
    "                 points_cap = None):\n",
    "        self.prediction = prediction\n",
    "        self.num_captured = num_captured\n",
    "        self.num_captured_incorrect = num_captured_incorrect\n",
    "        self.B0 = B0 # a list of b0\n",
    "        self.points_cap = points_cap #a 2-d list (nleaves by ndata) indicating which points are captured by each leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Eliminate:\n",
    "    \"\"\"\n",
    "    A data structure to record and identify\n",
    "    whether a tree has been visited/pruned\n",
    "    \"\"\"\n",
    "    def __init__(self, elim_dict = None):\n",
    "        self.elim_dict = {} # record these trees we have visited\n",
    "        \n",
    "    def eliminate(self, prefix):\n",
    "        self.elim_dict[tuple(sorted(prefix))] = 1\n",
    "        \n",
    "    def is_duplicated(self, prefix):\n",
    "        # if a tree is in the self.elim_dict, then we have already visited it\n",
    "        if tuple(sorted(prefix)) in self.elim_dict.keys():\n",
    "            #print(\"Eliminated!\")\n",
    "            return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Risk(tree,ndata):\n",
    "    return tree.get_lbound()[0]+(tree.get_ncc()[0])/ndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(lines, lamb, tic, queue_size, prefix_old, tree_new, R, d_c, R_c):\n",
    "    \"log\"\n",
    "    t = tree_new.get_prefix()\n",
    "    t_c = d_c.get_prefix()\n",
    "    \n",
    "    the_time = str(time.time()-tic)\n",
    "    the_queue_size = str(queue_size)\n",
    "    the_split_tree = str(prefix_old)\n",
    "    the_new_tree = str(t)\n",
    "    the_new_tree_length = str(len(t))\n",
    "    the_new_tree_pred = str(tree_new.get_pred())\n",
    "    the_new_tree_objective = str(R)\n",
    "    the_best_tree = str(t_c)\n",
    "    the_length = str(len(t_c))\n",
    "    the_pred = str(d_c.get_pred())\n",
    "    the_obj = str(R_c)\n",
    "    the_lbound = str(d_c.get_lbound())\n",
    "    the_accuracy = str(1-(R_c - lamb*len(t_c)))\n",
    "    the_num_cap = str(d_c.get_cap())\n",
    "    the_num_cap_inc = str(d_c.get_ncc())\n",
    "\n",
    "\n",
    "    line = \";\".join([the_time, the_queue_size, the_split_tree, \n",
    "                     the_new_tree, the_new_tree_length, the_new_tree_pred,the_new_tree_objective,\n",
    "                     the_best_tree, the_length, the_pred, the_obj, \n",
    "                     the_lbound, the_accuracy, the_num_cap, the_num_cap_inc])\n",
    "    lines.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5, 6)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(np.sum(([1],[5],[6]), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbound(x, y, lamb, prior_metric = None, MAXDEPTH = 4, niter=float('Inf')):\n",
    "    \"\"\"\n",
    "    An implementation of Algorithm\n",
    "    ## one copy of tree\n",
    "    ## mark which leaves to be split\n",
    "    \"\"\"\n",
    "    \n",
    "    #Initialize best rule list and objective\n",
    "    d_c = None\n",
    "    R_c = 1\n",
    "\n",
    "    nrule = x.shape[1]\n",
    "    ndata = len(y)\n",
    "    print(\"nrule:\", nrule)\n",
    "    print(\"ndata:\", ndata)\n",
    "    \n",
    "    E = Eliminate()\n",
    "    tic = time.time()\n",
    "    \n",
    "    lines = [] # a list for log\n",
    "    leaves = {} # cache leaves\n",
    "\n",
    "    # initialize the queue to include all trees of just one split\n",
    "    queue = []\n",
    "    for r in range(1, nrule+1):\n",
    "        tree0 = CacheTree(prefix = ((-r,),(r,)), x = x, y = y, lamb=lamb, prior_metric=prior_metric)\n",
    "        heapq.heappush(queue, (tree0.get_metric(),tree0))\n",
    "        #queue.append(tree0)\n",
    "        R = Risk(tree0,ndata)\n",
    "        if R<R_c:\n",
    "            d_c = tree0\n",
    "            R_c = R\n",
    "\n",
    "        #log(lines, lamb, tic, len(queue), tuple(), tree0, R, d_c, R_c) \n",
    "    \n",
    "    COUNT = nrule #count the total number of trees in the queue\n",
    "    while (queue) and COUNT<niter:\n",
    "        #tree = queue.pop(0)\n",
    "        (curio, tree)=heapq.heappop(queue)\n",
    "        d = tree.get_prefix()\n",
    "        \n",
    "        \n",
    "        #print(\"=======COUNT=======\",COUNT)\n",
    "        #print(\"d\",d)\n",
    "        #print(\"R\",tree.get_lbound()[0]+(tree.get_ncc()[0])/len(y))\n",
    "        \n",
    "        # if we have visited this tree\n",
    "        if E.is_duplicated(d):\n",
    "            continue\n",
    "        else:\n",
    "            E.eliminate(d)\n",
    "        \n",
    "        # the leaves we are going to split\n",
    "        split_next = tree.get_splitleaf().copy()\n",
    "        spl = split_next.pop(0)\n",
    "        \n",
    "        # enumerate through all the leaves\n",
    "        for i in range(len(d)):\n",
    "            # if the leaf is dead, then continue\n",
    "            if tree.get_deadleaf()[i]==1:\n",
    "                continue\n",
    "            \n",
    "            #(Lower bound on antecedent support)\n",
    "            # if this bound doesnot hold, set the leaf to be dead, and continue\n",
    "            if tree.get_cap()[i]/ndata/2 < lamb:\n",
    "                tree.set_deadleaf(i)\n",
    "                #print(\"==============dead==============\",i)\n",
    "                continue\n",
    "            \n",
    "            # 0 for not split; 1 for split\n",
    "            #if spl[0][i]==0:\n",
    "            if spl[i]==0:\n",
    "                continue\n",
    "\n",
    "            d0 = d[i] #d0 is the leaf we are going to split\n",
    "            dp = d[:i]+d[i+1:] #dp is the rest\n",
    "            \n",
    "            \n",
    "            # Restrict the depth of the tree\n",
    "            if len(d0)>=MAXDEPTH:\n",
    "                continue\n",
    "            \n",
    "            # we are going to split leaf i, and get 2 new leaves\n",
    "            # we will add the two new leaves to the end of the list\n",
    "            splitleaf_list = [split_next[k][:i]+split_next[k][i+1:]+split_next[k][i:i+1]*2\n",
    "                              for k in range(len(split_next))]\n",
    "            \n",
    "            \n",
    "            \n",
    "            lb = tree.get_lbound()[i] # the lower bound \n",
    "            b0 = tree.get_B0()[i] # the b0 defined in (28) of the paper\n",
    "            \n",
    "            \n",
    "            \n",
    "            # split the leaf d0 with feature j\n",
    "            for j in range(1, nrule+1):\n",
    "                if (j not in d0)and(-j not in d0):\n",
    "                    # split leaf d0 with feature j, and get 2 leaves l1 and l2\n",
    "                    l1 = d0+(-j,)\n",
    "                    l2 = d0+(j,)\n",
    "                    t = dp+(l1, l2) # t is the new tree\n",
    "                    #print(\"t\",t)\n",
    "\n",
    "                    # if tree t is duplicated, continue\n",
    "                    if E.is_duplicated(t):\n",
    "                        continue\n",
    "                    \n",
    "                    pred_l = [0]*2\n",
    "                    cap_l = [0]*2\n",
    "                    incorr_l = [0]*2\n",
    "                    B0_l = [0]*2\n",
    "                    points_l = [[0]*ndata]*2\n",
    "                    \n",
    "                    # for the two new leaves, calculate their predictions, \n",
    "                    # num of data captured, num of data incorrectly captured, and b0\n",
    "                    l1_sorted = tuple(sorted(l1))\n",
    "                    l2_sorted = tuple(sorted(l2))\n",
    "                    Cache_l1 = leaves.get(l1_sorted, None)\n",
    "                    Cache_l2 = leaves.get(l2_sorted, None)\n",
    "                    \n",
    "                    i_points = tree.get_pc()[i]\n",
    "                    \n",
    "                    \n",
    "                    if Cache_l1 != None:\n",
    "                        pred_l[0], cap_l[0], incorr_l[0], B0_l[0], points_l[0] = Cache_l1.prediction, Cache_l1.num_captured, Cache_l1.num_captured_incorrect, Cache_l1.B0, Cache_l1.points_cap\n",
    "                    else:\n",
    "                        pred_l[0], cap_l[0], incorr_l[0], B0_l[0], points_l[0] = calcul((l1,),x,y,i_points)\n",
    "                        leaves[l1_sorted] = CacheLeaf(pred_l[0], cap_l[0], incorr_l[0], B0_l[0], points_l[0])\n",
    "                    \n",
    "                    if Cache_l2 != None:\n",
    "                        pred_l[1], cap_l[1], incorr_l[1], B0_l[1], points_l[1] = Cache_l2.prediction, Cache_l2.num_captured, Cache_l2.num_captured_incorrect, Cache_l2.B0, Cache_l2.points_cap\n",
    "                    else:\n",
    "                        pred_l[1], cap_l[1], incorr_l[1], B0_l[1], points_l[1] = calcul((l2,),x,y,i_points)\n",
    "                        leaves[l2_sorted] = CacheLeaf(pred_l[1], cap_l[1], incorr_l[1], B0_l[1], points_l[1])\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    # calculate the bounds for each leaves in the new tree\n",
    "                    loss_l1 = (incorr_l[0])/ndata\n",
    "                    loss_l2 = (incorr_l[1])/ndata\n",
    "                    loss_d0 = tree.get_ncc()[i]/ndata\n",
    "                    delta = loss_l1+loss_l2-loss_d0+lamb\n",
    "                    old_lbound = tree.get_lbound()[:i]+tree.get_lbound()[i+1:]\n",
    "                    new_lbound = [b+delta for b in old_lbound]+[tree.get_lbound()[i]+loss_l2+lamb,tree.get_lbound()[i]+loss_l1+lamb]\n",
    "                    \n",
    "                    splitleaf_array = np.array(splitleaf_list)\n",
    "                    sl = splitleaf_list.copy()\n",
    "                        \n",
    "                    #(Lower bound on accurate antecedent support)\n",
    "                    a_l = (sum(cap_l)-sum(incorr_l))/ndata - sum(cap_l)/ndata/2\n",
    "                    \n",
    "                    #binary vector indicating split or not\n",
    "                    splitleaf1 = [1]*(len(t)) #all leaves labeled as to be split\n",
    "                    splitleaf2 = [0]*(len(t)-2)+[1,1] #l1,l2 labeled as to be split\n",
    "                    splitleaf3 = [1]*(len(t)-2)+[0,0] #dp labeled as to be split\n",
    "                    \n",
    "                    if lb+b0+lamb>=R_c or lb>=R_c:\n",
    "                        # if equivalent points bound combined with the lookahead bound doesn't hold\n",
    "                        # or if the hierarchical objective lower bound doesn't hold\n",
    "                        # we need to split at least one leaf in dp\n",
    "                        \n",
    "                        if a_l < lamb:\n",
    "                        # if the bound doesn't hold, we need to split the leaf l1/l2 further\n",
    "                            \n",
    "                            if len(splitleaf_list)>0:\n",
    "                                split_l1_l2 = splitleaf_array[:,-1].sum()+splitleaf_array[:,-2].sum()\n",
    "                                \n",
    "                                # if dp will have been split\n",
    "                                if splitleaf_array.sum()-split_l1_l2>0:\n",
    "                                    \n",
    "                                    # if l1/l2 will have been split\n",
    "                                    if split_l1_l2>0:\n",
    "                                        sl.append(splitleaf1)\n",
    "                                    \n",
    "                                    # if l1/l2 will not have been split, we need to split l1/l2\n",
    "                                    else:\n",
    "                                        sl.append(splitleaf2)\n",
    "                                \n",
    "                                # and we need to split leaves in dp, if dp will not have been split\n",
    "                                else:\n",
    "                                    \n",
    "                                    # if l1/l2 will have been split\n",
    "                                    if split_l1_l2>0:\n",
    "                                        sl.append(splitleaf3)\n",
    "                                    \n",
    "                                    # if l1/l2 will not have been split, we need to split l1/l2\n",
    "                                    else:\n",
    "                                        sl.append(splitleaf2)\n",
    "                                        sl.append(splitleaf3)\n",
    "                            else:\n",
    "                                sl.append(splitleaf2)\n",
    "                                sl.append(splitleaf3)\n",
    "                                \n",
    "                            \n",
    "                        else:\n",
    "                            \n",
    "                            if len(splitleaf_list)>0:\n",
    "                                split_l1_l2 = splitleaf_array[:,-1].sum()+splitleaf_array[:,-2].sum()\n",
    "                                \n",
    "                                # if dp will have been split\n",
    "                                if splitleaf_array.sum()-split_l1_l2>0:\n",
    "                                    sl.append(splitleaf1)\n",
    "                                \n",
    "                                # and we need to split leaves in dp, if dp will not have been split\n",
    "                                else:\n",
    "                                    sl.append(splitleaf3)\n",
    "                            else:\n",
    "                                sl.append(splitleaf3)\n",
    "                    else:\n",
    "                        \n",
    "                        if a_l < lamb:\n",
    "                            # if the bound doesn't hold, we need to split the leaf l1/l2 further\n",
    "                            \n",
    "                            \n",
    "                            if len(splitleaf_list)>0:\n",
    "                                split_l1_l2 = splitleaf_array[:,-1].sum()+splitleaf_array[:,-2].sum()\n",
    "                                \n",
    "                                # if l1/l2 will have been split\n",
    "                                if split_l1_l2>0:\n",
    "                                    sl.append(splitleaf1)\n",
    "                                    \n",
    "                                # if l1/l2 will not have been split, we need to split l1/l2\n",
    "                                else:\n",
    "                                    sl.append(splitleaf2)\n",
    "                            else:\n",
    "                                sl.append(splitleaf2)\n",
    "                                \n",
    "                        else:\n",
    "                            sl.append(splitleaf1)\n",
    "                    \n",
    "                    #construct the new tree\n",
    "                    tree_new = CacheTree(x = x, y = y, prefix = t,\n",
    "                                         prediction = tree.get_pred()[:i]+tree.get_pred()[i+1:]+pred_l,\n",
    "                                         num_captured = tree.get_cap()[:i]+tree.get_cap()[i+1:]+cap_l,\n",
    "                                         num_captured_incorrect = tree.get_ncc()[:i]+tree.get_ncc()[i+1:]+incorr_l,\n",
    "                                         deadleaf = tree.get_deadleaf()[:i]+tree.get_deadleaf()[i+1:]+[0,0],\n",
    "                                         splitleaf = sl,\n",
    "                                         lbound = new_lbound,\n",
    "                                         B0 = tree.get_B0()[:i]+tree.get_B0()[i+1:]+B0_l,\n",
    "                                         lamb = lamb,\n",
    "                                         prior_metric=prior_metric,\n",
    "                                         points_cap = tree.get_pc()[:i]+tree.get_pc()[i+1:]+points_l\n",
    "                                        )\n",
    "\n",
    "                    #queue.append(tree_new)\n",
    "                    heapq.heappush(queue, (tree_new.get_metric(),tree_new))\n",
    "                    R = Risk(tree_new,ndata)\n",
    "                    if R<R_c:\n",
    "                        d_c = tree_new\n",
    "                        R_c = R\n",
    "                    \n",
    "                    COUNT = COUNT+1\n",
    "                    \n",
    "                    #log(lines, lamb, tic, len(queue), d, tree_new, R, d_c, R_c)\n",
    "                    \n",
    "                   \n",
    "                \n",
    "                \n",
    "    header = ['time', 'queue_size', 'split_tree', 'new_tree', 'new_tree_length', 'new_tree_prediction', 'new_tree_objective',\n",
    "              'best_tree', 'best_tree_length', 'prediction', 'objective', 'lower_bound', 'accuracy', \n",
    "              'num_captured', 'num_captured_incorrect']\n",
    "    \n",
    "    fname = \"_\".join([str(nrule),str(ndata),prior_metric,str(lamb),\".txt\"])\n",
    "    f = open(fname, 'w')\n",
    "    f.write('%s\\n' % \";\".join(header))\n",
    "    f.write('\\n'.join(lines))\n",
    "    f.close()\n",
    "\n",
    "\n",
    "    print(\"d_c\", d_c.get_prefix())\n",
    "    print(\"R_c\", R_c)\n",
    "    print(\"COUNT\", COUNT)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### compas-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nrule: 5\n",
      "ndata: 6907\n",
      "d_c ((5,), (-5, -4), (-5, 4))\n",
      "R_c 0.3748675256985667\n",
      "COUNT 1987326\n",
      "         176918722 function calls in 1135.408 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "  1987326    3.962    0.000    3.962    0.000 <ipython-input-14-87578bc8ffa3>:102(get_metric)\n",
      "  4981775    9.346    0.000    9.346    0.000 <ipython-input-14-87578bc8ffa3>:106(get_B0)\n",
      "  5961963   11.115    0.000   11.115    0.000 <ipython-input-14-87578bc8ffa3>:111(get_pc)\n",
      "  9379008   22.981    0.000   22.981    0.000 <ipython-input-14-87578bc8ffa3>:116(__lt__)\n",
      "        5    0.000    0.000    0.000    0.000 <ipython-input-14-87578bc8ffa3>:34(<listcomp>)\n",
      "  1987326   66.692    0.000   95.309    0.000 <ipython-input-14-87578bc8ffa3>:41(<listcomp>)\n",
      "  1987327    4.036    0.000    4.036    0.000 <ipython-input-14-87578bc8ffa3>:61(get_prefix)\n",
      "  3974642    7.560    0.000    7.560    0.000 <ipython-input-14-87578bc8ffa3>:65(get_pred)\n",
      " 12144580   22.003    0.000   22.003    0.000 <ipython-input-14-87578bc8ffa3>:70(get_cap)\n",
      "  7949289   15.410    0.000   15.410    0.000 <ipython-input-14-87578bc8ffa3>:75(get_ncc)\n",
      " 13962200   25.251    0.000   25.251    0.000 <ipython-input-14-87578bc8ffa3>:80(get_deadleaf)\n",
      "   910001    1.782    0.000    1.782    0.000 <ipython-input-14-87578bc8ffa3>:85(get_splitleaf)\n",
      "  1987326   47.806    0.000  156.308    0.000 <ipython-input-14-87578bc8ffa3>:9(__init__)\n",
      "  2362324    5.022    0.000    5.022    0.000 <ipython-input-14-87578bc8ffa3>:90(set_deadleaf)\n",
      " 10943743   20.037    0.000   20.037    0.000 <ipython-input-14-87578bc8ffa3>:96(get_lbound)\n",
      "  4128024   36.207    0.000   65.002    0.000 <ipython-input-15-6992533a1f2b>:12(is_duplicated)\n",
      "        1    0.000    0.000    0.000    0.000 <ipython-input-15-6992533a1f2b>:6(__init__)\n",
      "   910001    5.271    0.000    9.137    0.000 <ipython-input-15-6992533a1f2b>:9(eliminate)\n",
      "  1987326   16.364    0.000   23.605    0.000 <ipython-input-16-bf32e23cb85b>:1(Risk)\n",
      "        1  508.472  508.472 1134.947 1134.947 <ipython-input-79-311f944d0a02>:1(bbound)\n",
      "  1987321    7.314    0.000    7.314    0.000 <ipython-input-79-311f944d0a02>:144(<listcomp>)\n",
      "  1007133    4.077    0.000    4.077    0.000 <ipython-input-79-311f944d0a02>:85(<listcomp>)\n",
      "      193    0.020    0.000    0.600    0.003 <ipython-input-80-8867b146913d>:1(calcul)\n",
      "      188    0.001    0.000    0.001    0.000 <ipython-input-82-8d566c88eb75>:7(__init__)\n",
      "        1    0.461    0.461 1135.408 1135.408 <string>:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 _bootlocale.py:23(getpreferredencoding)\n",
      "  5181002   17.256    0.000   56.795    0.000 _methods.py:31(_sum)\n",
      "        1    0.000    0.000    0.000    0.000 codecs.py:185(__init__)\n",
      "       22    0.000    0.000    0.001    0.000 iostream.py:195(schedule)\n",
      "       20    0.000    0.000    0.000    0.000 iostream.py:300(_is_master_process)\n",
      "       20    0.000    0.000    0.000    0.000 iostream.py:313(_schedule_flush)\n",
      "       20    0.000    0.000    0.002    0.000 iostream.py:366(write)\n",
      "       22    0.000    0.000    0.000    0.000 iostream.py:93(_event_pipe)\n",
      "       22    0.000    0.000    0.000    0.000 socket.py:333(send)\n",
      "       22    0.000    0.000    0.000    0.000 threading.py:1062(_wait_for_tstate_lock)\n",
      "       22    0.000    0.000    0.000    0.000 threading.py:1104(is_alive)\n",
      "       22    0.000    0.000    0.000    0.000 threading.py:506(is_set)\n",
      "  1987326   44.131    0.000   66.070    0.000 {built-in method _heapq.heappop}\n",
      "  1987326    7.588    0.000    8.630    0.000 {built-in method _heapq.heappush}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _locale.nl_langinfo}\n",
      "      198    0.000    0.000    0.000    0.000 {built-in method builtins.abs}\n",
      "        1    0.000    0.000 1135.408 1135.408 {built-in method builtins.exec}\n",
      "       20    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
      " 33854372   56.325    0.000   56.325    0.000 {built-in method builtins.len}\n",
      "  1987326    6.219    0.000    6.219    0.000 {built-in method builtins.min}\n",
      "        5    0.000    0.000    0.002    0.000 {built-in method builtins.print}\n",
      "  9012667   37.699    0.000   37.699    0.000 {built-in method builtins.sorted}\n",
      "  5962161   15.482    0.000   15.482    0.000 {built-in method builtins.sum}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method io.open}\n",
      "  1987509   19.071    0.000   19.071    0.000 {built-in method numpy.core.multiarray.array}\n",
      "       20    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method time.time}\n",
      "       22    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "       22    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "  2147326    3.993    0.000    3.993    0.000 {method 'append' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'close' of '_io.TextIOWrapper' objects}\n",
      "  2897322    5.480    0.000    5.480    0.000 {method 'copy' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "      198    0.007    0.000    0.007    0.000 {method 'dot' of 'numpy.ndarray' objects}\n",
      "  3974642    8.782    0.000    8.782    0.000 {method 'get' of 'dict' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}\n",
      "  4128024    7.239    0.000    7.239    0.000 {method 'keys' of 'dict' objects}\n",
      "   910001    2.157    0.000    2.157    0.000 {method 'pop' of 'list' objects}\n",
      "  5181002   39.540    0.000   39.540    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "  5181002   23.247    0.000   80.042    0.000 {method 'sum' of 'numpy.ndarray' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'write' of '_io.TextIOWrapper' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cProfile.run(\"bbound(x[:,:], y, lamb=0.01, prior_metric=\\\"curiosity\\\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nrule: 5\n",
      "ndata: 6907\n",
      "d_c ((-4,), (4, -5), (4, 5))\n",
      "R_c 0.3748675256985667\n",
      "COUNT 961709\n",
      "         105676267 function calls in 661.616 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "   961709    1.967    0.000    1.967    0.000 <ipython-input-14-87578bc8ffa3>:102(get_metric)\n",
      "  2972513    5.527    0.000    5.527    0.000 <ipython-input-14-87578bc8ffa3>:106(get_B0)\n",
      "  2885112    5.346    0.000    5.346    0.000 <ipython-input-14-87578bc8ffa3>:111(get_pc)\n",
      "   163704    0.417    0.000    0.417    0.000 <ipython-input-14-87578bc8ffa3>:116(__lt__)\n",
      "        5    0.000    0.000    0.000    0.000 <ipython-input-14-87578bc8ffa3>:34(<listcomp>)\n",
      "   961709    8.694    0.000    8.694    0.000 <ipython-input-14-87578bc8ffa3>:53(<listcomp>)\n",
      "   961709   13.851    0.000   13.851    0.000 <ipython-input-14-87578bc8ffa3>:55(<listcomp>)\n",
      "   961709   50.257    0.000   87.845    0.000 <ipython-input-14-87578bc8ffa3>:56(<listcomp>)\n",
      "   961710    1.911    0.000    1.911    0.000 <ipython-input-14-87578bc8ffa3>:61(get_prefix)\n",
      "  1923408    3.582    0.000    3.582    0.000 <ipython-input-14-87578bc8ffa3>:65(get_pred)\n",
      "  9915867   17.748    0.000   17.748    0.000 <ipython-input-14-87578bc8ffa3>:70(get_cap)\n",
      "  3846821    7.356    0.000    7.356    0.000 <ipython-input-14-87578bc8ffa3>:75(get_ncc)\n",
      " 12119691   21.634    0.000   21.634    0.000 <ipython-input-14-87578bc8ffa3>:80(get_deadleaf)\n",
      "   943936    1.760    0.000    1.760    0.000 <ipython-input-14-87578bc8ffa3>:85(get_splitleaf)\n",
      "   961709   24.963    0.000  141.881    0.000 <ipython-input-14-87578bc8ffa3>:9(__init__)\n",
      "  2046598    4.296    0.000    4.296    0.000 <ipython-input-14-87578bc8ffa3>:90(set_deadleaf)\n",
      "  5857630   10.751    0.000   10.751    0.000 <ipython-input-14-87578bc8ffa3>:96(get_lbound)\n",
      "  3206580   26.559    0.000   47.163    0.000 <ipython-input-15-6992533a1f2b>:12(is_duplicated)\n",
      "        1    0.000    0.000    0.000    0.000 <ipython-input-15-6992533a1f2b>:6(__init__)\n",
      "   943936    5.266    0.000    9.164    0.000 <ipython-input-15-6992533a1f2b>:9(eliminate)\n",
      "   961709    7.808    0.000   11.318    0.000 <ipython-input-16-bf32e23cb85b>:1(Risk)\n",
      "        1  274.203  274.203  661.443  661.443 <ipython-input-79-311f944d0a02>:1(bbound)\n",
      "   961704    3.386    0.000    3.386    0.000 <ipython-input-79-311f944d0a02>:144(<listcomp>)\n",
      "  1049105    3.809    0.000    3.809    0.000 <ipython-input-79-311f944d0a02>:85(<listcomp>)\n",
      "      193    0.020    0.000    0.605    0.003 <ipython-input-80-8867b146913d>:1(calcul)\n",
      "      188    0.001    0.000    0.001    0.000 <ipython-input-82-8d566c88eb75>:7(__init__)\n",
      "        1    0.173    0.173  661.616  661.616 <string>:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 _bootlocale.py:23(getpreferredencoding)\n",
      "  2198027    7.338    0.000   24.435    0.000 _methods.py:31(_sum)\n",
      "        1    0.000    0.000    0.000    0.000 codecs.py:185(__init__)\n",
      "       22    0.000    0.000    0.001    0.000 iostream.py:195(schedule)\n",
      "       20    0.000    0.000    0.000    0.000 iostream.py:300(_is_master_process)\n",
      "       20    0.000    0.000    0.000    0.000 iostream.py:313(_schedule_flush)\n",
      "       20    0.000    0.000    0.002    0.000 iostream.py:366(write)\n",
      "       22    0.000    0.000    0.000    0.000 iostream.py:93(_event_pipe)\n",
      "       22    0.000    0.000    0.000    0.000 socket.py:333(send)\n",
      "       22    0.000    0.000    0.000    0.000 threading.py:1062(_wait_for_tstate_lock)\n",
      "       22    0.000    0.000    0.000    0.000 threading.py:1104(is_alive)\n",
      "       22    0.000    0.000    0.000    0.000 threading.py:506(is_set)\n",
      "   961709    4.964    0.000    5.318    0.000 {built-in method _heapq.heappop}\n",
      "   961709    3.668    0.000    3.730    0.000 {built-in method _heapq.heappush}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _locale.nl_langinfo}\n",
      "      198    0.000    0.000    0.000    0.000 {built-in method builtins.abs}\n",
      "        1    0.000    0.000  661.616  661.616 {built-in method builtins.exec}\n",
      "       20    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
      " 11184964   17.690    0.000   17.690    0.000 {built-in method builtins.len}\n",
      "   961709    3.118    0.000    3.118    0.000 {built-in method builtins.min}\n",
      "        5    0.000    0.000    0.002    0.000 {built-in method builtins.print}\n",
      "  6073924   24.898    0.000   24.898    0.000 {built-in method builtins.sorted}\n",
      " 13292042   45.265    0.000   45.265    0.000 {built-in method builtins.sum}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method io.open}\n",
      "   961892    9.048    0.000    9.048    0.000 {built-in method numpy.core.multiarray.array}\n",
      "       20    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method time.time}\n",
      "       22    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "       22    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "  1135025    2.027    0.000    2.027    0.000 {method 'append' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'close' of '_io.TextIOWrapper' objects}\n",
      "  1905640    3.467    0.000    3.467    0.000 {method 'copy' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "      198    0.007    0.000    0.007    0.000 {method 'dot' of 'numpy.ndarray' objects}\n",
      "  1923408    4.186    0.000    4.186    0.000 {method 'get' of 'dict' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}\n",
      "  3206580    5.469    0.000    5.469    0.000 {method 'keys' of 'dict' objects}\n",
      "   943936    2.148    0.000    2.148    0.000 {method 'pop' of 'list' objects}\n",
      "  2198027   17.098    0.000   17.098    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "  2198027    9.938    0.000   34.373    0.000 {method 'sum' of 'numpy.ndarray' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'write' of '_io.TextIOWrapper' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cProfile.run(\"bbound(x[:,:], y, lamb=0.01, prior_metric=\\\"gini\\\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nrule: 3\n",
      "ndata: 6907\n",
      "d_c ((3,), (-3, -2), (-3, 2))\n",
      "R_c 0.3748675256985667\n",
      "COUNT 104\n",
      "CPU times: user 148 ms, sys: 4 ms, total: 152 ms\n",
      "Wall time: 150 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#all data\n",
    "\n",
    "bbound(x[:,2:], y, lamb=0.01, prior_metric=\"curiosity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#all data, 5 features\n",
    "\n",
    "bbound(x, y, lamb=0.01, prior_metric=\"bound\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#all data, 5 features\n",
    "\n",
    "bbound(x, y, lamb=0.01, prior_metric=\"entropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#all data, 5 features\n",
    "\n",
    "bbound(x, y, lamb=0.01, prior_metric=\"gini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
