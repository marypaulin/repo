{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#An implementation of Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import heapq\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the dataset\n",
    "df = pd.DataFrame(pd.read_csv('../data/compas-binary.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.as_matrix()[:,:13]\n",
    "\n",
    "y = df.as_matrix()[:,13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Association Rule Mining (Only one feature)\n",
    "\n",
    "#support\n",
    "#supp = [(x[:,i]*y).mean() for i in range(13)]\n",
    "#supp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3667168674698795,\n",
       " 0.592274678111588,\n",
       " 0.5300462249614792,\n",
       " 0.5184782608695652,\n",
       " 0.45773618016964024,\n",
       " 0.32459016393442625,\n",
       " 0.45069360675512665,\n",
       " 0.44644229291532195,\n",
       " 0.4233735747820255,\n",
       " 0.4932330827067669,\n",
       " 0.28986197049024276,\n",
       " 0.37864823348694315,\n",
       " 0.6614535418583257]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confidence\n",
    "conf1 = [sum(x[:,i]*y)/sum(x[:,i]) for i in range(13)]\n",
    "conf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.48557089084065247,\n",
       " 0.4481314432989691,\n",
       " 0.45573665707893896,\n",
       " 0.45415065976281943,\n",
       " 0.4676032110091743,\n",
       " 0.4923509759099701,\n",
       " 0.7527272727272727,\n",
       " 0.7275,\n",
       " 0.711558854718982,\n",
       " 0.45544199390353235,\n",
       " 0.5382854764877236,\n",
       " 0.4822479928635147,\n",
       " 0.37143460807099093]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confidence\n",
    "conf0 = [sum((x[:,i]==0)*y)/sum((x[:,i]==0)) for i in range(13)]\n",
    "conf0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x_idx = [conf1[i]>0.5 or conf0[i]>0.5 for i in range(len(conf1))]\n",
    "\"\"\"\n",
    "Because Using both conf1 and conf0 would select out too many features, \n",
    "which is hard for the algorithm to run out,\n",
    "we just use conf1 to select out a small fraction of feature.\n",
    "\"\"\"\n",
    "x_idx = [conf1[i]>0.5 for i in range(len(conf1))]\n",
    "x_idx[0] = True # in the CORELS paper, gender is an important feature, so I add it manually\n",
    "x_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select out these features\n",
    "x = x[:,x_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrule = x.shape[1]\n",
    "ndata = len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "calculate z, which is for the equivalent points bound\n",
    "z is the vector defined in algorithm 5 of the CORELS paper\n",
    "z is a binary vector indicating the data with a minority lable in its equivalent set\n",
    "\"\"\"\n",
    "z = pd.DataFrame([-1]*ndata).as_matrix()\n",
    "# enumerate through theses samples\n",
    "for i in range(ndata):\n",
    "    #if z[i]==-1, this sample i has not been put into its equivalent set\n",
    "    if z[i] == -1:\n",
    "        tag1 = np.array([True]*ndata)\n",
    "        for j in range(nrule):\n",
    "            rule_label = x[i][j]\n",
    "            #tag1 indicates which samples have exactly the same features with sample i\n",
    "            tag1 = (x[:,j] == rule_label)*tag1\n",
    "            \n",
    "        y_l = y[tag1]\n",
    "        pred = int(y_l.sum()/len(y_l) > 0.5)\n",
    "        #tag2 indicates the samples in a equiv set which have the minority label\n",
    "        tag2 = (y_l != pred)\n",
    "        z[tag1,0] = tag2\n",
    "\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcul(prefix, x, y):\n",
    "    \"\"\"\n",
    "    Function for calculating the predictions, number of data captured,\n",
    "    number of data incorrectly captured by the leaves, and b0 (defined in (28) in the CORELS paper).\n",
    "    \"\"\"\n",
    "    prediction = []\n",
    "    num_captured = []\n",
    "    num_captured_incorrect = []\n",
    "    B0 = [] # b0 is defined in (28)\n",
    "    for i in range(len(prefix)):\n",
    "        tag = np.array([True]*ndata)\n",
    "        for j in range(len(prefix[i])):\n",
    "            rule_index = abs(prefix[i][j])-1\n",
    "            rule_label = int(prefix[i][j]>0)\n",
    "            tag = (x[:,rule_index] == rule_label)*tag\n",
    "            \n",
    "        # the y's of these data captured by leaf prefix[i]\n",
    "        y_leaf = y[tag]\n",
    "        \n",
    "        #b0 is defined in (28)\n",
    "        b0 = tag.dot(z)[0]/ndata\n",
    "        B0.append(b0)\n",
    "        \n",
    "        num_cap = len(y_leaf)\n",
    "        num_captured.append(num_cap)\n",
    "        \n",
    "        if len(y_leaf)>0:\n",
    "            pred = int(y_leaf.sum()/len(y_leaf) > 0.5)\n",
    "            prediction.append(pred)\n",
    "            num_cap_incor = sum(y_leaf != pred)\n",
    "            num_captured_incorrect.append(num_cap_incor)\n",
    "        else:\n",
    "            prediction.append(0)\n",
    "            num_captured_incorrect.append(0)\n",
    "        \n",
    "    return prediction, num_captured, num_captured_incorrect, B0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CacheTree:\n",
    "    \"\"\"\n",
    "    A tree data structure.\n",
    "    prefix: a 2-d tuple to encode the leaves\n",
    "    prediction: a list to record the predictions of leaves\n",
    "    num_captured: a list to record number of data captured by the leaves\n",
    "    num_captured_incorrect: a list to record number of data incorrectly captured by the leaves\n",
    "    \"\"\"\n",
    "    def __init__(self, x, y, prefix,\n",
    "                 lamb, prior_metric = None,\n",
    "                 prediction=None,\n",
    "                 num_captured=None,\n",
    "                 num_captured_incorrect=None,\n",
    "                 deadleaf = None,\n",
    "                 splitleaf = None,\n",
    "                 lbound=None,\n",
    "                 B0 = None):\n",
    "        self.prefix = prefix\n",
    "        self.prediction = prediction\n",
    "        self.num_captured = num_captured\n",
    "        self.num_captured_incorrect = num_captured_incorrect\n",
    "        self.deadleaf = deadleaf #a list indicate which leaves will never be split (support bound)\n",
    "        self.splitleaf = splitleaf #a queue of list indicating which leaves will be split\n",
    "        self.lbound = lbound #a list of lower bound\n",
    "        self.B0 = B0 # a list of b0\n",
    "        \n",
    "        ndata = len(y)\n",
    "        l = len(prefix)\n",
    "        if prediction==None:\n",
    "            self.prediction, self.num_captured, self.num_captured_incorrect, self.B0 = calcul(self.prefix, x, y)\n",
    "            self.deadleaf = [0]*l\n",
    "            self.splitleaf = [[1]*l]\n",
    "            self.lbound = [sum(self.num_captured_incorrect[:i]+self.num_captured_incorrect[i+1:])/ndata + lamb*l \n",
    "                           for i in range(l)]\n",
    "        \n",
    "        # which metrics to use for the priority queue\n",
    "        if (prior_metric==\"curiosity\"):\n",
    "            self.curiosity = min([self.lbound[i]/((ndata-self.num_captured[i])/len(y)) \n",
    "                                  for i in range(l) if self.splitleaf[0][i]==1])\n",
    "        elif (prior_metric==\"bound\"):\n",
    "            self.curiosity = min([self.lbound[i]\n",
    "                                  for i in range(l) if self.splitleaf[0][i]==1])\n",
    "        elif (prior_metric==\"entropy\"): \n",
    "            self.p = [self.num_captured_incorrect[i]/self.num_captured[i] \n",
    "                      if self.num_captured[i]!=0 else 0 for i in range(l)]\n",
    "            self.entropy = [(-self.p[i]*math.log2(self.p[i])-(1-self.p[i])*math.log2(1-self.p[i]))*self.num_captured[i] \n",
    "                            if self.p[i]!=0 and self.p[i]!=1 else 0 for i in range(l)]\n",
    "            self.curiosity = min([sum(self.entropy[:i]+self.entropy[i+1:])/(ndata-self.num_captured[i]) for i in range(l)])\n",
    "        elif (prior_metric==\"gini\"):\n",
    "            self.p = [self.num_captured_incorrect[i]/self.num_captured[i] \n",
    "                      if self.num_captured[i]!=0 else 0 for i in range(l)]\n",
    "            self.giniindex = [(2*self.p[i]*(1-self.p[i]))*self.num_captured[i] for i in range(l)]\n",
    "            self.curiosity = min([sum(self.giniindex[:i]+self.giniindex[i+1:])/(ndata-self.num_captured[i]) for i in range(l)])\n",
    "        else:\n",
    "            self.curiosity = 0\n",
    "\n",
    "            \n",
    "    def get_prefix(self):\n",
    "        # return the encoded tree\n",
    "        return self.prefix\n",
    "    \n",
    "    def get_pred(self):\n",
    "        # return a list of length len(prefix)\n",
    "        # the predictions of all leaves\n",
    "        return self.prediction\n",
    "    \n",
    "    def get_cap(self):\n",
    "        # return a list of length len(prefix)\n",
    "        # the number of captured points of all leaves\n",
    "        return self.num_captured\n",
    "    \n",
    "    def get_ncc(self):\n",
    "        # return a list of length len(prefix)\n",
    "        # the number of incorrectly captured points of all leaves\n",
    "        return self.num_captured_incorrect\n",
    "    \n",
    "    def get_deadleaf(self):\n",
    "        # return a list of length len(prefix)\n",
    "        # indicating whether or not the leaf is dead (because of the support bound)\n",
    "        return self.deadleaf\n",
    "    \n",
    "    def get_splitleaf(self):\n",
    "        # return a queue of lists of length len(prefix)\n",
    "        # indicating whether or not the leaf will be split\n",
    "        return self.splitleaf\n",
    "    \n",
    "    def set_deadleaf(self,i):\n",
    "        # set leaf i to be dead\n",
    "        self.deadleaf[i] = 1\n",
    "        return\n",
    "    \n",
    "        \n",
    "    def get_lbound(self):\n",
    "        # return a list of length len(prefix)\n",
    "        # the lower bound of the tree with leaf i as d0, the rest as dp\n",
    "        return self.lbound\n",
    "    \n",
    "    \n",
    "    def get_curiosity(self):\n",
    "        # return the curiosity (to be used as metrics in priority queue)\n",
    "        return self.curiosity\n",
    "    \n",
    "    def get_B0(self):\n",
    "        # return a list of length len(prefix)\n",
    "        # b0\n",
    "        return self.B0\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        # define <, which will be used in the priority queue\n",
    "        return self.curiosity<other.curiosity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Eliminate:\n",
    "    \"\"\"\n",
    "    A data structure to record and identify\n",
    "    whether a tree has been visited/pruned\n",
    "    \"\"\"\n",
    "    def __init__(self, elim_dict = None, \n",
    "                 eliminated = None):\n",
    "        self.elim_dict = {} # record these trees we have visited\n",
    "        \n",
    "    def eliminate(self, prefix):\n",
    "        self.elim_dict[tuple(sorted(prefix))] = 1\n",
    "        \n",
    "    def is_duplicated(self, prefix):\n",
    "        # if a tree is in the self.elim_dict, then we have already visited it\n",
    "        if tuple(sorted(prefix)) in self.elim_dict.keys():\n",
    "            #print(\"Eliminated!\")\n",
    "            return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Risk(tree,ndata,lamb):\n",
    "    return tree.get_lbound()[0]+(tree.get_ncc()[0])/ndata+lamb*len(tree.get_prefix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbound(x, y, lamb, prior_metric = None, MAXDEPTH = 4):\n",
    "    \"\"\"\n",
    "    An implementation of Algorithm\n",
    "    ## one copy of tree\n",
    "    ## mark which leaves to split\n",
    "    \"\"\"\n",
    "    \n",
    "    d_c = None # the tree with the smallest risk\n",
    "    R_c = 1 # the smallest risk\n",
    "\n",
    "    nrule = x.shape[1]\n",
    "    ndata = len(y)\n",
    "    print(\"nrule:\", nrule)\n",
    "    print(\"ndata:\", ndata)\n",
    "\n",
    "    # initialize the queue to include all trees of just one split\n",
    "    queue = []\n",
    "    for r in range(1, nrule+1):\n",
    "        tree0 = CacheTree(prefix = ((-r,),(r,)), x = x, y = y, lamb=lamb, prior_metric=prior_metric)\n",
    "        heapq.heappush(queue, (tree0.get_curiosity(),tree0))\n",
    "        \"queue.append(tree0)\"\n",
    "        R = Risk(tree0,ndata,lamb)\n",
    "        if R<R_c:\n",
    "            d_c = tree0.get_prefix()\n",
    "            R_c = R\n",
    "    \n",
    "    E = Eliminate()\n",
    "    \n",
    "    COUNT = 0 #count the total number of trees in the queue\n",
    "    while (queue):\n",
    "        \"tree = queue.pop(0)\"\n",
    "        (curio, tree)=heapq.heappop(queue)\n",
    "        d = tree.get_prefix()\n",
    "        \n",
    "        COUNT = COUNT+1\n",
    "        #print(\"=======COUNT=======\",COUNT)\n",
    "        #print(\"d\",d)\n",
    "        #print(\"R\",tree.get_lbound()[0]+(tree.get_ncc()[0])/len(y))\n",
    "        \n",
    "        # if we have visited this tree or it has been pruned\n",
    "        if E.is_duplicated(d):\n",
    "            continue\n",
    "        else:\n",
    "            E.eliminate(d)\n",
    "        \n",
    "        # enumerate through all the leaves\n",
    "        for i in range(len(d)):\n",
    "            # if the leaf is dead, then continue\n",
    "            if tree.get_deadleaf()[i]==1:\n",
    "                continue\n",
    "            \n",
    "            #(Lower bound on antecedent support)\n",
    "            # if this bound doesnot hold, set the leaf to be dead, and continue\n",
    "            if tree.get_cap()[i]/ndata/2 < lamb:\n",
    "                tree.set_deadleaf(i)\n",
    "                #print(\"==============dead==============\",i)\n",
    "                continue\n",
    "            \n",
    "            # the leaves we are going to split\n",
    "            spl = tree.get_splitleaf()\n",
    "            split_next = spl[1:] # the leaves to be split after this round\n",
    "            \n",
    "            # 0 for not split; 1 for split\n",
    "            if spl[0][i]==0:\n",
    "                continue\n",
    "\n",
    "            # we are going to split leaf i, and get 2 new leaves\n",
    "            # we will add the two new leaves to the end of the list\n",
    "            splitleaf_list = [split_next[k][:i]+split_next[k][i+1:]+split_next[k][i]*2\n",
    "                              for k in range(len(split_next))]\n",
    "            \n",
    "            d0 = d[i] #d0 is the leaf we are going to split\n",
    "            dp = d[:i]+d[i+1:] #dp is the rest\n",
    "            \n",
    "            \n",
    "            # Restrict the depth of the tree\n",
    "            if len(d0)>=MAXDEPTH:\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            lb = tree.get_lbound()[i] # the lower bound \n",
    "            b0 = tree.get_B0()[i] # the b0 defined in (28) of the paper\n",
    "            \n",
    "            #The equivalent points bound+look ahead bound and the hierarchical objective lower bound\n",
    "            if lb+b0+lamb>=R_c or lb>=R_c:\n",
    "                # split the leaf d0 with feature j\n",
    "                for j in range(1, nrule+1):\n",
    "                    if (j not in d0)and(-j not in d0):\n",
    "                        # split leaf d0 with feature j, and get 2 leaves l1 and l2\n",
    "                        l1 = d0+(-j,)\n",
    "                        l2 = d0+(j,)\n",
    "                        t = dp+(l1, l2) # t is the new tree\n",
    "                        #print(\"t\",t)\n",
    "                        \n",
    "                        # if tree t is duplicated, continue\n",
    "                        if E.is_duplicated(t):\n",
    "                            continue\n",
    "                        \n",
    "                        # for the two new leaves, calculate their predictions, \n",
    "                        # num of data captured, num of data incorrectly captured, and b0\n",
    "                        pred_l, cap_l, incorr_l, B0_l = calcul((l1,l2),x,y)\n",
    "                        \n",
    "                        # calculate the bounds for each leaves in the new tree\n",
    "                        loss_l1 = (incorr_l[0])/len(y)\n",
    "                        loss_l2 = (incorr_l[1])/len(y)\n",
    "                        loss_d0 = tree.get_ncc()[i]/len(y)\n",
    "                        delta = loss_l1+loss_l2-loss_d0+lamb\n",
    "                        old_lbound = tree.get_lbound()[:i]+tree.get_lbound()[i+1:]\n",
    "                        new_lbound = [b+delta for b in old_lbound]+[tree.get_lbound()[i]+loss_l2+lamb,tree.get_lbound()[i]+loss_l1+lamb]\n",
    "                        \n",
    "                        #binary vector indicating split or not\n",
    "                        splitleaf1 = [1]*(len(t)) #all leaves labeled as to be split\n",
    "                        splitleaf2 = [0]*(len(t)-2)+[1,1] #l1,l2 labeled as to be split\n",
    "                        splitleaf3 = [1]*(len(t)-2)+[0,0] #dp labeled as to be split\n",
    "                        \n",
    "                        splitleaf_array = np.array(splitleaf_list)\n",
    "                        \n",
    "                        #(Lower bound on accurate antecedent support)\n",
    "                        a_l = (sum(cap_l)-sum(incorr_l))/ndata - sum(cap_l)/ndata/2\n",
    "                        \n",
    "                        if a_l < lamb:\n",
    "                        # if the bound doesn't hold, we need to split the leaf l1/l2 further\n",
    "                            \n",
    "                            if len(splitleaf_list)>0:\n",
    "                                split_l1_l2 = splitleaf_array[:,-1].sum()+splitleaf_array[:,-2].sum()\n",
    "                                \n",
    "                                # if dp will have been split\n",
    "                                if splitleaf_array.sum()-split_l1_l2>0:\n",
    "                                    \n",
    "                                    # if l1/l2 will have been split\n",
    "                                    if split_l1_l2>0:\n",
    "                                        sl = splitleaf_list+[splitleaf1]\n",
    "                                    \n",
    "                                    # if l1/l2 will not have been split, we need to split l1/l2\n",
    "                                    else:\n",
    "                                        sl = splitleaf_list+[splitleaf2]\n",
    "                                \n",
    "                                # and we need to split leaves in dp, if dp will not have been split\n",
    "                                else:\n",
    "                                    \n",
    "                                    # if l1/l2 will have been split\n",
    "                                    if split_l1_l2>0:\n",
    "                                        sl = splitleaf_list+[splitleaf3]\n",
    "                                    \n",
    "                                    # if l1/l2 will not have been split, we need to split l1/l2\n",
    "                                    else:\n",
    "                                        sl = splitleaf_list+[splitleaf2]+[splitleaf3]\n",
    "                                \n",
    "                                \n",
    "                            \n",
    "                        else:\n",
    "                            \n",
    "                            if len(splitleaf_list)>0:\n",
    "                                split_l1_l2 = splitleaf_array[:,-1].sum()+splitleaf_array[:,-2].sum()\n",
    "                                \n",
    "                                # if dp will have been split\n",
    "                                if splitleaf_array.sum()-split_l1_l2>0:\n",
    "                                    sl = splitleaf_list+[splitleaf1]\n",
    "                                \n",
    "                                # and we need to split leaves in dp, if dp will not have been split\n",
    "                                else:\n",
    "                                    sl = splitleaf_list+[splitleaf3]\n",
    "                                    \n",
    "                        \n",
    "                        #construct the new tree\n",
    "                        tree_new = CacheTree(x = x, y = y, prefix = t,\n",
    "                                             prediction = tree.get_pred()[:i]+tree.get_pred()[i+1:]+pred_l,\n",
    "                                             num_captured = tree.get_cap()[:i]+tree.get_cap()[i+1:]+cap_l,\n",
    "                                             num_captured_incorrect = tree.get_ncc()[:i]+tree.get_ncc()[i+1:]+incorr_l,\n",
    "                                             deadleaf = tree.get_deadleaf()[:i]+tree.get_deadleaf()[i+1:]+[0,0],\n",
    "                                             splitleaf = sl,\n",
    "                                             lbound = new_lbound,\n",
    "                                             B0 = tree.get_B0()[:i]+tree.get_B0()[i+1:]+B0_l,\n",
    "                                             lamb = lamb,\n",
    "                                             prior_metric=prior_metric\n",
    "                                            )\n",
    "                       \n",
    "                        \"queue.append(tree_new)\"\n",
    "                        heapq.heappush(queue, (tree_new.get_curiosity(),tree_new))\n",
    "                        R = Risk(tree_new,ndata,lamb)\n",
    "                        if R<R_c:\n",
    "                            d_c = t\n",
    "                            R_c = R\n",
    "                        \n",
    "            else:\n",
    "                # split the leaf d0 with feature j\n",
    "                for j in range(1, nrule+1):\n",
    "                    if (j not in d0)and(-j not in d0):\n",
    "                        # split leaf d0 with feature j, and get 2 leaves l1 and l2\n",
    "                        l1 = d0+(-j,)\n",
    "                        l2 = d0+(j,)\n",
    "                        t = dp+(l1, l2) # t is the new tree\n",
    "                        #print(\"t\",t)\n",
    "                        \n",
    "                        # if tree t is duplicated, continue\n",
    "                        if E.is_duplicated(t):\n",
    "                            continue\n",
    "                        \n",
    "                        # for the two new leaves, calculate their predictions, \n",
    "                        # num of data captured, num of data incorrectly captured, and b0\n",
    "                        pred_l, cap_l, incorr_l, B0_l = calcul((l1,l2),x,y)\n",
    "                        \n",
    "                        # calculate the bounds for each leaves in the new tree\n",
    "                        loss_l1 = (incorr_l[0])/len(y)\n",
    "                        loss_l2 = (incorr_l[1])/len(y)\n",
    "                        loss_d0 = tree.get_ncc()[i]/len(y)\n",
    "                        delta = loss_l1+loss_l2-loss_d0+lamb\n",
    "                        old_lbound = tree.get_lbound()[:i]+tree.get_lbound()[i+1:]\n",
    "                        new_lbound = [b+delta for b in old_lbound]+[tree.get_lbound()[i]+loss_l2+lamb,tree.get_lbound()[i]+loss_l1+lamb]\n",
    "                        \n",
    "                        #binary vector indicating split or not\n",
    "                        splitleaf1 = [1]*len(t) #all leaves labeled as to be split\n",
    "                        splitleaf2 = [0]*(len(t)-2)+[1,1] #l1,l2 labeled as to be split\n",
    "                        \n",
    "                        splitleaf_array = np.array(splitleaf_list)\n",
    "                        \n",
    "                        #(Lower bound on accurate antecedent support)\n",
    "                        a_l = (sum(cap_l)-sum(incorr_l))/ndata - sum(cap_l)/ndata/2\n",
    "                        if a_l < lamb:\n",
    "                            # if the bound doesn't hold, we need to split the leaf l1/l2 further\n",
    "                            \n",
    "                            \n",
    "                            if len(splitleaf_list)>0:\n",
    "                                split_l1_l2 = splitleaf_array[:,-1].sum()+splitleaf_array[:,-2].sum()\n",
    "                                \n",
    "                                # if l1/l2 will have been split\n",
    "                                if split_l1_l2>0:\n",
    "                                    sl = splitleaf_list+[splitleaf1]\n",
    "                                    \n",
    "                                # if l1/l2 will not have been split, we need to split l1/l2\n",
    "                                else:\n",
    "                                    sl = splitleaf_list+[splitleaf2]\n",
    "                                \n",
    "                        else:\n",
    "                            sl = splitleaf_list+[splitleaf1]\n",
    "                        \n",
    "                        #construct the new tree\n",
    "                        tree_new = CacheTree(x = x, y = y, prefix = t,\n",
    "                                             prediction = tree.get_pred()[:i]+tree.get_pred()[i+1:]+pred_l,\n",
    "                                             num_captured = tree.get_cap()[:i]+tree.get_cap()[i+1:]+cap_l,\n",
    "                                             num_captured_incorrect = tree.get_ncc()[:i]+tree.get_ncc()[i+1:]+incorr_l,\n",
    "                                             deadleaf = tree.get_deadleaf()[:i]+tree.get_deadleaf()[i+1:]+[0,0],\n",
    "                                             splitleaf = sl,\n",
    "                                             lbound = new_lbound,\n",
    "                                             B0 = tree.get_B0()[:i]+tree.get_B0()[i+1:]+B0_l,\n",
    "                                             lamb = lamb,\n",
    "                                             prior_metric=prior_metric\n",
    "                                            )\n",
    "\n",
    "                        \"queue.append(tree_new)\"\n",
    "                        heapq.heappush(queue, (tree_new.get_curiosity(),tree_new))\n",
    "                        R = Risk(tree_new,ndata,lamb)\n",
    "                        if R<R_c:\n",
    "                            d_c = t\n",
    "                            R_c = R\n",
    "\n",
    "\n",
    "    print(\"d_c\", d_c)\n",
    "    print(\"R_c\", R_c)\n",
    "    print(\"COUNT\", COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### compas-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "bbound() missing 1 required positional argument: 'lamb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: bbound() missing 1 required positional argument: 'lamb'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 4 rules, all data, lambda = 0.0025############\n",
    "\n",
    "bbound(x[:,1:],y,prior_metric=\"curiosity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nrule: 3\n",
      "ndata: 6907\n",
      "[]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-7d5dccf0a89a>\u001b[0m in \u001b[0;36mbbound\u001b[0;34m(x, y, lamb, prior_metric, MAXDEPTH)\u001b[0m\n\u001b[1;32m    147\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplitleaf_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m                             \u001b[0msplit_l1_l2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplitleaf_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msplitleaf_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplitleaf_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msplitleaf_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msplit_l1_l2\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# algorithm1_2splits, 3 rules, all data, lambda = 0.0025############\n",
    "\n",
    "bbound(x[:,2:], y, lamb=0.04, prior_metric=\"curiosity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nrule: 5\n",
      "ndata: 6907\n",
      "d_c ((-5,), (5,))\n",
      "R_c 0.5210829593166353\n",
      "COUNT 55005\n",
      "CPU times: user 3min 31s, sys: 24 ms, total: 3min 31s\n",
      "Wall time: 3min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# algorithm1_2splits, 5 rules, all data, lambda = 0.04\n",
    "\n",
    "bbound(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dddd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
