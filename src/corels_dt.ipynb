{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import heapq\n",
    "import math\n",
    "import time\n",
    "\n",
    "import gmpy2\n",
    "from gmpy2 import mpz\n",
    "import re\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "import cProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the dataset\n",
    "df = pd.DataFrame(pd.read_csv('../data/compas-binary.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = df.as_matrix()[:,:13]\n",
    "\n",
    "y = df.as_matrix()[:,13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Association Rule Mining (Only one feature)\n",
    "\n",
    "#support\n",
    "#supp = [(x[:,i]*y).mean() for i in range(13)]\n",
    "#supp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confidence\n",
    "#conf1 = [sum(x_all[:,i]*y)/sum(x_all[:,i]) for i in range(13)]\n",
    "#conf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confidence\n",
    "#conf0 = [sum((x_all[:,i]==0)*y)/sum((x_all[:,i]==0)) for i in range(13)]\n",
    "#conf0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_idx = [conf1[i]>=0.5 or conf0[i]>=0.5 for i in range(len(conf1))]\n",
    "\n",
    "# Because Using both conf1 and conf0 would select out too many features, \n",
    "#which is hard for the algorithm to run out,\n",
    "# just use conf1 to select out a small fraction of feature.\n",
    "#x_idx = [conf1[i]>=0.5 for i in range(len(conf1))]\n",
    "#x_idx[0] = True # in the CORELS paper, gender is an important feature, so I add it manually\n",
    "#x_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select out these features\n",
    "#x = x_all[:,x_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 1],\n",
       "       ...,\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 1, 0],\n",
       "       [1, 0, 1, 1, 0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#manaually select out 5 features, accoring to CORELS paper when lambda=0.01\n",
    "## sex:Female, age:18-20,age:21-22, juvenile-crimes:=0, priors:>3\n",
    "##x_idx = [0,1,2,8,12]\n",
    "\n",
    "# sex:Female, age:18-20,age:21-22, priors:2-3, priors:>3\n",
    "x_idx = [0,1,2,9,12]\n",
    "x = x_all[:,x_idx]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 1],\n",
       "       ...,\n",
       "       [0, 0, 0, 1, 0, 0],\n",
       "       [1, 0, 0, 1, 1, 0],\n",
       "       [1, 0, 1, 1, 1, 0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#manaually select out 6 features, accoring to CORELS paper when lambda=0.01\n",
    "# sex:Female, age:18-20,age:21-22, juvenile-crimes:=0, priors:2-3, priors:>3\n",
    "x_idx6 = [0,1,2,8,9,12]\n",
    "x6 = x_all[:,x_idx6]\n",
    "x6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrule = x.shape[1]\n",
    "ndata = len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3520089764007529"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accu = clf.score(x,y)\n",
    "nleaves = (clf.tree_.node_count+1)/2\n",
    "R_c = 1-accu + 0.001*nleaves\n",
    "R_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "print(clf.tree_.node_count) #get the node count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "calculate z, which is for the equivalent points bound\n",
    "z is the vector defined in algorithm 5 of the CORELS paper\n",
    "z is a binary vector indicating the data with a minority lable in its equivalent set\n",
    "\"\"\"\n",
    "z = pd.DataFrame([-1]*ndata).as_matrix()\n",
    "# enumerate through theses samples\n",
    "for i in range(ndata):\n",
    "    #if z[i,0]==-1, this sample i has not been put into its equivalent set\n",
    "    if z[i,0] == -1:\n",
    "        tag1 = np.array([True]*ndata)\n",
    "        for j in range(nrule):\n",
    "            rule_label = x[i][j]\n",
    "            #tag1 indicates which samples have exactly the same features with sample i\n",
    "            tag1 = (x[:,j] == rule_label)*tag1\n",
    "            \n",
    "        y_l = y[tag1]\n",
    "        pred = int(y_l.sum()/len(y_l) >= 0.5)\n",
    "        #tag2 indicates the samples in a equiv set which have the minority label\n",
    "        tag2 = (y_l != pred)\n",
    "        z[tag1,0] = tag2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without similar support bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import heapq\n",
    "import math\n",
    "import time\n",
    "\n",
    "from rule import make_all_ones, make_zeros, rule_vand, rule_vectompz\n",
    "\n",
    "class CacheTree:\n",
    "    \"\"\"\n",
    "    A tree data structure.\n",
    "    leaves: a 2-d tuple to encode the leaves\n",
    "    num_captured: a list to record number of data captured by the leaves\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ndata, leaves,\n",
    "                 prior_metric=None,\n",
    "                 splitleaf=None,\n",
    "                 lbound=None\n",
    "                 ):\n",
    "        self.leaves = leaves\n",
    "        # a queue of lists indicating which leaves will be split in next rounds\n",
    "        # (1 for split, 0 for not split)\n",
    "        self.splitleaf = splitleaf\n",
    "        self.lbound = lbound  # a list of lower bound\n",
    "\n",
    "        l = len(leaves)\n",
    "\n",
    "        self.risk = self.lbound[0] + (leaves[0].p * leaves[0].num_captured) / ndata\n",
    "\n",
    "        # which metrics to use for the priority queue\n",
    "        if leaves[0].num_captured == ndata:\n",
    "            # this case is when constructing the null tree ((),)\n",
    "            self.metric = 0\n",
    "        elif prior_metric == \"curiosity\":\n",
    "            self.metric = min([self.lbound[i] / ((ndata - leaves[i].num_captured) / ndata)\n",
    "                               if leaves[i].is_dead == 0 else float('Inf') for i in range(l)])\n",
    "        elif prior_metric == \"bound\":\n",
    "            self.metric = min([self.lbound[i] if leaves[i].is_dead == 0 else float('Inf') for i in range(l)])\n",
    "        elif prior_metric == \"entropy\":\n",
    "            # entropy weighted by number of points captured\n",
    "            self.entropy = [(-leaves[i].p * math.log2(leaves[i].p) - (1 - leaves[i].p) * math.log2(1 - leaves[i].p)) * leaves[i].num_captured\n",
    "                            if leaves[i].p != 0 and leaves[i].p != 1 else 0 for i in range(l)]\n",
    "            self.metric = min([sum(self.entropy[:i] + self.entropy[i + 1:]) / (ndata - leaves[i].num_captured)\n",
    "                               if leaves[i].is_dead == 0 else float('Inf') for i in range(l)])\n",
    "        elif prior_metric == \"gini\":\n",
    "            # gini index weighted by number of points captured\n",
    "            self.giniindex = [(2 * leaves[i].p * (1 - leaves[i].p))\n",
    "                              * leaves[i].num_captured for i in range(l)]\n",
    "            self.metric = min([sum(self.giniindex[:i] + self.giniindex[i + 1:]) / (ndata - leaves[i].num_captured)\n",
    "                               if leaves[i].is_dead == 0 else float('Inf') for i in range(l)])\n",
    "        elif prior_metric == \"objective\":\n",
    "            self.metric = self.risk\n",
    "\n",
    "    def sorted_leaves(self):\n",
    "        # Used by the cache\n",
    "        return tuple(sorted(leaf.rules for leaf in self.leaves))\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        # define <, which will be used in the priority queue\n",
    "        return self.metric < other.metric\n",
    "\"\"\"\n",
    "    def _to_nested_dict(self):\n",
    "        tree = {}\n",
    "\n",
    "        for i, leaf in enumerate(self.leaves):\n",
    "            current_node = tree\n",
    "\n",
    "            for rule in leaf:\n",
    "                current_node['rule'] = abs(rule)\n",
    "                direction = 'left' if rule < 0 else 'right'\n",
    "                if direction not in current_node:\n",
    "                    current_node[direction] = {}\n",
    "                current_node = current_node[direction]\n",
    "\n",
    "            current_node['label'] = self.leaves[i].prediction\n",
    "\n",
    "        return tree\n",
    "\n",
    "    def _format_dict(self, tree, depth=0):\n",
    "        fmt = '-' * depth\n",
    "\n",
    "        if 'rule' in tree:\n",
    "            fmt += 'r{}'.format(tree['rule'])\n",
    "        else:\n",
    "            assert 'label' in tree\n",
    "            fmt += str(tree['label'])\n",
    "\n",
    "        fmt += '\\n'\n",
    "\n",
    "        if 'left' in tree:\n",
    "            fmt += self._format_dict(tree['left'], depth + 1)\n",
    "\n",
    "        if 'right' in tree:\n",
    "            fmt += self._format_dict(tree['right'], depth + 1)\n",
    "\n",
    "        return fmt\n",
    "\n",
    "    def __str__(self):\n",
    "        return self._format_dict(self._to_nested_dict())\n",
    "\"\"\"\n",
    "\n",
    "class CacheLeaf:\n",
    "    \"\"\"\n",
    "    A data structure to cache every single leaf (symmetry aware)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, rules, y, z, points_cap, num_captured, lamb, support):\n",
    "        self.rules = rules\n",
    "        self.points_cap = points_cap\n",
    "        self.num_captured = num_captured\n",
    "\n",
    "        # the y's of these data captured by leaf antecedent[0]\n",
    "        #y_leaf = y[tag]\n",
    "        # print(\"tag\",tag)\n",
    "        # print(\"y\",y)\n",
    "        _, num_ones = rule_vand(points_cap, rule_vectompz(y))\n",
    "\n",
    "        #b0 is defined in (28)\n",
    "\n",
    "        tag_z = rule_vectompz(z.reshape(1, -1)[0])\n",
    "        _, num_errors = rule_vand(points_cap, tag_z)\n",
    "        self.B0 = num_errors / len(y)\n",
    "\n",
    "        if self.num_captured:\n",
    "            self.prediction = int(num_ones / self.num_captured >= 0.5)\n",
    "            if self.prediction == 1:\n",
    "                self.num_captured_incorrect = self.num_captured - num_ones\n",
    "            else:\n",
    "                self.num_captured_incorrect = num_ones\n",
    "            self.p = self.num_captured_incorrect / self.num_captured\n",
    "        else:\n",
    "            self.prediction = 0\n",
    "            self.num_captured_incorrect = 0\n",
    "            self.p = 0\n",
    "\n",
    "        # Lower bound on antecedent support\n",
    "        if support == True:\n",
    "            self.is_dead = self.num_captured / len(y) / 2 < lamb\n",
    "        else:\n",
    "            self.is_dead = 0\n",
    "\n",
    "        self.loss = float(self.num_captured_incorrect) / len(y)\n",
    "\n",
    "\n",
    "\n",
    "def log(lines, COUNT_POP, COUNT, queue, metric, R_c, tree_old, tree_new,sorted_new_tree_rules):\n",
    "    \"log\"\n",
    "\n",
    "    the_count_pop = str(COUNT_POP)\n",
    "    the_count = str(COUNT)\n",
    "    the_queue_size = str(len(queue))\n",
    "    the_metric = str(metric)\n",
    "    the_Rc = str(R_c)\n",
    "    \n",
    "    the_old_tree = str(sorted([leaf.rules for leaf in tree_old.leaves]))\n",
    "    the_old_tree_splitleaf = str(tree_old.splitleaf)\n",
    "    the_new_tree = str(list(sorted_new_tree_rules))\n",
    "    the_new_tree_splitleaf = str(tree_new.splitleaf)\n",
    "    \n",
    "    the_new_tree_objective = str(tree_new.risk)\n",
    "    the_new_tree_lbound = str(min(tree_new.lbound))\n",
    "    the_new_tree_length = str(len(tree_new.leaves))\n",
    "    the_new_tree_depth = str(max([len(leaf.rules) for leaf in tree_new.leaves]))\n",
    "\n",
    "    the_queue = str([[ leaf.rules for leaf in thetree.leaves]  for _,thetree in queue])\n",
    "    \n",
    "    line = \";\".join([the_count_pop, the_count, the_queue_size, the_metric, the_Rc,\n",
    "                     the_old_tree, the_old_tree_splitleaf, the_new_tree, the_new_tree_splitleaf,\n",
    "                     the_new_tree_objective, the_new_tree_lbound, the_new_tree_length, the_new_tree_depth,\n",
    "                     the_queue\n",
    "                    ])\n",
    "    lines.append(line)\n",
    "\n",
    "\n",
    "def generate_new_splitleaf(tree_new_leaves, sorted_new_tree_rules, leaf_cache, splitleaf_list, ndata, nleaves, lamb, R_c, accu_support, equiv_points, lookahead):\n",
    "    \"\"\"\n",
    "    generate the new splitleaf for the new tree\n",
    "    \"\"\"\n",
    "    tree_new_rules = [leaf.rules for leaf in tree_new_leaves]\n",
    "    \n",
    "    found = False\n",
    "    for r1 in sorted_new_tree_rules:\n",
    "        for j in range(len(r1)):\n",
    "            r2 = tuple(sorted(r1[:j]+(-r1[j],)+r1[j+1:]))\n",
    "            r0 = r1[:j]+r1[j+1:]\n",
    "            #print(\"r1:\",r1)\n",
    "            #print(\"r2:\",r2)\n",
    "            #print(\"sorted_tree_new_rules\",sorted_tree_new_rules)\n",
    "            if r2 in sorted_new_tree_rules and r0 in leaf_cache:\n",
    "                l1 = r1\n",
    "                l2 = r2\n",
    "                l0 = r0\n",
    "                found = True\n",
    "                break\n",
    "                #print(\"l1\",l1)\n",
    "        if found == True:\n",
    "            break\n",
    "    \n",
    "    idx1 = tree_new_rules.index(l1)\n",
    "    idx2 = tree_new_rules.index(l2)\n",
    "    \n",
    "    cap_l = [tree_new_leaves[idx1].points_cap, tree_new_leaves[idx2].points_cap]\n",
    "    incorr_l = [tree_new_leaves[idx1].num_captured_incorrect, tree_new_leaves[idx2].num_captured_incorrect]\n",
    "    lb = sum([leaf.loss for leaf in tree_new_leaves]) - tree_new_leaves[idx1].loss - tree_new_leaves[idx2].loss + lamb*(len(tree_new_leaves)-1)\n",
    "    \n",
    "    #print(\"l1\",l1)\n",
    "    #print(\"l2\",l2)\n",
    "    #print(\"l0\",l0)\n",
    "    #print(\"leaf_cache\",leaf_cache)\n",
    "    b0 = leaf_cache[l0].B0\n",
    "    \n",
    "    splitleaf_array = np.array(splitleaf_list)\n",
    "    sl = splitleaf_list.copy()\n",
    "\n",
    "    #(Lower bound on accurate antecedent support)\n",
    "    a_l = (sum(cap_l) - sum(incorr_l)) / ndata - sum(cap_l) / ndata / 2\n",
    "    if accu_support==False:\n",
    "        a_l = float('Inf')\n",
    "\n",
    "    # binary vector indicating split or not\n",
    "    splitleaf1 = [1] * nleaves  # all leaves labeled as to be split\n",
    "    splitleaf2 = [0] * (nleaves)# l1,l2 labeled as to be split\n",
    "    splitleaf2[idx1]=1\n",
    "    splitleaf2[idx2]=1\n",
    "    splitleaf3 = [1] * (nleaves)# dp labeled as to be split\n",
    "    splitleaf3[idx1]=0\n",
    "    splitleaf3[idx2]=0\n",
    "\n",
    "    lambbb = lamb\n",
    "    if lookahead==False:\n",
    "        lambbb = 0\n",
    "    \n",
    "    b00 = b0\n",
    "    if equiv_points==False:\n",
    "        b00 = 0\n",
    "    \n",
    "    if lb + b00 + lambbb >= R_c:\n",
    "        # print(\"lb+b0+lamb\",lb+b0+lamb)\n",
    "        # print(\"R_c\",R_c)\n",
    "        # if equivalent points bound combined with the lookahead bound doesn't hold\n",
    "        # or if the hierarchical objective lower bound doesn't hold\n",
    "        # we need to split at least one leaf in dp\n",
    "\n",
    "        if a_l < lamb:\n",
    "            # if the bound doesn't hold, we need to split the leaf l1/l2\n",
    "            # further\n",
    "\n",
    "            if len(splitleaf_list) > 0:\n",
    "                split_l1_l2 = splitleaf_array[\n",
    "                    :, idx1].sum() + splitleaf_array[:, idx2].sum()\n",
    "\n",
    "                # if dp will have been split\n",
    "                if splitleaf_array.sum() - split_l1_l2 > 0:\n",
    "\n",
    "                    # if l1/l2 will have been split\n",
    "                    if split_l1_l2 > 0:\n",
    "                        sl.append(splitleaf1)\n",
    "\n",
    "                    # if l1/l2 will not have been split, we need to split l1/l2\n",
    "                    else:\n",
    "                        sl.append(splitleaf2)\n",
    "\n",
    "                # and we need to split leaves in dp, if dp will not have been\n",
    "                # split\n",
    "                else:\n",
    "\n",
    "                    # if l1/l2 will have been split\n",
    "                    if split_l1_l2 > 0:\n",
    "                        sl.append(splitleaf3)\n",
    "\n",
    "                    # if l1/l2 will not have been split, we need to split l1/l2\n",
    "                    else:\n",
    "                        sl.append(splitleaf2)\n",
    "                        sl.append(splitleaf3)\n",
    "            else:\n",
    "                sl.append(splitleaf2)\n",
    "                sl.append(splitleaf3)\n",
    "\n",
    "        else:\n",
    "\n",
    "            if len(splitleaf_list) > 0:\n",
    "                split_l1_l2 = splitleaf_array[\n",
    "                    :, idx1].sum() + splitleaf_array[:, idx2].sum()\n",
    "\n",
    "                # if dp will have been split\n",
    "                if splitleaf_array.sum() - split_l1_l2 > 0:\n",
    "                    sl.append(splitleaf1)\n",
    "\n",
    "                # and we need to split leaves in dp, if dp will not have been\n",
    "                # split\n",
    "                else:\n",
    "                    sl.append(splitleaf3)\n",
    "            else:\n",
    "                sl.append(splitleaf3)\n",
    "    else:\n",
    "\n",
    "        if a_l < lamb:\n",
    "            # if the bound doesn't hold, we need to split the leaf l1/l2\n",
    "            # further\n",
    "\n",
    "            if len(splitleaf_list) > 0:\n",
    "                split_l1_l2 = splitleaf_array[\n",
    "                    :, -1].sum() + splitleaf_array[:, -2].sum()\n",
    "\n",
    "                # if l1/l2 will have been split\n",
    "                if split_l1_l2 > 0:\n",
    "                    sl.append(splitleaf1)\n",
    "\n",
    "                # if l1/l2 will not have been split, we need to split l1/l2\n",
    "                else:\n",
    "                    sl.append(splitleaf2)\n",
    "            else:\n",
    "                sl.append(splitleaf2)\n",
    "\n",
    "        else:\n",
    "            sl.append(splitleaf1)\n",
    "\n",
    "    return sl\n",
    "\n",
    "def gini_reduction(x,y,ndata,nrule):\n",
    "    \"\"\"\n",
    "    calculate the gini reduction by each feature\n",
    "    return the rank of by descending\n",
    "    \"\"\"\n",
    "    \n",
    "    p0 = sum(y==1)/ndata\n",
    "    gini0 = 2*p0*(1-p0)\n",
    "    \n",
    "    gr = []\n",
    "    for i in range(nrule):\n",
    "        xi = x[:,i]\n",
    "        y1 = y[xi == 0]\n",
    "        y2 = y[xi == 1]\n",
    "        ndata1 = len(y1)\n",
    "        ndata2 = len(y2)\n",
    "        p1 = sum(y1==1)/ndata1\n",
    "        p2 = sum(y2==1)/ndata2\n",
    "        gini1 = 2*p1*(1-p1)\n",
    "        gini2 = 2*p2*(1-p2)\n",
    "        gini_red = gini0 - ndata1/ndata*gini1 - ndata2/ndata*gini2\n",
    "        gr.append(gini_red)\n",
    "        \n",
    "    gr = pd.Series(gr)\n",
    "    rk = list(map(lambda x: int(x)-1, list(gr.rank(method = 'first'))[::-1])) \n",
    "    \n",
    "    print(\"the rank of x's columns: \", rk)\n",
    "    return rk\n",
    "\n",
    "def bbound(x, y, z, lamb, prior_metric=None, MAXDEPTH=4, niter=float('Inf'), logon=False,\n",
    "           support=True, accu_support=True, equiv_points=True, lookahead=True):\n",
    "    \"\"\"\n",
    "    An implementation of Algorithm\n",
    "    ## one copy of tree\n",
    "    ## mark which leaves to be split\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize best rule list and objective\n",
    "    #d_c = None\n",
    "    #R_c = 1\n",
    "\n",
    "    nrule = x.shape[1]\n",
    "    ndata = len(y)\n",
    "    print(\"nrule:\", nrule)\n",
    "    print(\"ndata:\", ndata)\n",
    "    \n",
    "    # order the columns by descending gini reduction\n",
    "    idx = gini_reduction(x,y,ndata,nrule)\n",
    "    x = x[:,idx]\n",
    "    \n",
    "    tic = time.time()\n",
    "\n",
    "    lines = []  # a list for log\n",
    "    leaf_cache = {}  # cache leaves\n",
    "    tree_cache = {}  # cache trees\n",
    "\n",
    "    # initialize the queue to include just empty root\n",
    "    queue = []\n",
    "    root_leaf = CacheLeaf((), y, z, make_all_ones(ndata+1), ndata, lamb, support)\n",
    "    tree0 = CacheTree(leaves=[root_leaf], ndata = ndata, prior_metric=prior_metric, splitleaf=[[1]], lbound=[lamb])\n",
    "    heapq.heappush(queue, (tree0.metric, tree0))\n",
    "    # queue.append(tree0)\n",
    "    d_c = tree0\n",
    "    R_c = tree0.risk\n",
    "    R = tree0.risk\n",
    "    #log(lines, lamb, tic, len(queue), tuple(), tree0, R, d_c, R_c)\n",
    "    \n",
    "    leaf_cache[()] = root_leaf\n",
    "    \n",
    "    COUNT = 0  # count the total number of trees in the queue\n",
    "\n",
    "    COUNT_POP = 0\n",
    "    while queue and COUNT < niter:\n",
    "        #tree = queue.pop(0)\n",
    "        metric, tree = heapq.heappop(queue)\n",
    "\n",
    "        COUNT_POP = COUNT_POP + 1\n",
    "\n",
    "        #print([leaf.rules for leaf in tree.leaves])\n",
    "        #print(\"curio\", curio)\n",
    "        leaves = tree.leaves\n",
    "\n",
    "        # print(\"=======COUNT=======\",COUNT)\n",
    "        # print(\"d\",d)\n",
    "        # print(\"R\",tree.lbound[0]+(tree.num_captured_incorrect[0])/len(y))\n",
    "\n",
    "        \"\"\"\n",
    "        # if we have visited this tree\n",
    "        if tree.sorted_leaves() in tree_cache:\n",
    "            continue\n",
    "        else:\n",
    "            tree_cache[tree.sorted_leaves()] = True\n",
    "        \"\"\"\n",
    "\n",
    "        # the leaves we are going to split\n",
    "        split_next = tree.splitleaf.copy()\n",
    "        spl = split_next.pop(0)\n",
    "\n",
    "        # enumerate through all the leaves\n",
    "        for i in range(len(leaves)):\n",
    "            # print(\"d!!!\",d)\n",
    "            # if the leaf is dead, then continue\n",
    "            if tree.leaves[i].is_dead == 1:\n",
    "                continue\n",
    "\n",
    "            # 0 for not split; 1 for split\n",
    "            if spl[i] == 0:\n",
    "                continue\n",
    "\n",
    "\n",
    "            removed_leaf = leaves[i]\n",
    "            unchanged_leaves = leaves[:i] + leaves[i+1:]\n",
    "\n",
    "            # Restrict the depth of the tree\n",
    "            if len(removed_leaf.rules) >= MAXDEPTH:\n",
    "                continue\n",
    "\n",
    "            # we are going to split leaf i, and get 2 new leaves\n",
    "            # we will add the two new leaves to the end of the list\n",
    "            splitleaf_list = [split_next[k][:i] + split_next[k][i + 1:] + split_next[k][i:i + 1] * 2\n",
    "                              for k in range(len(split_next))]\n",
    "\n",
    "            lb = tree.lbound[i]  # the lower bound\n",
    "            b0 = tree.leaves[i].B0  # the b0 defined in (28) of the paper\n",
    "\n",
    "\n",
    "            d0 = removed_leaf.rules\n",
    "\n",
    "            # split the leaf d0 with feature j\n",
    "            for j in range(1, nrule + 1):\n",
    "                if j not in d0 and -j not in d0:\n",
    "                    # split leaf d0 with feature j, and get 2 leaves l1 and l2\n",
    "                    l1 = d0 + (-j,)\n",
    "                    l2 = d0 + (j,)\n",
    "                    # print(\"t\",t)\n",
    "\n",
    "                    pred_l = [0] * 2\n",
    "                    cap_l = [0] * 2\n",
    "                    incorr_l = [0] * 2\n",
    "                    p_l = [0] * 2\n",
    "                    B0_l = [0] * 2\n",
    "                    points_l = make_zeros(2)\n",
    "\n",
    "                    # for the two new leaves, if they have not been visited,\n",
    "                    # calculate their predictions,\n",
    "                    l1_sorted = tuple(sorted(l1))\n",
    "                    l2_sorted = tuple(sorted(l2))\n",
    "\n",
    "\n",
    "                    tag = removed_leaf.points_cap  # points captured by the leaf's parent leaf\n",
    "\n",
    "                    rule_index = j-1\n",
    "\n",
    "                    if l1_sorted not in leaf_cache:\n",
    "                        tag_rule1 = rule_vectompz(np.array(x[:, rule_index] == 0) * 1)\n",
    "                        new_points_cap1, new_num_captured1 = rule_vand(tag, tag_rule1)\n",
    "                        leaf_cache[l1_sorted] = CacheLeaf(l1_sorted, y, z, new_points_cap1, new_num_captured1, lamb, support)\n",
    "\n",
    "                    Cache_l1 = leaf_cache[l1_sorted]\n",
    "                    cap_l[0], incorr_l[\n",
    "                        0] = Cache_l1.num_captured, Cache_l1.num_captured_incorrect\n",
    "\n",
    "                    if l2_sorted not in leaf_cache:\n",
    "                        tag_rule2 = rule_vectompz(np.array(x[:, rule_index] == 1) * 1)\n",
    "                        new_points_cap2, new_num_captured2 = rule_vand(tag, tag_rule2)\n",
    "                        leaf_cache[l2_sorted] = CacheLeaf(l2_sorted, y, z, new_points_cap2, new_num_captured2, lamb, support)\n",
    "\n",
    "                    Cache_l2 = leaf_cache[l2_sorted]\n",
    "                    cap_l[1], incorr_l[\n",
    "                        1] = Cache_l2.num_captured, Cache_l2.num_captured_incorrect\n",
    "\n",
    "\n",
    "                    new_leaves = [Cache_l1, Cache_l2]\n",
    "                    \n",
    "                    tree_new_leaves = unchanged_leaves+new_leaves\n",
    "\n",
    "                    sorted_new_tree_rules = tuple(sorted(leaf.rules for leaf in tree_new_leaves))\n",
    "                    if sorted_new_tree_rules in tree_cache:\n",
    "                        continue\n",
    "                    else:\n",
    "                        tree_cache[sorted_new_tree_rules] = True\n",
    "\n",
    "\n",
    "                    # calculate the bounds for each leaves in the new tree\n",
    "                    loss_l1 = incorr_l[0] / ndata\n",
    "                    loss_l2 = incorr_l[1] / ndata\n",
    "                    loss_d0 = tree.leaves[i].p * tree.leaves[i].num_captured / ndata\n",
    "                    delta = loss_l1 + loss_l2 - loss_d0 + lamb\n",
    "                    old_lbound = tree.lbound[:i] + tree.lbound[i + 1:]\n",
    "                    new_lbound = [b + delta for b in old_lbound] + \\\n",
    "                        [tree.lbound[i] + loss_l2 + lamb,\n",
    "                            tree.lbound[i] + loss_l1 + lamb]\n",
    "\n",
    "                    # generate the new splitleaf for the new tree\n",
    "                    sl = generate_new_splitleaf(\n",
    "                        tree_new_leaves, sorted_new_tree_rules, leaf_cache, splitleaf_list, ndata, len(unchanged_leaves)+2, lamb, min(R_c, new_lbound[-1]+loss_l2),\n",
    "                        accu_support, equiv_points, lookahead)\n",
    "                    # print('sl',sl)\n",
    "\n",
    "                    # construct the new tree\n",
    "                    tree_new = CacheTree(ndata=ndata, leaves=tree_new_leaves,\n",
    "                                         prior_metric=prior_metric,\n",
    "                                         splitleaf=sl,\n",
    "                                         lbound=new_lbound,\n",
    "                                         )\n",
    "\n",
    "\n",
    "\n",
    "                    # queue.append(tree_new)\n",
    "\n",
    "                    heapq.heappush(queue, (tree_new.metric, tree_new))\n",
    "                    COUNT = COUNT + 1\n",
    "                    R = tree_new.risk\n",
    "                    if R < R_c:\n",
    "                        d_c = tree_new\n",
    "                        R_c = R\n",
    "                        C_c = COUNT\n",
    "                        time_c = time.time()-tic\n",
    "\n",
    "                    if logon==True:\n",
    "                        log(lines, COUNT_POP, COUNT, queue, metric, R_c, tree, tree_new, sorted_new_tree_rules)\n",
    "\n",
    "                    if COUNT % 100000 == 0:\n",
    "                        print(\"COUNT:\", COUNT)\n",
    "\n",
    "\n",
    "    header = ['#pop', '#push', 'queue_size', 'metric', 'R_c',\n",
    "              'the_old_tree', 'the_old_tree_splitleaf', 'the_new_tree', 'the_new_tree_splitleaf',\n",
    "              'the_new_tree_objective', 'the_new_tree_lbound', 'the_new_tree_length', 'the_new_tree_depth', 'queue']\n",
    "\n",
    "    fname = \"_\".join([str(nrule), str(ndata), prior_metric,\n",
    "                      str(lamb), str(MAXDEPTH), str(lookahead), \".txt\"])\n",
    "    with open(fname, 'w') as f:\n",
    "        f.write('%s\\n' % \";\".join(header))\n",
    "        f.write('\\n'.join(lines))\n",
    "\n",
    "    print(\">>> log:\",logon)\n",
    "    print(\">>> support bound:\",support)\n",
    "    print(\">>> accurate support bound:\",accu_support)\n",
    "    print(\">>> equiv points bound:\",equiv_points)\n",
    "    print(\">>> lookahead bound:\",lookahead)\n",
    "\n",
    "    print(\"total time: \", time.time() - tic)\n",
    "    print(\"lambda: \", lamb)\n",
    "    print(\"leaves: \", [leaf.rules for leaf in d_c.leaves])\n",
    "    #print(\"lbound: \", d_c.lbound)\n",
    "    #print(\"d_c.num_captured: \", [leaf.num_captured for leaf in d_c.leaves])\n",
    "    print(\"prediction: \", [leaf.prediction for leaf in d_c.leaves])\n",
    "    print(\"Objective: \", R_c)\n",
    "    print(\"COUNT of the best tree: \", C_c)\n",
    "    print(\"time when the best tree is achieved: \", time_c)\n",
    "    print(\"TOTAL COUNT: \", COUNT)\n",
    "\n",
    "    return d_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nrule: 5\n",
      "ndata: 6907\n",
      "the rank of x's columns:  [4, 0, 1, 2, 3]\n",
      "COUNT: 100000\n",
      "COUNT: 200000\n",
      "COUNT: 300000\n",
      "COUNT: 400000\n",
      "COUNT: 500000\n",
      "COUNT: 600000\n",
      "COUNT: 700000\n",
      "COUNT: 800000\n",
      "COUNT: 900000\n",
      "COUNT: 1000000\n",
      "COUNT: 1100000\n",
      "COUNT: 1200000\n",
      "COUNT: 1300000\n",
      "COUNT: 1400000\n",
      "COUNT: 1500000\n",
      "COUNT: 1600000\n",
      "COUNT: 1700000\n",
      "COUNT: 1800000\n",
      "COUNT: 1900000\n",
      "COUNT: 2000000\n",
      ">>> log: False\n",
      ">>> support bound: True\n",
      ">>> accurate support bound: True\n",
      ">>> equiv points bound: True\n",
      ">>> lookahead bound: True\n",
      "total time:  274.8425557613373\n",
      "lambda:  0.0035\n",
      "leaves:  [(3,), (-3, 1), (-4, -3, -1), (-5, -3, -1, 4), (-3, -1, 4, 5)]\n",
      "prediction:  [1, 1, 0, 0, 1]\n",
      "Objective:  0.3541150282322281\n",
      "COUNT of the best tree:  499510\n",
      "time when the best tree is achieved:  68.28114938735962\n",
      "TOTAL COUNT:  2053987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.CacheTree at 0x7fb6dc70a048>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all bounds\n",
    "#all data, 5 features\n",
    "\n",
    "bbound(x, y, z, lamb=0.0035, prior_metric=\"objective\", MAXDEPTH = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nrule: 5\n",
      "ndata: 6907\n",
      "the rank of x's columns:  [4, 0, 1, 2, 3]\n",
      "COUNT: 100000\n",
      "COUNT: 200000\n",
      "COUNT: 300000\n",
      "COUNT: 400000\n",
      "COUNT: 500000\n",
      "COUNT: 600000\n",
      "COUNT: 700000\n",
      "COUNT: 800000\n",
      "COUNT: 900000\n",
      "COUNT: 1000000\n",
      "COUNT: 1100000\n",
      "COUNT: 1200000\n",
      "COUNT: 1300000\n",
      "COUNT: 1400000\n",
      "COUNT: 1500000\n",
      "COUNT: 1600000\n",
      "COUNT: 1700000\n",
      "COUNT: 1800000\n",
      "COUNT: 1900000\n",
      "COUNT: 2000000\n",
      "COUNT: 2100000\n",
      "COUNT: 2200000\n",
      "COUNT: 2300000\n",
      ">>> log: False\n",
      ">>> support bound: True\n",
      ">>> accurate support bound: True\n",
      ">>> equiv points bound: True\n",
      ">>> lookahead bound: False\n",
      "total time:  319.55824398994446\n",
      "lambda:  0.0035\n",
      "leaves:  [(3,), (-3, 1), (-4, -3, -1), (-5, -3, -1, 4), (-3, -1, 4, 5)]\n",
      "prediction:  [1, 1, 0, 0, 1]\n",
      "Objective:  0.3541150282322281\n",
      "COUNT of the best tree:  533160\n",
      "time when the best tree is achieved:  73.70012855529785\n",
      "TOTAL COUNT:  2346425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.CacheTree at 0x7fb6e0725c18>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all data, 5 features\n",
    "\n",
    "bbound(x, y, z, lamb=0.0035, prior_metric=\"objective\", MAXDEPTH = 4, lookahead=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nrule: 5\n",
      "ndata: 6907\n",
      "the rank of x's columns:  [4, 0, 1, 2, 3]\n",
      "COUNT: 100000\n",
      "COUNT: 200000\n",
      "COUNT: 300000\n",
      "COUNT: 400000\n",
      "COUNT: 500000\n",
      "COUNT: 600000\n",
      "COUNT: 700000\n",
      "COUNT: 800000\n",
      "COUNT: 900000\n",
      "COUNT: 1000000\n",
      "COUNT: 1100000\n",
      "COUNT: 1200000\n",
      "COUNT: 1300000\n",
      "COUNT: 1400000\n",
      "COUNT: 1500000\n",
      "COUNT: 1600000\n",
      "COUNT: 1700000\n",
      "COUNT: 1800000\n",
      "COUNT: 1900000\n",
      "COUNT: 2000000\n",
      ">>> log: False\n",
      ">>> support bound: True\n",
      ">>> accurate support bound: False\n",
      ">>> equiv points bound: True\n",
      ">>> lookahead bound: True\n",
      "total time:  272.8768117427826\n",
      "lambda:  0.0035\n",
      "leaves:  [(3,), (-3, 1), (-4, -3, -1), (-5, -3, -1, 4), (-3, -1, 4, 5)]\n",
      "prediction:  [1, 1, 0, 0, 1]\n",
      "Objective:  0.3541150282322281\n",
      "COUNT of the best tree:  499510\n",
      "time when the best tree is achieved:  67.63874244689941\n",
      "TOTAL COUNT:  2053987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.CacheTree at 0x7fb6e0647898>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all data, 5 features\n",
    "\n",
    "bbound(x, y, z, lamb=0.0035, prior_metric=\"objective\", MAXDEPTH = 4, accu_support=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nrule: 5\n",
      "ndata: 6907\n",
      "the rank of x's columns:  [4, 0, 1, 2, 3]\n",
      "COUNT: 100000\n",
      "COUNT: 200000\n",
      "COUNT: 300000\n",
      "COUNT: 400000\n",
      "COUNT: 500000\n",
      "COUNT: 600000\n",
      "COUNT: 700000\n",
      "COUNT: 800000\n",
      "COUNT: 900000\n",
      "COUNT: 1000000\n",
      "COUNT: 1100000\n",
      "COUNT: 1200000\n",
      "COUNT: 1300000\n",
      "COUNT: 1400000\n",
      "COUNT: 1500000\n",
      "COUNT: 1600000\n",
      "COUNT: 1700000\n",
      "COUNT: 1800000\n",
      "COUNT: 1900000\n",
      "COUNT: 2000000\n",
      "COUNT: 2100000\n",
      "COUNT: 2200000\n",
      "COUNT: 2300000\n",
      "COUNT: 2400000\n",
      "COUNT: 2500000\n",
      "COUNT: 2600000\n",
      "COUNT: 2700000\n",
      "COUNT: 2800000\n",
      "COUNT: 2900000\n",
      "COUNT: 3000000\n",
      "COUNT: 3100000\n",
      "COUNT: 3200000\n",
      "COUNT: 3300000\n",
      "COUNT: 3400000\n",
      "COUNT: 3500000\n",
      ">>> log: False\n",
      ">>> support bound: True\n",
      ">>> accurate support bound: True\n",
      ">>> equiv points bound: False\n",
      ">>> lookahead bound: True\n",
      "total time:  523.9261918067932\n",
      "lambda:  0.0035\n",
      "leaves:  [(3,), (-3, 1), (-4, -3, -1), (-5, -3, -1, 4), (-3, -1, 4, 5)]\n",
      "prediction:  [1, 1, 0, 0, 1]\n",
      "Objective:  0.3541150282322281\n",
      "COUNT of the best tree:  624933\n",
      "time when the best tree is achieved:  89.16136598587036\n",
      "TOTAL COUNT:  3578198\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.CacheTree at 0x7fb6e05579e8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all data, 5 features\n",
    "\n",
    "bbound(x, y, z, lamb=0.0035, prior_metric=\"objective\", MAXDEPTH = 4, equiv_points=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nrule: 5\n",
      "ndata: 6907\n",
      "the rank of x's columns:  [4, 0, 1, 2, 3]\n",
      "COUNT: 100000\n",
      "COUNT: 200000\n",
      "COUNT: 300000\n",
      "COUNT: 400000\n",
      "COUNT: 500000\n",
      "COUNT: 600000\n",
      "COUNT: 700000\n",
      "COUNT: 800000\n",
      "COUNT: 900000\n",
      "COUNT: 1000000\n",
      "COUNT: 1100000\n",
      "COUNT: 1200000\n",
      "COUNT: 1300000\n",
      "COUNT: 1400000\n",
      "COUNT: 1500000\n",
      "COUNT: 1600000\n",
      "COUNT: 1700000\n",
      "COUNT: 1800000\n",
      "COUNT: 1900000\n",
      "COUNT: 2000000\n",
      "COUNT: 2100000\n",
      "COUNT: 2200000\n",
      "COUNT: 2300000\n",
      "COUNT: 2400000\n",
      "COUNT: 2500000\n",
      "COUNT: 2600000\n",
      "COUNT: 2700000\n",
      "COUNT: 2800000\n",
      "COUNT: 2900000\n",
      "COUNT: 3000000\n",
      "COUNT: 3100000\n",
      "COUNT: 3200000\n",
      "COUNT: 3300000\n",
      "COUNT: 3400000\n",
      "COUNT: 3500000\n",
      "COUNT: 3600000\n",
      "COUNT: 3700000\n",
      "COUNT: 3800000\n",
      "COUNT: 3900000\n",
      "COUNT: 4000000\n",
      "COUNT: 4100000\n",
      "COUNT: 4200000\n",
      "COUNT: 4300000\n",
      "COUNT: 4400000\n",
      "COUNT: 4500000\n",
      "COUNT: 4600000\n",
      "COUNT: 4700000\n",
      "COUNT: 4800000\n",
      "COUNT: 4900000\n",
      "COUNT: 5000000\n",
      "COUNT: 5100000\n",
      "COUNT: 5200000\n",
      "COUNT: 5300000\n",
      "COUNT: 5400000\n",
      "COUNT: 5500000\n",
      "COUNT: 5600000\n",
      "COUNT: 5700000\n",
      "COUNT: 5800000\n",
      "COUNT: 5900000\n",
      "COUNT: 6000000\n",
      "COUNT: 6100000\n",
      "COUNT: 6200000\n",
      "COUNT: 6300000\n",
      "COUNT: 6400000\n",
      "COUNT: 6500000\n",
      "COUNT: 6600000\n",
      "COUNT: 6700000\n",
      "COUNT: 6800000\n",
      "COUNT: 6900000\n",
      "COUNT: 7000000\n",
      "COUNT: 7100000\n",
      "COUNT: 7200000\n",
      "COUNT: 7300000\n",
      "COUNT: 7400000\n",
      "COUNT: 7500000\n",
      "COUNT: 7600000\n",
      "COUNT: 7700000\n",
      "COUNT: 7800000\n",
      "COUNT: 7900000\n",
      "COUNT: 8000000\n",
      "COUNT: 8100000\n",
      "COUNT: 8200000\n",
      "COUNT: 8300000\n",
      "COUNT: 8400000\n",
      "COUNT: 8500000\n",
      "COUNT: 8600000\n",
      "COUNT: 8700000\n",
      "COUNT: 8800000\n",
      "COUNT: 8900000\n",
      "COUNT: 9000000\n",
      "COUNT: 9100000\n",
      "COUNT: 9200000\n",
      "COUNT: 9300000\n",
      "COUNT: 9400000\n",
      ">>> log: False\n",
      ">>> support bound: False\n",
      ">>> accurate support bound: True\n",
      ">>> equiv points bound: True\n",
      ">>> lookahead bound: True\n",
      "total time:  1603.6600823402405\n",
      "lambda:  0.0035\n",
      "leaves:  [(3,), (-3, 1), (-4, -3, -1), (-5, -3, -1, 4), (-3, -1, 4, 5)]\n",
      "prediction:  [1, 1, 0, 0, 1]\n",
      "Objective:  0.3541150282322281\n",
      "COUNT of the best tree:  3147089\n",
      "time when the best tree is achieved:  518.7519805431366\n",
      "TOTAL COUNT:  9429026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.CacheTree at 0x7fb670886160>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all data, 5 features\n",
    "\n",
    "bbound(x, y, z, lamb=0.0035, prior_metric=\"objective\", MAXDEPTH = 4, support=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nrule: 4\n",
      "ndata: 6907\n",
      "the rank of x's columns:  [0, 1, 2, 3]\n",
      ">>> log: False\n",
      ">>> support bound: True\n",
      ">>> accurate support bound: True\n",
      ">>> equiv points bound: True\n",
      ">>> lookahead bound: True\n",
      "total time:  5.384786605834961\n",
      "lambda:  0.0035\n",
      "leaves:  [(1,), (-1, 2), (-3, -2, -1), (-2, -1, 3)]\n",
      "prediction:  [0, 1, 0, 1]\n",
      "Objective:  0.4442881135080353\n",
      "COUNT of the best tree:  16360\n",
      "time when the best tree is achieved:  3.387017250061035\n",
      "TOTAL COUNT:  32126\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.CacheTree at 0x7f0cd2394cf8>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all bounds\n",
    "#all data, 4 features\n",
    "\n",
    "bbound(x[:,:4], y, z, lamb=0.0035, prior_metric=\"objective\", MAXDEPTH = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nrule: 4\n",
      "ndata: 6907\n",
      "the rank of x's columns:  [0, 1, 2, 3]\n",
      ">>> log: False\n",
      ">>> support bound: True\n",
      ">>> accurate support bound: True\n",
      ">>> equiv points bound: True\n",
      ">>> lookahead bound: True\n",
      "total time:  22.75815510749817\n",
      "lambda:  0.0035\n",
      "leaves:  [(1,), (-1, 2), (-3, -2, -1), (-2, -1, 3)]\n",
      "prediction:  [0, 1, 0, 1]\n",
      "Objective:  0.4442881135080353\n",
      "COUNT of the best tree:  16360\n",
      "time when the best tree is achieved:  10.576642751693726\n",
      "TOTAL COUNT:  32126\n",
      "         3737049 function calls (3737048 primitive calls) in 22.873 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:997(_handle_fromlist)\n",
      "       80    0.003    0.000    1.108    0.014 <ipython-input-18-7c39778edeb1>:107(__init__)\n",
      "    32127    0.284    0.000    0.340    0.000 <ipython-input-18-7c39778edeb1>:15(__init__)\n",
      "    32126    2.266    0.000    3.785    0.000 <ipython-input-18-7c39778edeb1>:175(generate_new_splitleaf)\n",
      "    32126    0.115    0.000    0.115    0.000 <ipython-input-18-7c39778edeb1>:179(<listcomp>)\n",
      "    32126    0.120    0.000    0.120    0.000 <ipython-input-18-7c39778edeb1>:204(<listcomp>)\n",
      "        1    0.004    0.004    0.109    0.109 <ipython-input-18-7c39778edeb1>:320(gini_reduction)\n",
      "        4    0.000    0.000    0.000    0.000 <ipython-input-18-7c39778edeb1>:344(<lambda>)\n",
      "        1    6.066    6.066   22.871   22.871 <ipython-input-18-7c39778edeb1>:349(bbound)\n",
      "   120479    0.225    0.000    0.225    0.000 <ipython-input-18-7c39778edeb1>:439(<listcomp>)\n",
      "  1608016    3.322    0.000    3.322    0.000 <ipython-input-18-7c39778edeb1>:496(<genexpr>)\n",
      "    32126    0.104    0.000    0.104    0.000 <ipython-input-18-7c39778edeb1>:509(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 <ipython-input-18-7c39778edeb1>:563(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 <ipython-input-18-7c39778edeb1>:566(<listcomp>)\n",
      "    97025    0.239    0.000    0.239    0.000 <ipython-input-18-7c39778edeb1>:58(__lt__)\n",
      "        1    0.001    0.001   22.873   22.873 <string>:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:200(iteritems)\n",
      "        1    0.000    0.000    0.000    0.000 _bootlocale.py:23(getpreferredencoding)\n",
      "        1    0.000    0.000    0.000    0.000 _weakrefset.py:70(__contains__)\n",
      "        1    0.000    0.000    0.000    0.000 abc.py:180(__instancecheck__)\n",
      "        1    0.000    0.000    0.000    0.000 algorithms.py:217(_get_data_algo)\n",
      "        1    0.000    0.000    0.000    0.000 algorithms.py:39(_ensure_data)\n",
      "        1    0.000    0.000    0.000    0.000 algorithms.py:680(rank)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:4155(_ensure_index)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:551(_reset_identity)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:707(ndim)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:799(tolist)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:817(__iter__)\n",
      "        1    0.000    0.000    0.000    0.000 cast.py:39(maybe_convert_platform)\n",
      "        1    0.000    0.000    0.000    0.000 cast.py:826(maybe_castable)\n",
      "        1    0.000    0.000    0.000    0.000 cast.py:935(maybe_cast_to_datetime)\n",
      "        1    0.000    0.000    0.000    0.000 codecs.py:185(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:1493(is_float_dtype)\n",
      "        2    0.000    0.000    0.000    0.000 common.py:1545(is_bool_dtype)\n",
      "        6    0.000    0.000    0.000    0.000 common.py:1773(_get_dtype_type)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:207(_default_index)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:223(is_datetimetz)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:238(_all_none)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:297(is_datetime64_dtype)\n",
      "        2    0.000    0.000    0.000    0.000 common.py:334(is_datetime64tz_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:372(is_timedelta64_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:478(is_categorical_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:612(is_datetimelike)\n",
      "        2    0.000    0.000    0.000    0.000 common.py:824(is_signed_integer_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:85(is_object_dtype)\n",
      "        2    0.000    0.000    0.000    0.000 common.py:873(is_unsigned_integer_dtype)\n",
      "        3    0.000    0.000    0.000    0.000 dtypes.py:85(is_dtype)\n",
      "        4    0.000    0.000    0.000    0.000 enum.py:265(__call__)\n",
      "        4    0.000    0.000    0.000    0.000 enum.py:515(__new__)\n",
      "        2    0.000    0.000    0.000    0.000 enum.py:801(__and__)\n",
      "        2    0.000    0.000    0.000    0.000 generic.py:120(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:279(_construct_axes_dict)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:281(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:346(_get_axis_number)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:3583(__finalize__)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:359(_get_axis_name)\n",
      "        2    0.000    0.000    0.000    0.000 generic.py:3600(__getattr__)\n",
      "        2    0.000    0.000    0.000    0.000 generic.py:3616(__setattr__)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:372(_get_axis)\n",
      "        1    0.000    0.000    0.001    0.001 generic.py:5595(rank)\n",
      "        1    0.000    0.000    0.001    0.001 generic.py:5633(ranker)\n",
      "        4    0.000    0.000    0.000    0.000 generic.py:7(_check)\n",
      "        1    0.000    0.000    0.000    0.000 inference.py:234(is_list_like)\n",
      "        2    0.000    0.000    0.000    0.000 internals.py:107(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 internals.py:155(external_values)\n",
      "        1    0.000    0.000    0.000    0.000 internals.py:159(internal_values)\n",
      "        2    0.000    0.000    0.000    0.000 internals.py:189(mgr_locs)\n",
      "        2    0.000    0.000    0.000    0.000 internals.py:226(mgr_locs)\n",
      "        2    0.000    0.000    0.000    0.000 internals.py:2921(make_block)\n",
      "        6    0.000    0.000    0.000    0.000 internals.py:307(dtype)\n",
      "        1    0.000    0.000    0.000    0.000 internals.py:3135(_get_items)\n",
      "        1    0.000    0.000    0.000    0.000 internals.py:3224(__len__)\n",
      "        2    0.000    0.000    0.000    0.000 internals.py:4363(__init__)\n",
      "        8    0.000    0.000    0.000    0.000 internals.py:4409(_block)\n",
      "        6    0.000    0.000    0.000    0.000 internals.py:4479(dtype)\n",
      "        1    0.000    0.000    0.000    0.000 internals.py:4503(external_values)\n",
      "        1    0.000    0.000    0.000    0.000 internals.py:4506(internal_values)\n",
      "       66    0.001    0.000    0.004    0.000 iostream.py:195(schedule)\n",
      "       64    0.000    0.000    0.000    0.000 iostream.py:300(_is_master_process)\n",
      "       64    0.000    0.000    0.000    0.000 iostream.py:313(_schedule_flush)\n",
      "       64    0.001    0.000    0.005    0.000 iostream.py:366(write)\n",
      "       66    0.000    0.000    0.000    0.000 iostream.py:93(_event_pipe)\n",
      "        1    0.000    0.000    0.000    0.000 numeric.py:424(asarray)\n",
      "        2    0.000    0.000    0.000    0.000 numeric.py:99(is_all_dates)\n",
      "        1    0.000    0.000    0.000    0.000 range.py:119(_simple_new)\n",
      "        1    0.000    0.000    0.000    0.000 range.py:146(_validate_dtype)\n",
      "        5    0.000    0.000    0.000    0.000 range.py:469(__len__)\n",
      "        1    0.000    0.000    0.000    0.000 range.py:56(__new__)\n",
      "        2    0.000    0.000    0.000    0.000 range.py:72(_ensure_int)\n",
      "      239    0.002    0.000    0.632    0.003 re.py:184(sub)\n",
      "      239    0.001    0.000    0.002    0.000 re.py:286(_compile)\n",
      "      239    0.997    0.004    1.649    0.007 rule.py:148(rule_vectompz)\n",
      "      239    0.002    0.000    0.002    0.000 rule.py:162(rule_vand)\n",
      "        1    0.000    0.000    0.000    0.000 rule.py:74(make_all_ones)\n",
      "   144457    0.641    0.000    0.961    0.000 rule.py:85(make_zeros)\n",
      "        2    0.000    0.000    0.001    0.000 series.py:155(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 series.py:284(_constructor)\n",
      "        2    0.000    0.000    0.000    0.000 series.py:300(_set_axis)\n",
      "        2    0.000    0.000    0.000    0.000 series.py:3136(_sanitize_array)\n",
      "        1    0.000    0.000    0.000    0.000 series.py:3153(_try_cast)\n",
      "        2    0.000    0.000    0.000    0.000 series.py:326(_set_subtyp)\n",
      "        3    0.000    0.000    0.000    0.000 series.py:336(name)\n",
      "        3    0.000    0.000    0.000    0.000 series.py:340(name)\n",
      "        6    0.000    0.000    0.000    0.000 series.py:347(dtype)\n",
      "        1    0.000    0.000    0.000    0.000 series.py:367(values)\n",
      "        1    0.000    0.000    0.000    0.000 series.py:400(_values)\n",
      "        1    0.000    0.000    0.000    0.000 series.py:483(__len__)\n",
      "       66    0.001    0.000    0.001    0.000 socket.py:333(send)\n",
      "        2    0.000    0.000    0.000    0.000 sre_compile.py:223(_compile_charset)\n",
      "        2    0.000    0.000    0.000    0.000 sre_compile.py:250(_optimize_charset)\n",
      "        2    0.000    0.000    0.000    0.000 sre_compile.py:376(_mk_bitmap)\n",
      "        2    0.000    0.000    0.000    0.000 sre_compile.py:378(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 sre_compile.py:414(_get_literal_prefix)\n",
      "        1    0.000    0.000    0.000    0.000 sre_compile.py:441(_get_charset_prefix)\n",
      "        1    0.000    0.000    0.000    0.000 sre_compile.py:482(_compile_info)\n",
      "        2    0.000    0.000    0.000    0.000 sre_compile.py:539(isstring)\n",
      "        1    0.000    0.000    0.000    0.000 sre_compile.py:542(_code)\n",
      "        1    0.000    0.000    0.001    0.001 sre_compile.py:557(compile)\n",
      "        1    0.000    0.000    0.000    0.000 sre_compile.py:64(_compile)\n",
      "        1    0.000    0.000    0.000    0.000 sre_parse.py:111(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 sre_parse.py:171(append)\n",
      "        1    0.000    0.000    0.000    0.000 sre_parse.py:173(getwidth)\n",
      "        1    0.000    0.000    0.000    0.000 sre_parse.py:223(__init__)\n",
      "        8    0.000    0.000    0.000    0.000 sre_parse.py:232(__next)\n",
      "        7    0.000    0.000    0.000    0.000 sre_parse.py:248(match)\n",
      "        7    0.000    0.000    0.000    0.000 sre_parse.py:253(get)\n",
      "        2    0.000    0.000    0.000    0.000 sre_parse.py:285(tell)\n",
      "        3    0.000    0.000    0.000    0.000 sre_parse.py:294(_class_escape)\n",
      "        1    0.000    0.000    0.000    0.000 sre_parse.py:407(_parse_sub)\n",
      "        1    0.000    0.000    0.000    0.000 sre_parse.py:470(_parse)\n",
      "        1    0.000    0.000    0.000    0.000 sre_parse.py:76(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 sre_parse.py:81(groups)\n",
      "        1    0.000    0.000    0.000    0.000 sre_parse.py:828(fix_flags)\n",
      "        1    0.000    0.000    0.000    0.000 sre_parse.py:844(parse)\n",
      "       66    0.000    0.000    0.000    0.000 threading.py:1062(_wait_for_tstate_lock)\n",
      "       66    0.001    0.000    0.001    0.000 threading.py:1104(is_alive)\n",
      "       66    0.000    0.000    0.000    0.000 threading.py:506(is_set)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x7fc16a936780}\n",
      "    32127    0.481    0.000    0.706    0.000 {built-in method _heapq.heappop}\n",
      "    32127    0.114    0.000    0.127    0.000 {built-in method _heapq.heappush}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _locale.nl_langinfo}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _sre.compile}\n",
      "        1    0.000    0.000   22.873   22.873 {built-in method builtins.exec}\n",
      "        9    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "        7    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\n",
      "      160    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
      "       11    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n",
      "510894/510893    0.899    0.000    0.899    0.000 {built-in method builtins.len}\n",
      "        5    0.000    0.000    0.000    0.000 {built-in method builtins.max}\n",
      "    32129    0.089    0.000    0.089    0.000 {built-in method builtins.min}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.ord}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.pow}\n",
      "       16    0.000    0.000    0.006    0.000 {built-in method builtins.print}\n",
      "   498098    4.737    0.000    8.059    0.000 {built-in method builtins.sorted}\n",
      "   128513    0.524    0.000    0.524    0.000 {built-in method builtins.sum}\n",
      "   144697    0.339    0.000    0.339    0.000 {built-in method gmpy2.mpz}\n",
      "      239    0.001    0.000    0.001    0.000 {built-in method gmpy2.popcount}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method io.open}\n",
      "    32206    0.220    0.000    0.220    0.000 {built-in method numpy.core.multiarray.array}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method pandas._libs.algos.ensure_float64}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method pandas._libs.lib.is_integer}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method pandas._libs.lib.isscalar}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method pandas._libs.lib.list_to_object_array}\n",
      "       64    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method time.time}\n",
      "       66    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "       66    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "    32161    0.067    0.000    0.067    0.000 {method 'append' of 'list' objects}\n",
      "    64253    0.125    0.000    0.125    0.000 {method 'copy' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}\n",
      "       10    0.000    0.000    0.000    0.000 {method 'find' of 'bytearray' objects}\n",
      "        9    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "    64252    0.170    0.000    0.170    0.000 {method 'index' of 'list' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}\n",
      "    32127    0.077    0.000    0.077    0.000 {method 'pop' of 'list' objects}\n",
      "       80    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
      "      239    0.628    0.003    0.628    0.003 {method 'sub' of '_sre.SRE_Pattern' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'tolist' of 'numpy.ndarray' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'translate' of 'bytearray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'write' of '_io.TextIOWrapper' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {pandas._libs.algos.rank_1d_float64}\n",
      "        1    0.000    0.000    0.000    0.000 {pandas._libs.lib.maybe_convert_objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cProfile.run(\"bbound(x[:,:4], y, z, lamb=0.0035, prior_metric=\\\"objective\\\", MAXDEPTH = 4)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With similar support bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import heapq\n",
    "import math\n",
    "import time\n",
    "\n",
    "from rule import make_all_ones, make_zeros, rule_vand, rule_vxor, rule_vectompz\n",
    "\n",
    "class CacheTree:\n",
    "    \"\"\"\n",
    "    A tree data structure.\n",
    "    leaves: a 2-d tuple to encode the leaves\n",
    "    num_captured: a list to record number of data captured by the leaves\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ndata, leaves,\n",
    "                 prior_metric=None,\n",
    "                 splitleaf=None,\n",
    "                 lbound=None,\n",
    "                 similar_leafdead = None\n",
    "                 ):\n",
    "        self.leaves = leaves\n",
    "        # a queue of lists indicating which leaves will be split in next rounds\n",
    "        # (1 for split, 0 for not split)\n",
    "        self.splitleaf = splitleaf\n",
    "        self.lbound = lbound  # a list of lower bound\n",
    "        \n",
    "        # a binary vector indicating whether or not leaves in the tree are dead because of the similar support bound\n",
    "        self.similar_leafdead = similar_leafdead \n",
    "\n",
    "        l = len(leaves)\n",
    "\n",
    "        self.risk = self.lbound[0] + (leaves[0].p * leaves[0].num_captured) / ndata\n",
    "\n",
    "        # which metrics to use for the priority queue\n",
    "        if leaves[0].num_captured == ndata:\n",
    "            # this case is when constructing the null tree ((),)\n",
    "            self.metric = 0\n",
    "        elif prior_metric == \"curiosity\":\n",
    "            self.metric = min([self.lbound[i] / ((ndata - leaves[i].num_captured) / ndata)\n",
    "                               if leaves[i].is_dead == 0 else float('Inf') for i in range(l)])\n",
    "        elif prior_metric == \"bound\":\n",
    "            self.metric = min([self.lbound[i] if leaves[i].is_dead == 0 else float('Inf') for i in range(l)])\n",
    "        elif prior_metric == \"entropy\":\n",
    "            # entropy weighted by number of points captured\n",
    "            self.entropy = [(-leaves[i].p * math.log2(leaves[i].p) - (1 - leaves[i].p) * math.log2(1 - leaves[i].p)) * leaves[i].num_captured\n",
    "                            if leaves[i].p != 0 and leaves[i].p != 1 else 0 for i in range(l)]\n",
    "            self.metric = min([sum(self.entropy[:i] + self.entropy[i + 1:]) / (ndata - leaves[i].num_captured)\n",
    "                               if leaves[i].is_dead == 0 else float('Inf') for i in range(l)])\n",
    "        elif prior_metric == \"gini\":\n",
    "            # gini index weighted by number of points captured\n",
    "            self.giniindex = [(2 * leaves[i].p * (1 - leaves[i].p))\n",
    "                              * leaves[i].num_captured for i in range(l)]\n",
    "            self.metric = min([sum(self.giniindex[:i] + self.giniindex[i + 1:]) / (ndata - leaves[i].num_captured)\n",
    "                               if leaves[i].is_dead == 0 else float('Inf') for i in range(l)])\n",
    "        elif prior_metric == \"objective\":\n",
    "            self.metric = self.risk\n",
    "\n",
    "    def sorted_leaves(self):\n",
    "        # Used by the cache\n",
    "        return tuple(sorted(leaf.rules for leaf in self.leaves))\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        # define <, which will be used in the priority queue\n",
    "        return self.metric < other.metric\n",
    "\"\"\"\n",
    "    def _to_nested_dict(self):\n",
    "        tree = {}\n",
    "\n",
    "        for i, leaf in enumerate(self.leaves):\n",
    "            current_node = tree\n",
    "\n",
    "            for rule in leaf:\n",
    "                current_node['rule'] = abs(rule)\n",
    "                direction = 'left' if rule < 0 else 'right'\n",
    "                if direction not in current_node:\n",
    "                    current_node[direction] = {}\n",
    "                current_node = current_node[direction]\n",
    "\n",
    "            current_node['label'] = self.leaves[i].prediction\n",
    "\n",
    "        return tree\n",
    "\n",
    "    def _format_dict(self, tree, depth=0):\n",
    "        fmt = '-' * depth\n",
    "\n",
    "        if 'rule' in tree:\n",
    "            fmt += 'r{}'.format(tree['rule'])\n",
    "        else:\n",
    "            assert 'label' in tree\n",
    "            fmt += str(tree['label'])\n",
    "\n",
    "        fmt += '\\n'\n",
    "\n",
    "        if 'left' in tree:\n",
    "            fmt += self._format_dict(tree['left'], depth + 1)\n",
    "\n",
    "        if 'right' in tree:\n",
    "            fmt += self._format_dict(tree['right'], depth + 1)\n",
    "\n",
    "        return fmt\n",
    "\n",
    "    def __str__(self):\n",
    "        return self._format_dict(self._to_nested_dict())\n",
    "\"\"\"\n",
    "\n",
    "class CacheLeaf:\n",
    "    \"\"\"\n",
    "    A data structure to cache every single leaf (symmetry aware)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, rules, y, z, points_cap, num_captured, lamb, support):\n",
    "        self.rules = rules\n",
    "        self.points_cap = points_cap\n",
    "        self.num_captured = num_captured\n",
    "\n",
    "        # the y's of these data captured by leaf antecedent[0]\n",
    "        #y_leaf = y[tag]\n",
    "        # print(\"tag\",tag)\n",
    "        # print(\"y\",y)\n",
    "        _, num_ones = rule_vand(points_cap, rule_vectompz(y))\n",
    "\n",
    "        #b0 is defined in (28)\n",
    "\n",
    "        tag_z = rule_vectompz(z.reshape(1, -1)[0])\n",
    "        _, num_errors = rule_vand(points_cap, tag_z)\n",
    "        self.B0 = num_errors / len(y)\n",
    "\n",
    "        if self.num_captured:\n",
    "            self.prediction = int(num_ones / self.num_captured >= 0.5)\n",
    "            if self.prediction == 1:\n",
    "                self.num_captured_incorrect = self.num_captured - num_ones\n",
    "            else:\n",
    "                self.num_captured_incorrect = num_ones\n",
    "            self.p = self.num_captured_incorrect / self.num_captured\n",
    "        else:\n",
    "            self.prediction = 0\n",
    "            self.num_captured_incorrect = 0\n",
    "            self.p = 0\n",
    "\n",
    "        # Lower bound on antecedent support\n",
    "        if support == True:\n",
    "            self.is_dead = self.num_captured / len(y) / 2 < lamb\n",
    "        else:\n",
    "            self.is_dead = 0\n",
    "\n",
    "        self.loss = float(self.num_captured_incorrect) / len(y)\n",
    "\n",
    "\n",
    "\n",
    "def log(lines, COUNT_POP, COUNT, queue, metric, R_c, tree_old, tree_new,sorted_new_tree_rules):\n",
    "    \"log\"\n",
    "\n",
    "    the_count_pop = str(COUNT_POP)\n",
    "    the_count = str(COUNT)\n",
    "    the_queue_size = str(len(queue))\n",
    "    the_metric = str(metric)\n",
    "    the_Rc = str(R_c)\n",
    "    \n",
    "    the_old_tree = str(sorted([leaf.rules for leaf in tree_old.leaves]))\n",
    "    the_old_tree_splitleaf = str(tree_old.splitleaf)\n",
    "    the_new_tree = str(list(sorted_new_tree_rules))\n",
    "    the_new_tree_splitleaf = str(tree_new.splitleaf)\n",
    "    \n",
    "    the_new_tree_objective = str(tree_new.risk)\n",
    "    the_new_tree_lbound = str(min(tree_new.lbound))\n",
    "    the_new_tree_length = str(len(tree_new.leaves))\n",
    "    the_new_tree_depth = str(max([len(leaf.rules) for leaf in tree_new.leaves]))\n",
    "\n",
    "    the_queue = str([[ leaf.rules for leaf in thetree.leaves]  for _,thetree in queue])\n",
    "    \n",
    "    line = \";\".join([the_count_pop, the_count, the_queue_size, the_metric, the_Rc,\n",
    "                     the_old_tree, the_old_tree_splitleaf, the_new_tree, the_new_tree_splitleaf,\n",
    "                     the_new_tree_objective, the_new_tree_lbound, the_new_tree_length, the_new_tree_depth,\n",
    "                     the_queue\n",
    "                    ])\n",
    "    lines.append(line)\n",
    "\n",
    "\n",
    "def generate_new_splitleaf(tree_new_leaves, sorted_new_tree_rules, leaf_cache, splitleaf_list, ndata, nleaves, lamb, R_c, accu_support, equiv_points, lookahead):\n",
    "    \"\"\"\n",
    "    generate the new splitleaf for the new tree\n",
    "    \"\"\"\n",
    "    tree_new_rules = [leaf.rules for leaf in tree_new_leaves]\n",
    "    \n",
    "    found = False\n",
    "    for r1 in sorted_new_tree_rules:\n",
    "        for j in range(len(r1)):\n",
    "            r2 = tuple(sorted(r1[:j]+(-r1[j],)+r1[j+1:]))\n",
    "            r0 = r1[:j]+r1[j+1:]\n",
    "            #print(\"r1:\",r1)\n",
    "            #print(\"r2:\",r2)\n",
    "            #print(\"sorted_tree_new_rules\",sorted_tree_new_rules)\n",
    "            if r2 in sorted_new_tree_rules and r0 in leaf_cache:\n",
    "                l1 = r1\n",
    "                l2 = r2\n",
    "                l0 = r0\n",
    "                found = True\n",
    "                break\n",
    "                #print(\"l1\",l1)\n",
    "        if found == True:\n",
    "            break\n",
    "    \n",
    "    idx1 = tree_new_rules.index(l1)\n",
    "    idx2 = tree_new_rules.index(l2)\n",
    "    \n",
    "    cap_l = [tree_new_leaves[idx1].points_cap, tree_new_leaves[idx2].points_cap]\n",
    "    incorr_l = [tree_new_leaves[idx1].num_captured_incorrect, tree_new_leaves[idx2].num_captured_incorrect]\n",
    "    lb = sum([leaf.loss for leaf in tree_new_leaves]) - tree_new_leaves[idx1].loss - tree_new_leaves[idx2].loss + lamb*(len(tree_new_leaves)-1)\n",
    "    \n",
    "    #print(\"l1\",l1)\n",
    "    #print(\"l2\",l2)\n",
    "    #print(\"l0\",l0)\n",
    "    #print(\"leaf_cache\",leaf_cache)\n",
    "    b0 = leaf_cache[l0].B0\n",
    "    \n",
    "    splitleaf_array = np.array(splitleaf_list)\n",
    "    sl = splitleaf_list.copy()\n",
    "\n",
    "    #(Lower bound on accurate antecedent support)\n",
    "    a_l = (sum(cap_l) - sum(incorr_l)) / ndata - sum(cap_l) / ndata / 2\n",
    "    if accu_support==False:\n",
    "        a_l = float('Inf')\n",
    "\n",
    "    # binary vector indicating split or not\n",
    "    splitleaf1 = [1] * nleaves  # all leaves labeled as to be split\n",
    "    splitleaf2 = [0] * (nleaves)# l1,l2 labeled as to be split\n",
    "    splitleaf2[idx1]=1\n",
    "    splitleaf2[idx2]=1\n",
    "    splitleaf3 = [1] * (nleaves)# dp labeled as to be split\n",
    "    splitleaf3[idx1]=0\n",
    "    splitleaf3[idx2]=0\n",
    "\n",
    "    lambbb = lamb\n",
    "    if lookahead==False:\n",
    "        lambbb = 0\n",
    "    \n",
    "    b00 = b0\n",
    "    if equiv_points==False:\n",
    "        b00 = 0\n",
    "    \n",
    "    if lb + b00 + lambbb >= R_c:\n",
    "        # print(\"lb+b0+lamb\",lb+b0+lamb)\n",
    "        # print(\"R_c\",R_c)\n",
    "        # if equivalent points bound combined with the lookahead bound doesn't hold\n",
    "        # or if the hierarchical objective lower bound doesn't hold\n",
    "        # we need to split at least one leaf in dp\n",
    "\n",
    "        if a_l < lamb:\n",
    "            # if the bound doesn't hold, we need to split the leaf l1/l2\n",
    "            # further\n",
    "\n",
    "            if len(splitleaf_list) > 0:\n",
    "                split_l1_l2 = splitleaf_array[\n",
    "                    :, idx1].sum() + splitleaf_array[:, idx2].sum()\n",
    "\n",
    "                # if dp will have been split\n",
    "                if splitleaf_array.sum() - split_l1_l2 > 0:\n",
    "\n",
    "                    # if l1/l2 will have been split\n",
    "                    if split_l1_l2 > 0:\n",
    "                        sl.append(splitleaf1)\n",
    "\n",
    "                    # if l1/l2 will not have been split, we need to split l1/l2\n",
    "                    else:\n",
    "                        sl.append(splitleaf2)\n",
    "\n",
    "                # and we need to split leaves in dp, if dp will not have been\n",
    "                # split\n",
    "                else:\n",
    "\n",
    "                    # if l1/l2 will have been split\n",
    "                    if split_l1_l2 > 0:\n",
    "                        sl.append(splitleaf3)\n",
    "\n",
    "                    # if l1/l2 will not have been split, we need to split l1/l2\n",
    "                    else:\n",
    "                        sl.append(splitleaf2)\n",
    "                        sl.append(splitleaf3)\n",
    "            else:\n",
    "                sl.append(splitleaf2)\n",
    "                sl.append(splitleaf3)\n",
    "\n",
    "        else:\n",
    "\n",
    "            if len(splitleaf_list) > 0:\n",
    "                split_l1_l2 = splitleaf_array[\n",
    "                    :, idx1].sum() + splitleaf_array[:, idx2].sum()\n",
    "\n",
    "                # if dp will have been split\n",
    "                if splitleaf_array.sum() - split_l1_l2 > 0:\n",
    "                    sl.append(splitleaf1)\n",
    "\n",
    "                # and we need to split leaves in dp, if dp will not have been\n",
    "                # split\n",
    "                else:\n",
    "                    sl.append(splitleaf3)\n",
    "            else:\n",
    "                sl.append(splitleaf3)\n",
    "    else:\n",
    "\n",
    "        if a_l < lamb:\n",
    "            # if the bound doesn't hold, we need to split the leaf l1/l2\n",
    "            # further\n",
    "\n",
    "            if len(splitleaf_list) > 0:\n",
    "                split_l1_l2 = splitleaf_array[\n",
    "                    :, -1].sum() + splitleaf_array[:, -2].sum()\n",
    "\n",
    "                # if l1/l2 will have been split\n",
    "                if split_l1_l2 > 0:\n",
    "                    sl.append(splitleaf1)\n",
    "\n",
    "                # if l1/l2 will not have been split, we need to split l1/l2\n",
    "                else:\n",
    "                    sl.append(splitleaf2)\n",
    "            else:\n",
    "                sl.append(splitleaf2)\n",
    "\n",
    "        else:\n",
    "            sl.append(splitleaf1)\n",
    "\n",
    "    return sl\n",
    "\n",
    "def gini_reduction(x,y,ndata,nrule):\n",
    "    \"\"\"\n",
    "    calculate the gini reduction by each feature\n",
    "    return the rank of by descending\n",
    "    \"\"\"\n",
    "    \n",
    "    p0 = sum(y==1)/ndata\n",
    "    gini0 = 2*p0*(1-p0)\n",
    "    \n",
    "    gr = []\n",
    "    for i in range(nrule):\n",
    "        xi = x[:,i]\n",
    "        y1 = y[xi == 0]\n",
    "        y2 = y[xi == 1]\n",
    "        ndata1 = len(y1)\n",
    "        ndata2 = len(y2)\n",
    "        p1 = sum(y1==1)/ndata1\n",
    "        p2 = sum(y2==1)/ndata2\n",
    "        gini1 = 2*p1*(1-p1)\n",
    "        gini2 = 2*p2*(1-p2)\n",
    "        gini_red = gini0 - ndata1/ndata*gini1 - ndata2/ndata*gini2\n",
    "        gr.append(gini_red)\n",
    "        \n",
    "    gr = pd.Series(gr)\n",
    "    rk = list(map(lambda x: int(x)-1, list(gr.rank(method = 'first'))[::-1])) \n",
    "    \n",
    "    print(\"the rank of x's columns: \", rk)\n",
    "    return rk\n",
    "\n",
    "def bbound(x, y, z, lamb, prior_metric=None, MAXDEPTH=4, niter=float('Inf'), logon=False,\n",
    "           support=True, accu_support=True, equiv_points=True, lookahead=True):\n",
    "    \"\"\"\n",
    "    An implementation of Algorithm\n",
    "    ## one copy of tree\n",
    "    ## mark which leaves to be split\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize best rule list and objective\n",
    "    #d_c = None\n",
    "    #R_c = 1\n",
    "\n",
    "    nrule = x.shape[1]\n",
    "    ndata = len(y)\n",
    "    print(\"nrule:\", nrule)\n",
    "    print(\"ndata:\", ndata)\n",
    "    \n",
    "    # order the columns by descending gini reduction\n",
    "    idx = gini_reduction(x,y,ndata,nrule)\n",
    "    x = x[:,idx]\n",
    "    \n",
    "    tic = time.time()\n",
    "\n",
    "    lines = []  # a list for log\n",
    "    leaf_cache = {}  # cache leaves\n",
    "    tree_cache = {}  # cache trees\n",
    "    deadprefix_cache = [] # cache dead prefix for the similar support bound\n",
    "\n",
    "    # initialize the queue to include just empty root\n",
    "    queue = []\n",
    "    root_leaf = CacheLeaf((), y, z, make_all_ones(ndata+1), ndata, lamb, support)\n",
    "    tree0 = CacheTree(leaves=[root_leaf], ndata = ndata, prior_metric=prior_metric, splitleaf=[[1]], lbound=[lamb], similar_leafdead=[0])\n",
    "    heapq.heappush(queue, (tree0.metric, tree0))\n",
    "    # queue.append(tree0)\n",
    "    d_c = tree0\n",
    "    R_c = tree0.risk\n",
    "    R = tree0.risk\n",
    "    #log(lines, lamb, tic, len(queue), tuple(), tree0, R, d_c, R_c)\n",
    "    \n",
    "    leaf_cache[()] = root_leaf\n",
    "    \n",
    "    COUNT = 0  # count the total number of trees in the queue\n",
    "\n",
    "    COUNT_POP = 0\n",
    "    while queue and COUNT < niter:\n",
    "        #tree = queue.pop(0)\n",
    "        metric, tree = heapq.heappop(queue)\n",
    "\n",
    "        COUNT_POP = COUNT_POP + 1\n",
    "\n",
    "        #print([leaf.rules for leaf in tree.leaves])\n",
    "        #print(\"curio\", curio)\n",
    "        leaves = tree.leaves\n",
    "\n",
    "        # print(\"=======COUNT=======\",COUNT)\n",
    "        # print(\"d\",d)\n",
    "        # print(\"R\",tree.lbound[0]+(tree.num_captured_incorrect[0])/len(y))\n",
    "\n",
    "        \"\"\"\n",
    "        # if we have visited this tree\n",
    "        if tree.sorted_leaves() in tree_cache:\n",
    "            continue\n",
    "        else:\n",
    "            tree_cache[tree.sorted_leaves()] = True\n",
    "        \"\"\"\n",
    "\n",
    "        # the leaves we are going to split\n",
    "        split_next = tree.splitleaf.copy()\n",
    "        spl = split_next.pop(0)\n",
    "\n",
    "        # enumerate through all the leaves\n",
    "        for i in range(len(leaves)):\n",
    "            \n",
    "            lb = tree.lbound[i]  # the lower bound\n",
    "            pc = leaves[i].points_cap\n",
    "            \n",
    "            # print(\"d!!!\",d)\n",
    "            # if the leaf is dead, then continue\n",
    "            if tree.leaves[i].is_dead == 1:\n",
    "                # cache the lower bound of the prefix, and the points not captured by the prefix\n",
    "                if (lb, pc) not in deadprefix_cache:\n",
    "                    deadprefix_cache.append((lb, pc))\n",
    "                continue\n",
    "                \n",
    "            if tree.similar_leafdead[i] == 1:\n",
    "                continue\n",
    "\n",
    "            # 0 for not split; 1 for split\n",
    "            if spl[i] == 0:\n",
    "                continue\n",
    "                \n",
    "            is_similar = False\n",
    "            # similar support bound\n",
    "            for deadprefix_lb, deadprefix_cap in deadprefix_cache:\n",
    "                cnt = rule_vxor(pc, deadprefix_cap)\n",
    "                if lb + lamb - deadprefix_lb >= cnt/ndata:\n",
    "                    tree.similar_leafdead[i] == 1\n",
    "                    if (lb, pc) not in deadprefix_cache:\n",
    "                        deadprefix_cache.append((lb, pc))\n",
    "                    \n",
    "                    is_similar = True\n",
    "                    break\n",
    "            \n",
    "            if is_similar == True:\n",
    "                continue\n",
    "\n",
    "            removed_leaf = leaves[i]\n",
    "            unchanged_leaves = leaves[:i] + leaves[i+1:]\n",
    "\n",
    "            # Restrict the depth of the tree\n",
    "            if len(removed_leaf.rules) >= MAXDEPTH:\n",
    "                continue\n",
    "\n",
    "            # we are going to split leaf i, and get 2 new leaves\n",
    "            # we will add the two new leaves to the end of the list\n",
    "            splitleaf_list = [split_next[k][:i] + split_next[k][i + 1:] + split_next[k][i:i + 1] * 2\n",
    "                              for k in range(len(split_next))]\n",
    "\n",
    "            \n",
    "            b0 = tree.leaves[i].B0  # the b0 defined in (28) of the paper\n",
    "\n",
    "\n",
    "            d0 = removed_leaf.rules\n",
    "\n",
    "            # split the leaf d0 with feature j\n",
    "            for j in range(1, nrule + 1):\n",
    "                if j not in d0 and -j not in d0:\n",
    "                    # split leaf d0 with feature j, and get 2 leaves l1 and l2\n",
    "                    l1 = d0 + (-j,)\n",
    "                    l2 = d0 + (j,)\n",
    "                    # print(\"t\",t)\n",
    "\n",
    "                    pred_l = [0] * 2\n",
    "                    cap_l = [0] * 2\n",
    "                    incorr_l = [0] * 2\n",
    "                    p_l = [0] * 2\n",
    "                    B0_l = [0] * 2\n",
    "                    points_l = make_zeros(2)\n",
    "\n",
    "                    # for the two new leaves, if they have not been visited,\n",
    "                    # calculate their predictions,\n",
    "                    l1_sorted = tuple(sorted(l1))\n",
    "                    l2_sorted = tuple(sorted(l2))\n",
    "\n",
    "\n",
    "                    tag = removed_leaf.points_cap  # points captured by the leaf's parent leaf\n",
    "\n",
    "                    rule_index = j-1\n",
    "\n",
    "                    if l1_sorted not in leaf_cache:\n",
    "                        tag_rule1 = rule_vectompz(np.array(x[:, rule_index] == 0) * 1)\n",
    "                        new_points_cap1, new_num_captured1 = rule_vand(tag, tag_rule1)\n",
    "                        leaf_cache[l1_sorted] = CacheLeaf(l1_sorted, y, z, new_points_cap1, new_num_captured1, lamb, support)\n",
    "\n",
    "                    Cache_l1 = leaf_cache[l1_sorted]\n",
    "                    cap_l[0], incorr_l[\n",
    "                        0] = Cache_l1.num_captured, Cache_l1.num_captured_incorrect\n",
    "\n",
    "                    if l2_sorted not in leaf_cache:\n",
    "                        tag_rule2 = rule_vectompz(np.array(x[:, rule_index] == 1) * 1)\n",
    "                        new_points_cap2, new_num_captured2 = rule_vand(tag, tag_rule2)\n",
    "                        leaf_cache[l2_sorted] = CacheLeaf(l2_sorted, y, z, new_points_cap2, new_num_captured2, lamb, support)\n",
    "\n",
    "                    Cache_l2 = leaf_cache[l2_sorted]\n",
    "                    cap_l[1], incorr_l[\n",
    "                        1] = Cache_l2.num_captured, Cache_l2.num_captured_incorrect\n",
    "\n",
    "\n",
    "                    new_leaves = [Cache_l1, Cache_l2]\n",
    "                    \n",
    "                    tree_new_leaves = unchanged_leaves+new_leaves\n",
    "\n",
    "                    sorted_new_tree_rules = tuple(sorted(leaf.rules for leaf in tree_new_leaves))\n",
    "                    if sorted_new_tree_rules in tree_cache:\n",
    "                        continue\n",
    "                    else:\n",
    "                        tree_cache[sorted_new_tree_rules] = True\n",
    "\n",
    "\n",
    "                    # calculate the bounds for each leaves in the new tree\n",
    "                    loss_l1 = incorr_l[0] / ndata\n",
    "                    loss_l2 = incorr_l[1] / ndata\n",
    "                    loss_d0 = tree.leaves[i].p * tree.leaves[i].num_captured / ndata\n",
    "                    delta = loss_l1 + loss_l2 - loss_d0 + lamb\n",
    "                    old_lbound = tree.lbound[:i] + tree.lbound[i + 1:]\n",
    "                    new_lbound = [b + delta for b in old_lbound] + \\\n",
    "                        [tree.lbound[i] + loss_l2 + lamb,\n",
    "                            tree.lbound[i] + loss_l1 + lamb]\n",
    "\n",
    "                    # generate the new splitleaf for the new tree\n",
    "                    sl = generate_new_splitleaf(\n",
    "                        tree_new_leaves, sorted_new_tree_rules, leaf_cache, splitleaf_list, ndata, len(unchanged_leaves)+2, lamb, min(R_c, new_lbound[-1]+loss_l2),\n",
    "                        accu_support, equiv_points, lookahead)\n",
    "                    # print('sl',sl)\n",
    "\n",
    "                    # construct the new tree\n",
    "                    tree_new = CacheTree(ndata=ndata, leaves=tree_new_leaves,\n",
    "                                         prior_metric=prior_metric,\n",
    "                                         splitleaf=sl,\n",
    "                                         lbound=new_lbound,\n",
    "                                         similar_leafdead = tree.similar_leafdead[:i]+tree.similar_leafdead[i+1:]+[0,0]\n",
    "                                         )\n",
    "\n",
    "\n",
    "\n",
    "                    # queue.append(tree_new)\n",
    "\n",
    "                    heapq.heappush(queue, (tree_new.metric, tree_new))\n",
    "                    COUNT = COUNT + 1\n",
    "                    R = tree_new.risk\n",
    "                    if R < R_c:\n",
    "                        d_c = tree_new\n",
    "                        R_c = R\n",
    "                        C_c = COUNT\n",
    "                        time_c = time.time()-tic\n",
    "\n",
    "                    if logon==True:\n",
    "                        log(lines, COUNT_POP, COUNT, queue, metric, R_c, tree, tree_new, sorted_new_tree_rules)\n",
    "\n",
    "                    if COUNT % 100000 == 0:\n",
    "                        print(\"COUNT:\", COUNT)\n",
    "\n",
    "\n",
    "    header = ['#pop', '#push', 'queue_size', 'metric', 'R_c',\n",
    "              'the_old_tree', 'the_old_tree_splitleaf', 'the_new_tree', 'the_new_tree_splitleaf',\n",
    "              'the_new_tree_objective', 'the_new_tree_lbound', 'the_new_tree_length', 'the_new_tree_depth', 'queue']\n",
    "\n",
    "    fname = \"_\".join([str(nrule), str(ndata), prior_metric,\n",
    "                      str(lamb), str(MAXDEPTH), str(lookahead), \".txt\"])\n",
    "    with open(fname, 'w') as f:\n",
    "        f.write('%s\\n' % \";\".join(header))\n",
    "        f.write('\\n'.join(lines))\n",
    "\n",
    "    print(\">>> log:\",logon)\n",
    "    print(\">>> support bound:\",support)\n",
    "    print(\">>> accurate support bound:\",accu_support)\n",
    "    print(\">>> equiv points bound:\",equiv_points)\n",
    "    print(\">>> lookahead bound:\",lookahead)\n",
    "\n",
    "    print(\"total time: \", time.time() - tic)\n",
    "    print(\"lambda: \", lamb)\n",
    "    print(\"leaves: \", [leaf.rules for leaf in d_c.leaves])\n",
    "    #print(\"lbound: \", d_c.lbound)\n",
    "    #print(\"d_c.num_captured: \", [leaf.num_captured for leaf in d_c.leaves])\n",
    "    print(\"prediction: \", [leaf.prediction for leaf in d_c.leaves])\n",
    "    print(\"Objective: \", R_c)\n",
    "    print(\"COUNT of the best tree: \", C_c)\n",
    "    print(\"time when the best tree is achieved: \", time_c)\n",
    "    print(\"TOTAL COUNT: \", COUNT)\n",
    "\n",
    "    return d_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nrule: 5\n",
      "ndata: 6907\n",
      "the rank of x's columns:  [4, 0, 1, 2, 3]\n",
      "COUNT: 100000\n",
      "COUNT: 200000\n"
     ]
    }
   ],
   "source": [
    "#all bounds\n",
    "#all data, 5 features\n",
    "\n",
    "bbound(x, y, z, lamb=0.0035, prior_metric=\"objective\", MAXDEPTH = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nrule: 4\n",
      "ndata: 6907\n",
      "the rank of x's columns:  [0, 1, 2, 3]\n",
      ">>> log: False\n",
      ">>> support bound: True\n",
      ">>> accurate support bound: True\n",
      ">>> equiv points bound: True\n",
      ">>> lookahead bound: True\n",
      "total time:  123.88997340202332\n",
      "lambda:  0.0035\n",
      "leaves:  [(1,), (-1, 2), (-3, -2, -1), (-2, -1, 3)]\n",
      "prediction:  [0, 1, 0, 1]\n",
      "Objective:  0.4442881135080353\n",
      "COUNT of the best tree:  13984\n",
      "time when the best tree is achieved:  27.082135915756226\n",
      "TOTAL COUNT:  21107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.CacheTree at 0x7fb9b3674080>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all bounds\n",
    "#all data, 4 features\n",
    "\n",
    "bbound(x[:,:4], y, z, lamb=0.0035, prior_metric=\"objective\", MAXDEPTH = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nrule: 4\n",
      "ndata: 6907\n",
      "the rank of x's columns:  [0, 1, 2, 3]\n",
      ">>> log: False\n",
      ">>> support bound: True\n",
      ">>> accurate support bound: True\n",
      ">>> equiv points bound: True\n",
      ">>> lookahead bound: True\n",
      "total time:  1438.1010637283325\n",
      "lambda:  0.0035\n",
      "leaves:  [(1,), (-1, 2), (-3, -2, -1), (-2, -1, 3)]\n",
      "prediction:  [0, 1, 0, 1]\n",
      "Objective:  0.4442881135080353\n",
      "COUNT of the best tree:  13984\n",
      "time when the best tree is achieved:  297.12666606903076\n",
      "TOTAL COUNT:  21107\n",
      "         302470331 function calls (302470330 primitive calls) in 1438.251 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:997(_handle_fromlist)\n",
      "       80    0.003    0.000    1.219    0.015 <ipython-input-20-237989e3b57a>:111(__init__)\n",
      "    21108    0.207    0.000    0.246    0.000 <ipython-input-20-237989e3b57a>:15(__init__)\n",
      "    21107    1.592    0.000    2.676    0.000 <ipython-input-20-237989e3b57a>:179(generate_new_splitleaf)\n",
      "    21107    0.077    0.000    0.077    0.000 <ipython-input-20-237989e3b57a>:183(<listcomp>)\n",
      "    21107    0.094    0.000    0.094    0.000 <ipython-input-20-237989e3b57a>:208(<listcomp>)\n",
      "        1    0.003    0.003    0.144    0.144 <ipython-input-20-237989e3b57a>:324(gini_reduction)\n",
      "        4    0.000    0.000    0.000    0.000 <ipython-input-20-237989e3b57a>:348(<lambda>)\n",
      "        1  486.428  486.428 1438.249 1438.249 <ipython-input-20-237989e3b57a>:353(bbound)\n",
      "    62725    0.124    0.000    0.124    0.000 <ipython-input-20-237989e3b57a>:468(<listcomp>)\n",
      "   824462    1.769    0.000    1.769    0.000 <ipython-input-20-237989e3b57a>:525(<genexpr>)\n",
      "    21107    0.073    0.000    0.073    0.000 <ipython-input-20-237989e3b57a>:538(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 <ipython-input-20-237989e3b57a>:593(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 <ipython-input-20-237989e3b57a>:596(<listcomp>)\n",
      "    59651    0.156    0.000    0.156    0.000 <ipython-input-20-237989e3b57a>:62(__lt__)\n",
      "        1    0.001    0.001 1438.251 1438.251 <string>:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:200(iteritems)\n",
      "        1    0.000    0.000    0.000    0.000 _bootlocale.py:23(getpreferredencoding)\n",
      "        1    0.000    0.000    0.000    0.000 _weakrefset.py:70(__contains__)\n",
      "        1    0.000    0.000    0.000    0.000 abc.py:180(__instancecheck__)\n",
      "        1    0.000    0.000    0.000    0.000 algorithms.py:217(_get_data_algo)\n",
      "        1    0.000    0.000    0.000    0.000 algorithms.py:39(_ensure_data)\n",
      "        1    0.000    0.000    0.000    0.000 algorithms.py:680(rank)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:4155(_ensure_index)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:551(_reset_identity)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:707(ndim)\n",
      "        1    0.000    0.000    0.001    0.001 base.py:799(tolist)\n",
      "        1    0.000    0.000    0.001    0.001 base.py:817(__iter__)\n",
      "        1    0.000    0.000    0.000    0.000 cast.py:39(maybe_convert_platform)\n",
      "        1    0.000    0.000    0.000    0.000 cast.py:826(maybe_castable)\n",
      "        1    0.000    0.000    0.000    0.000 cast.py:935(maybe_cast_to_datetime)\n",
      "        1    0.000    0.000    0.000    0.000 codecs.py:185(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:1493(is_float_dtype)\n",
      "        2    0.000    0.000    0.000    0.000 common.py:1545(is_bool_dtype)\n",
      "        6    0.000    0.000    0.000    0.000 common.py:1773(_get_dtype_type)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:207(_default_index)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:223(is_datetimetz)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:238(_all_none)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:297(is_datetime64_dtype)\n",
      "        2    0.000    0.000    0.001    0.000 common.py:334(is_datetime64tz_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:372(is_timedelta64_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:478(is_categorical_dtype)\n",
      "        1    0.000    0.000    0.001    0.001 common.py:612(is_datetimelike)\n",
      "        2    0.000    0.000    0.000    0.000 common.py:824(is_signed_integer_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:85(is_object_dtype)\n",
      "        2    0.000    0.000    0.000    0.000 common.py:873(is_unsigned_integer_dtype)\n",
      "        3    0.000    0.000    0.001    0.000 dtypes.py:85(is_dtype)\n",
      "        4    0.000    0.000    0.000    0.000 enum.py:265(__call__)\n",
      "        4    0.000    0.000    0.000    0.000 enum.py:515(__new__)\n",
      "        2    0.000    0.000    0.000    0.000 enum.py:801(__and__)\n",
      "        2    0.000    0.000    0.000    0.000 generic.py:120(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:279(_construct_axes_dict)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:281(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:346(_get_axis_number)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:3583(__finalize__)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:359(_get_axis_name)\n",
      "        2    0.000    0.000    0.000    0.000 generic.py:3600(__getattr__)\n",
      "        2    0.000    0.000    0.000    0.000 generic.py:3616(__setattr__)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:372(_get_axis)\n",
      "        1    0.000    0.000    0.001    0.001 generic.py:5595(rank)\n",
      "        1    0.000    0.000    0.001    0.001 generic.py:5633(ranker)\n",
      "        4    0.000    0.000    0.000    0.000 generic.py:7(_check)\n",
      "        1    0.000    0.000    0.000    0.000 inference.py:234(is_list_like)\n",
      "        2    0.000    0.000    0.000    0.000 internals.py:107(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 internals.py:155(external_values)\n",
      "        1    0.000    0.000    0.000    0.000 internals.py:159(internal_values)\n",
      "        2    0.000    0.000    0.000    0.000 internals.py:189(mgr_locs)\n",
      "        2    0.000    0.000    0.000    0.000 internals.py:226(mgr_locs)\n",
      "        2    0.000    0.000    0.000    0.000 internals.py:2921(make_block)\n",
      "        6    0.000    0.000    0.000    0.000 internals.py:307(dtype)\n",
      "        1    0.000    0.000    0.000    0.000 internals.py:3135(_get_items)\n",
      "        1    0.000    0.000    0.000    0.000 internals.py:3224(__len__)\n",
      "        2    0.000    0.000    0.000    0.000 internals.py:4363(__init__)\n",
      "        8    0.000    0.000    0.000    0.000 internals.py:4409(_block)\n",
      "        6    0.000    0.000    0.000    0.000 internals.py:4479(dtype)\n",
      "        1    0.000    0.000    0.000    0.000 internals.py:4503(external_values)\n",
      "        1    0.000    0.000    0.000    0.000 internals.py:4506(internal_values)\n",
      "       66    0.001    0.000    0.004    0.000 iostream.py:195(schedule)\n",
      "       64    0.000    0.000    0.000    0.000 iostream.py:300(_is_master_process)\n",
      "       64    0.000    0.000    0.000    0.000 iostream.py:313(_schedule_flush)\n",
      "       64    0.001    0.000    0.005    0.000 iostream.py:366(write)\n",
      "       66    0.000    0.000    0.000    0.000 iostream.py:93(_event_pipe)\n",
      "        1    0.000    0.000    0.000    0.000 numeric.py:424(asarray)\n",
      "        2    0.000    0.000    0.000    0.000 numeric.py:99(is_all_dates)\n",
      "        1    0.000    0.000    0.000    0.000 range.py:119(_simple_new)\n",
      "        1    0.000    0.000    0.000    0.000 range.py:146(_validate_dtype)\n",
      "        5    0.000    0.000    0.000    0.000 range.py:469(__len__)\n",
      "        1    0.000    0.000    0.000    0.000 range.py:56(__new__)\n",
      "        2    0.000    0.000    0.000    0.000 range.py:72(_ensure_int)\n",
      "      239    0.002    0.000    0.664    0.003 re.py:184(sub)\n",
      "      239    0.001    0.000    0.002    0.000 re.py:286(_compile)\n",
      "      239    1.120    0.005    1.803    0.008 rule.py:148(rule_vectompz)\n",
      "      239    0.002    0.000    0.002    0.000 rule.py:162(rule_vand)\n",
      "150202454  623.260    0.000  940.805    0.000 rule.py:191(rule_vxor)\n",
      "        1    0.000    0.000    0.000    0.000 rule.py:74(make_all_ones)\n",
      "    76590    0.341    0.000    0.526    0.000 rule.py:85(make_zeros)\n",
      "        2    0.000    0.000    0.001    0.001 series.py:155(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 series.py:284(_constructor)\n",
      "        2    0.000    0.000    0.000    0.000 series.py:300(_set_axis)\n",
      "        2    0.000    0.000    0.000    0.000 series.py:3136(_sanitize_array)\n",
      "        1    0.000    0.000    0.000    0.000 series.py:3153(_try_cast)\n",
      "        2    0.000    0.000    0.000    0.000 series.py:326(_set_subtyp)\n",
      "        3    0.000    0.000    0.000    0.000 series.py:336(name)\n",
      "        3    0.000    0.000    0.000    0.000 series.py:340(name)\n",
      "        6    0.000    0.000    0.000    0.000 series.py:347(dtype)\n",
      "        1    0.000    0.000    0.000    0.000 series.py:367(values)\n",
      "        1    0.000    0.000    0.000    0.000 series.py:400(_values)\n",
      "        1    0.000    0.000    0.000    0.000 series.py:483(__len__)\n",
      "       66    0.001    0.000    0.001    0.000 socket.py:333(send)\n",
      "        2    0.000    0.000    0.000    0.000 sre_compile.py:223(_compile_charset)\n",
      "        2    0.000    0.000    0.000    0.000 sre_compile.py:250(_optimize_charset)\n",
      "        2    0.000    0.000    0.000    0.000 sre_compile.py:376(_mk_bitmap)\n",
      "        2    0.000    0.000    0.000    0.000 sre_compile.py:378(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 sre_compile.py:414(_get_literal_prefix)\n",
      "        1    0.000    0.000    0.000    0.000 sre_compile.py:441(_get_charset_prefix)\n",
      "        1    0.000    0.000    0.000    0.000 sre_compile.py:482(_compile_info)\n",
      "        2    0.000    0.000    0.000    0.000 sre_compile.py:539(isstring)\n",
      "        1    0.000    0.000    0.000    0.000 sre_compile.py:542(_code)\n",
      "        1    0.000    0.000    0.001    0.001 sre_compile.py:557(compile)\n",
      "        1    0.000    0.000    0.000    0.000 sre_compile.py:64(_compile)\n",
      "        1    0.000    0.000    0.000    0.000 sre_parse.py:111(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 sre_parse.py:171(append)\n",
      "        1    0.000    0.000    0.000    0.000 sre_parse.py:173(getwidth)\n",
      "        1    0.000    0.000    0.000    0.000 sre_parse.py:223(__init__)\n",
      "        8    0.000    0.000    0.000    0.000 sre_parse.py:232(__next)\n",
      "        7    0.000    0.000    0.000    0.000 sre_parse.py:248(match)\n",
      "        7    0.000    0.000    0.000    0.000 sre_parse.py:253(get)\n",
      "        2    0.000    0.000    0.000    0.000 sre_parse.py:285(tell)\n",
      "        3    0.000    0.000    0.000    0.000 sre_parse.py:294(_class_escape)\n",
      "        1    0.000    0.000    0.000    0.000 sre_parse.py:407(_parse_sub)\n",
      "        1    0.000    0.000    0.000    0.000 sre_parse.py:470(_parse)\n",
      "        1    0.000    0.000    0.000    0.000 sre_parse.py:76(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 sre_parse.py:81(groups)\n",
      "        1    0.000    0.000    0.000    0.000 sre_parse.py:828(fix_flags)\n",
      "        1    0.000    0.000    0.000    0.000 sre_parse.py:844(parse)\n",
      "       66    0.000    0.000    0.000    0.000 threading.py:1062(_wait_for_tstate_lock)\n",
      "       66    0.001    0.000    0.001    0.000 threading.py:1104(is_alive)\n",
      "       66    0.000    0.000    0.000    0.000 threading.py:506(is_set)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x7fba00314780}\n",
      "    21108    0.340    0.000    0.488    0.000 {built-in method _heapq.heappop}\n",
      "    21108    0.076    0.000    0.084    0.000 {built-in method _heapq.heappush}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _locale.nl_langinfo}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _sre.compile}\n",
      "        1    0.000    0.000 1438.251 1438.251 {built-in method builtins.exec}\n",
      "        9    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "        7    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\n",
      "      160    0.001    0.000    0.001    0.000 {built-in method builtins.isinstance}\n",
      "       11    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n",
      "285281/285280    0.527    0.000    0.527    0.000 {built-in method builtins.len}\n",
      "        5    0.000    0.000    0.000    0.000 {built-in method builtins.max}\n",
      "    21110    0.064    0.000    0.064    0.000 {built-in method builtins.min}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.ord}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.pow}\n",
      "       16    0.000    0.000    0.006    0.000 {built-in method builtins.print}\n",
      "   271003    2.631    0.000    4.400    0.000 {built-in method builtins.sorted}\n",
      "    84437    0.432    0.000    0.432    0.000 {built-in method builtins.sum}\n",
      "    76830    0.205    0.000    0.205    0.000 {built-in method gmpy2.mpz}\n",
      "150202693  317.546    0.000  317.546    0.000 {built-in method gmpy2.popcount}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method io.open}\n",
      "    21187    0.197    0.000    0.197    0.000 {built-in method numpy.core.multiarray.array}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method pandas._libs.algos.ensure_float64}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method pandas._libs.lib.is_integer}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method pandas._libs.lib.isscalar}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method pandas._libs.lib.list_to_object_array}\n",
      "       64    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method time.time}\n",
      "       66    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "       66    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "    26001    0.055    0.000    0.055    0.000 {method 'append' of 'list' objects}\n",
      "    42215    0.085    0.000    0.085    0.000 {method 'copy' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}\n",
      "       10    0.000    0.000    0.000    0.000 {method 'find' of 'bytearray' objects}\n",
      "        9    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "    42214    0.115    0.000    0.115    0.000 {method 'index' of 'list' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}\n",
      "    21108    0.058    0.000    0.058    0.000 {method 'pop' of 'list' objects}\n",
      "       80    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
      "      239    0.659    0.003    0.659    0.003 {method 'sub' of '_sre.SRE_Pattern' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'tolist' of 'numpy.ndarray' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'translate' of 'bytearray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'write' of '_io.TextIOWrapper' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {pandas._libs.algos.rank_1d_float64}\n",
      "        1    0.000    0.000    0.000    0.000 {pandas._libs.lib.maybe_convert_objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cProfile.run(\"bbound(x[:,:4], y, z, lamb=0.0035, prior_metric=\\\"objective\\\", MAXDEPTH = 4)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
